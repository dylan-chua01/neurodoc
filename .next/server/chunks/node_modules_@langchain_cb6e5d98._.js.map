{
  "version": 3,
  "sources": [],
  "sections": [
    {"offset": {"line": 7, "column": 0}, "map": {"version":3,"sources":["file:///Users/dylanchua/Documents/Personal/Code/neurodocument/node_modules/%40langchain/google-genai/node_modules/uuid/dist/esm/native.js"],"sourcesContent":["import { randomUUID } from 'crypto';\nexport default { randomUUID };\n"],"names":[],"mappings":";;;AAAA;;uCACe;IAAE,YAAA,qGAAA,CAAA,aAAU;AAAC","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 21, "column": 0}, "map": {"version":3,"sources":["file:///Users/dylanchua/Documents/Personal/Code/neurodocument/node_modules/%40langchain/google-genai/node_modules/uuid/dist/esm/rng.js"],"sourcesContent":["import { randomFillSync } from 'crypto';\nconst rnds8Pool = new Uint8Array(256);\nlet poolPtr = rnds8Pool.length;\nexport default function rng() {\n    if (poolPtr > rnds8Pool.length - 16) {\n        randomFillSync(rnds8Pool);\n        poolPtr = 0;\n    }\n    return rnds8Pool.slice(poolPtr, (poolPtr += 16));\n}\n"],"names":[],"mappings":";;;AAAA;;AACA,MAAM,YAAY,IAAI,WAAW;AACjC,IAAI,UAAU,UAAU,MAAM;AACf,SAAS;IACpB,IAAI,UAAU,UAAU,MAAM,GAAG,IAAI;QACjC,CAAA,GAAA,qGAAA,CAAA,iBAAc,AAAD,EAAE;QACf,UAAU;IACd;IACA,OAAO,UAAU,KAAK,CAAC,SAAU,WAAW;AAChD","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 41, "column": 0}, "map": {"version":3,"sources":["file:///Users/dylanchua/Documents/Personal/Code/neurodocument/node_modules/%40langchain/google-genai/node_modules/uuid/dist/esm/regex.js"],"sourcesContent":["export default /^(?:[0-9a-f]{8}-[0-9a-f]{4}-[1-8][0-9a-f]{3}-[89ab][0-9a-f]{3}-[0-9a-f]{12}|00000000-0000-0000-0000-000000000000|ffffffff-ffff-ffff-ffff-ffffffffffff)$/i;\n"],"names":[],"mappings":";;;uCAAe","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 51, "column": 0}, "map": {"version":3,"sources":["file:///Users/dylanchua/Documents/Personal/Code/neurodocument/node_modules/%40langchain/google-genai/node_modules/uuid/dist/esm/validate.js"],"sourcesContent":["import REGEX from './regex.js';\nfunction validate(uuid) {\n    return typeof uuid === 'string' && REGEX.test(uuid);\n}\nexport default validate;\n"],"names":[],"mappings":";;;AAAA;;AACA,SAAS,SAAS,IAAI;IAClB,OAAO,OAAO,SAAS,YAAY,gMAAA,CAAA,UAAK,CAAC,IAAI,CAAC;AAClD;uCACe","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 66, "column": 0}, "map": {"version":3,"sources":["file:///Users/dylanchua/Documents/Personal/Code/neurodocument/node_modules/%40langchain/google-genai/node_modules/uuid/dist/esm/stringify.js"],"sourcesContent":["import validate from './validate.js';\nconst byteToHex = [];\nfor (let i = 0; i < 256; ++i) {\n    byteToHex.push((i + 0x100).toString(16).slice(1));\n}\nexport function unsafeStringify(arr, offset = 0) {\n    return (byteToHex[arr[offset + 0]] +\n        byteToHex[arr[offset + 1]] +\n        byteToHex[arr[offset + 2]] +\n        byteToHex[arr[offset + 3]] +\n        '-' +\n        byteToHex[arr[offset + 4]] +\n        byteToHex[arr[offset + 5]] +\n        '-' +\n        byteToHex[arr[offset + 6]] +\n        byteToHex[arr[offset + 7]] +\n        '-' +\n        byteToHex[arr[offset + 8]] +\n        byteToHex[arr[offset + 9]] +\n        '-' +\n        byteToHex[arr[offset + 10]] +\n        byteToHex[arr[offset + 11]] +\n        byteToHex[arr[offset + 12]] +\n        byteToHex[arr[offset + 13]] +\n        byteToHex[arr[offset + 14]] +\n        byteToHex[arr[offset + 15]]).toLowerCase();\n}\nfunction stringify(arr, offset = 0) {\n    const uuid = unsafeStringify(arr, offset);\n    if (!validate(uuid)) {\n        throw TypeError('Stringified UUID is invalid');\n    }\n    return uuid;\n}\nexport default stringify;\n"],"names":[],"mappings":";;;;AAAA;;AACA,MAAM,YAAY,EAAE;AACpB,IAAK,IAAI,IAAI,GAAG,IAAI,KAAK,EAAE,EAAG;IAC1B,UAAU,IAAI,CAAC,CAAC,IAAI,KAAK,EAAE,QAAQ,CAAC,IAAI,KAAK,CAAC;AAClD;AACO,SAAS,gBAAgB,GAAG,EAAE,SAAS,CAAC;IAC3C,OAAO,CAAC,SAAS,CAAC,GAAG,CAAC,SAAS,EAAE,CAAC,GAC9B,SAAS,CAAC,GAAG,CAAC,SAAS,EAAE,CAAC,GAC1B,SAAS,CAAC,GAAG,CAAC,SAAS,EAAE,CAAC,GAC1B,SAAS,CAAC,GAAG,CAAC,SAAS,EAAE,CAAC,GAC1B,MACA,SAAS,CAAC,GAAG,CAAC,SAAS,EAAE,CAAC,GAC1B,SAAS,CAAC,GAAG,CAAC,SAAS,EAAE,CAAC,GAC1B,MACA,SAAS,CAAC,GAAG,CAAC,SAAS,EAAE,CAAC,GAC1B,SAAS,CAAC,GAAG,CAAC,SAAS,EAAE,CAAC,GAC1B,MACA,SAAS,CAAC,GAAG,CAAC,SAAS,EAAE,CAAC,GAC1B,SAAS,CAAC,GAAG,CAAC,SAAS,EAAE,CAAC,GAC1B,MACA,SAAS,CAAC,GAAG,CAAC,SAAS,GAAG,CAAC,GAC3B,SAAS,CAAC,GAAG,CAAC,SAAS,GAAG,CAAC,GAC3B,SAAS,CAAC,GAAG,CAAC,SAAS,GAAG,CAAC,GAC3B,SAAS,CAAC,GAAG,CAAC,SAAS,GAAG,CAAC,GAC3B,SAAS,CAAC,GAAG,CAAC,SAAS,GAAG,CAAC,GAC3B,SAAS,CAAC,GAAG,CAAC,SAAS,GAAG,CAAC,EAAE,WAAW;AAChD;AACA,SAAS,UAAU,GAAG,EAAE,SAAS,CAAC;IAC9B,MAAM,OAAO,gBAAgB,KAAK;IAClC,IAAI,CAAC,CAAA,GAAA,mMAAA,CAAA,UAAQ,AAAD,EAAE,OAAO;QACjB,MAAM,UAAU;IACpB;IACA,OAAO;AACX;uCACe","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 93, "column": 0}, "map": {"version":3,"sources":["file:///Users/dylanchua/Documents/Personal/Code/neurodocument/node_modules/%40langchain/google-genai/node_modules/uuid/dist/esm/v4.js"],"sourcesContent":["import native from './native.js';\nimport rng from './rng.js';\nimport { unsafeStringify } from './stringify.js';\nfunction v4(options, buf, offset) {\n    if (native.randomUUID && !buf && !options) {\n        return native.randomUUID();\n    }\n    options = options || {};\n    const rnds = options.random ?? options.rng?.() ?? rng();\n    if (rnds.length < 16) {\n        throw new Error('Random bytes length must be >= 16');\n    }\n    rnds[6] = (rnds[6] & 0x0f) | 0x40;\n    rnds[8] = (rnds[8] & 0x3f) | 0x80;\n    if (buf) {\n        offset = offset || 0;\n        if (offset < 0 || offset + 16 > buf.length) {\n            throw new RangeError(`UUID byte range ${offset}:${offset + 15} is out of buffer bounds`);\n        }\n        for (let i = 0; i < 16; ++i) {\n            buf[offset + i] = rnds[i];\n        }\n        return buf;\n    }\n    return unsafeStringify(rnds);\n}\nexport default v4;\n"],"names":[],"mappings":";;;AAAA;AACA;AACA;;;;AACA,SAAS,GAAG,OAAO,EAAE,GAAG,EAAE,MAAM;IAC5B,IAAI,iMAAA,CAAA,UAAM,CAAC,UAAU,IAAI,CAAC,OAAO,CAAC,SAAS;QACvC,OAAO,iMAAA,CAAA,UAAM,CAAC,UAAU;IAC5B;IACA,UAAU,WAAW,CAAC;IACtB,MAAM,OAAO,QAAQ,MAAM,IAAI,QAAQ,GAAG,QAAQ,CAAA,GAAA,8LAAA,CAAA,UAAG,AAAD;IACpD,IAAI,KAAK,MAAM,GAAG,IAAI;QAClB,MAAM,IAAI,MAAM;IACpB;IACA,IAAI,CAAC,EAAE,GAAG,AAAC,IAAI,CAAC,EAAE,GAAG,OAAQ;IAC7B,IAAI,CAAC,EAAE,GAAG,AAAC,IAAI,CAAC,EAAE,GAAG,OAAQ;IAC7B,IAAI,KAAK;QACL,SAAS,UAAU;QACnB,IAAI,SAAS,KAAK,SAAS,KAAK,IAAI,MAAM,EAAE;YACxC,MAAM,IAAI,WAAW,CAAC,gBAAgB,EAAE,OAAO,CAAC,EAAE,SAAS,GAAG,wBAAwB,CAAC;QAC3F;QACA,IAAK,IAAI,IAAI,GAAG,IAAI,IAAI,EAAE,EAAG;YACzB,GAAG,CAAC,SAAS,EAAE,GAAG,IAAI,CAAC,EAAE;QAC7B;QACA,OAAO;IACX;IACA,OAAO,CAAA,GAAA,oMAAA,CAAA,kBAAe,AAAD,EAAE;AAC3B;uCACe","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 142, "column": 0}, "map": {"version":3,"sources":["file:///Users/dylanchua/Documents/Personal/Code/neurodocument/node_modules/%40langchain/community/dist/document_loaders/fs/pdf.js"],"sourcesContent":["import { Document } from \"@langchain/core/documents\";\nimport { BufferLoader } from \"langchain/document_loaders/fs/buffer\";\n/**\n * A class that extends the `BufferLoader` class. It represents a document\n * loader that loads documents from PDF files.\n * @example\n * ```typescript\n * const loader = new PDFLoader(\"path/to/bitcoin.pdf\");\n * const docs = await loader.load();\n * console.log({ docs });\n * ```\n */\nexport class PDFLoader extends BufferLoader {\n    constructor(filePathOrBlob, { splitPages = true, pdfjs = PDFLoaderImports, parsedItemSeparator = \"\", } = {}) {\n        super(filePathOrBlob);\n        Object.defineProperty(this, \"splitPages\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"pdfjs\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"parsedItemSeparator\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        this.splitPages = splitPages;\n        this.pdfjs = pdfjs;\n        this.parsedItemSeparator = parsedItemSeparator;\n    }\n    /**\n     * A method that takes a `raw` buffer and `metadata` as parameters and\n     * returns a promise that resolves to an array of `Document` instances. It\n     * uses the `getDocument` function from the PDF.js library to load the PDF\n     * from the buffer. It then iterates over each page of the PDF, retrieves\n     * the text content using the `getTextContent` method, and joins the text\n     * items to form the page content. It creates a new `Document` instance\n     * for each page with the extracted text content and metadata, and adds it\n     * to the `documents` array. If `splitPages` is `true`, it returns the\n     * array of `Document` instances. Otherwise, if there are no documents, it\n     * returns an empty array. Otherwise, it concatenates the page content of\n     * all documents and creates a single `Document` instance with the\n     * concatenated content.\n     * @param raw The buffer to be parsed.\n     * @param metadata The metadata of the document.\n     * @returns A promise that resolves to an array of `Document` instances.\n     */\n    async parse(raw, metadata) {\n        const { getDocument, version } = await this.pdfjs();\n        const pdf = await getDocument({\n            data: new Uint8Array(raw.buffer),\n            useWorkerFetch: false,\n            isEvalSupported: false,\n            useSystemFonts: true,\n        }).promise;\n        const meta = await pdf.getMetadata().catch(() => null);\n        const documents = [];\n        for (let i = 1; i <= pdf.numPages; i += 1) {\n            const page = await pdf.getPage(i);\n            const content = await page.getTextContent();\n            if (content.items.length === 0) {\n                continue;\n            }\n            // Eliminate excessive newlines\n            // Source: https://github.com/albertcui/pdf-parse/blob/7086fc1cc9058545cdf41dd0646d6ae5832c7107/lib/pdf-parse.js#L16\n            let lastY;\n            const textItems = [];\n            for (const item of content.items) {\n                if (\"str\" in item) {\n                    if (lastY === item.transform[5] || !lastY) {\n                        textItems.push(item.str);\n                    }\n                    else {\n                        textItems.push(`\\n${item.str}`);\n                    }\n                    // eslint-disable-next-line prefer-destructuring\n                    lastY = item.transform[5];\n                }\n            }\n            const text = textItems.join(this.parsedItemSeparator);\n            documents.push(new Document({\n                pageContent: text,\n                metadata: {\n                    ...metadata,\n                    pdf: {\n                        version,\n                        info: meta?.info,\n                        metadata: meta?.metadata,\n                        totalPages: pdf.numPages,\n                    },\n                    loc: {\n                        pageNumber: i,\n                    },\n                },\n            }));\n        }\n        if (this.splitPages) {\n            return documents;\n        }\n        if (documents.length === 0) {\n            return [];\n        }\n        return [\n            new Document({\n                pageContent: documents.map((doc) => doc.pageContent).join(\"\\n\\n\"),\n                metadata: {\n                    ...metadata,\n                    pdf: {\n                        version,\n                        info: meta?.info,\n                        metadata: meta?.metadata,\n                        totalPages: pdf.numPages,\n                    },\n                },\n            }),\n        ];\n    }\n}\nasync function PDFLoaderImports() {\n    try {\n        const { default: mod } = await import(\"pdf-parse/lib/pdf.js/v1.10.100/build/pdf.js\");\n        const { getDocument, version } = mod;\n        return { getDocument, version };\n    }\n    catch (e) {\n        console.error(e);\n        throw new Error(\"Failed to load pdf-parse. Please install it with eg. `npm install pdf-parse`.\");\n    }\n}\n"],"names":[],"mappings":";;;AAAA;AAAA;AACA;AAAA;;;AAWO,MAAM,kBAAkB,uKAAA,CAAA,eAAY;IACvC,YAAY,cAAc,EAAE,EAAE,aAAa,IAAI,EAAE,QAAQ,gBAAgB,EAAE,sBAAsB,EAAE,EAAG,GAAG,CAAC,CAAC,CAAE;QACzG,KAAK,CAAC;QACN,OAAO,cAAc,CAAC,IAAI,EAAE,cAAc;YACtC,YAAY;YACZ,cAAc;YACd,UAAU;YACV,OAAO,KAAK;QAChB;QACA,OAAO,cAAc,CAAC,IAAI,EAAE,SAAS;YACjC,YAAY;YACZ,cAAc;YACd,UAAU;YACV,OAAO,KAAK;QAChB;QACA,OAAO,cAAc,CAAC,IAAI,EAAE,uBAAuB;YAC/C,YAAY;YACZ,cAAc;YACd,UAAU;YACV,OAAO,KAAK;QAChB;QACA,IAAI,CAAC,UAAU,GAAG;QAClB,IAAI,CAAC,KAAK,GAAG;QACb,IAAI,CAAC,mBAAmB,GAAG;IAC/B;IACA;;;;;;;;;;;;;;;;KAgBC,GACD,MAAM,MAAM,GAAG,EAAE,QAAQ,EAAE;QACvB,MAAM,EAAE,WAAW,EAAE,OAAO,EAAE,GAAG,MAAM,IAAI,CAAC,KAAK;QACjD,MAAM,MAAM,MAAM,YAAY;YAC1B,MAAM,IAAI,WAAW,IAAI,MAAM;YAC/B,gBAAgB;YAChB,iBAAiB;YACjB,gBAAgB;QACpB,GAAG,OAAO;QACV,MAAM,OAAO,MAAM,IAAI,WAAW,GAAG,KAAK,CAAC,IAAM;QACjD,MAAM,YAAY,EAAE;QACpB,IAAK,IAAI,IAAI,GAAG,KAAK,IAAI,QAAQ,EAAE,KAAK,EAAG;YACvC,MAAM,OAAO,MAAM,IAAI,OAAO,CAAC;YAC/B,MAAM,UAAU,MAAM,KAAK,cAAc;YACzC,IAAI,QAAQ,KAAK,CAAC,MAAM,KAAK,GAAG;gBAC5B;YACJ;YACA,+BAA+B;YAC/B,oHAAoH;YACpH,IAAI;YACJ,MAAM,YAAY,EAAE;YACpB,KAAK,MAAM,QAAQ,QAAQ,KAAK,CAAE;gBAC9B,IAAI,SAAS,MAAM;oBACf,IAAI,UAAU,KAAK,SAAS,CAAC,EAAE,IAAI,CAAC,OAAO;wBACvC,UAAU,IAAI,CAAC,KAAK,GAAG;oBAC3B,OACK;wBACD,UAAU,IAAI,CAAC,CAAC,EAAE,EAAE,KAAK,GAAG,EAAE;oBAClC;oBACA,gDAAgD;oBAChD,QAAQ,KAAK,SAAS,CAAC,EAAE;gBAC7B;YACJ;YACA,MAAM,OAAO,UAAU,IAAI,CAAC,IAAI,CAAC,mBAAmB;YACpD,UAAU,IAAI,CAAC,IAAI,sKAAA,CAAA,WAAQ,CAAC;gBACxB,aAAa;gBACb,UAAU;oBACN,GAAG,QAAQ;oBACX,KAAK;wBACD;wBACA,MAAM,MAAM;wBACZ,UAAU,MAAM;wBAChB,YAAY,IAAI,QAAQ;oBAC5B;oBACA,KAAK;wBACD,YAAY;oBAChB;gBACJ;YACJ;QACJ;QACA,IAAI,IAAI,CAAC,UAAU,EAAE;YACjB,OAAO;QACX;QACA,IAAI,UAAU,MAAM,KAAK,GAAG;YACxB,OAAO,EAAE;QACb;QACA,OAAO;YACH,IAAI,sKAAA,CAAA,WAAQ,CAAC;gBACT,aAAa,UAAU,GAAG,CAAC,CAAC,MAAQ,IAAI,WAAW,EAAE,IAAI,CAAC;gBAC1D,UAAU;oBACN,GAAG,QAAQ;oBACX,KAAK;wBACD;wBACA,MAAM,MAAM;wBACZ,UAAU,MAAM;wBAChB,YAAY,IAAI,QAAQ;oBAC5B;gBACJ;YACJ;SACH;IACL;AACJ;AACA,eAAe;IACX,IAAI;QACA,MAAM,EAAE,SAAS,GAAG,EAAE,GAAG;QACzB,MAAM,EAAE,WAAW,EAAE,OAAO,EAAE,GAAG;QACjC,OAAO;YAAE;YAAa;QAAQ;IAClC,EACA,OAAO,GAAG;QACN,QAAQ,KAAK,CAAC;QACd,MAAM,IAAI,MAAM;IACpB;AACJ","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 281, "column": 0}, "map": {"version":3,"sources":["file:///Users/dylanchua/Documents/Personal/Code/neurodocument/node_modules/%40langchain/community/document_loaders/fs/pdf.js"],"sourcesContent":["export * from '../../dist/document_loaders/fs/pdf.js'"],"names":[],"mappings":";AAAA","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 299, "column": 0}, "map": {"version":3,"sources":["file:///Users/dylanchua/Documents/Personal/Code/neurodocument/node_modules/%40langchain/community/dist/vectorstores/pgvector.js"],"sourcesContent":["import pg from \"pg\";\nimport { VectorStore, } from \"@langchain/core/vectorstores\";\nimport { Document } from \"@langchain/core/documents\";\nimport { getEnvironmentVariable } from \"@langchain/core/utils/env\";\nimport { maximalMarginalRelevance } from \"@langchain/core/utils/math\";\n/**\n * PGVector vector store integration.\n *\n * Setup:\n * Install `@langchain/community` and `pg`.\n *\n * If you wish to generate ids, you should also install the `uuid` package.\n *\n * ```bash\n * npm install @langchain/community pg uuid\n * ```\n *\n * ## [Constructor args](https://api.js.langchain.com/classes/_langchain_community.vectorstores_pgvector.PGVectorStore.html#constructor)\n *\n * <details open>\n * <summary><strong>Instantiate</strong></summary>\n *\n * ```typescript\n * import {\n *   PGVectorStore,\n *   DistanceStrategy,\n * } from \"@langchain/community/vectorstores/pgvector\";\n *\n * // Or other embeddings\n * import { OpenAIEmbeddings } from \"@langchain/openai\";\n * import { PoolConfig } from \"pg\";\n *\n * const embeddings = new OpenAIEmbeddings({\n *   model: \"text-embedding-3-small\",\n * });\n *\n * // Sample config\n * const config = {\n *   postgresConnectionOptions: {\n *     type: \"postgres\",\n *     host: \"127.0.0.1\",\n *     port: 5433,\n *     user: \"myuser\",\n *     password: \"ChangeMe\",\n *     database: \"api\",\n *   } as PoolConfig,\n *   tableName: \"testlangchainjs\",\n *   columns: {\n *     idColumnName: \"id\",\n *     vectorColumnName: \"vector\",\n *     contentColumnName: \"content\",\n *     metadataColumnName: \"metadata\",\n *   },\n *   // supported distance strategies: cosine (default), innerProduct, or euclidean\n *   distanceStrategy: \"cosine\" as DistanceStrategy,\n * };\n *\n * const vectorStore = await PGVectorStore.initialize(embeddings, config);\n * ```\n * </details>\n *\n * <br />\n *\n * <details>\n * <summary><strong>Add documents</strong></summary>\n *\n * ```typescript\n * import type { Document } from '@langchain/core/documents';\n *\n * const document1 = { pageContent: \"foo\", metadata: { baz: \"bar\" } };\n * const document2 = { pageContent: \"thud\", metadata: { bar: \"baz\" } };\n * const document3 = { pageContent: \"i will be deleted :(\", metadata: {} };\n *\n * const documents: Document[] = [document1, document2, document3];\n * const ids = [\"1\", \"2\", \"3\"];\n * await vectorStore.addDocuments(documents, { ids });\n * ```\n * </details>\n *\n * <br />\n *\n * <details>\n * <summary><strong>Delete documents</strong></summary>\n *\n * ```typescript\n * await vectorStore.delete({ ids: [\"3\"] });\n * ```\n * </details>\n *\n * <br />\n *\n * <details>\n * <summary><strong>Similarity search</strong></summary>\n *\n * ```typescript\n * const results = await vectorStore.similaritySearch(\"thud\", 1);\n * for (const doc of results) {\n *   console.log(`* ${doc.pageContent} [${JSON.stringify(doc.metadata, null)}]`);\n * }\n * // Output: * thud [{\"baz\":\"bar\"}]\n * ```\n * </details>\n *\n * <br />\n *\n *\n * <details>\n * <summary><strong>Similarity search with filter</strong></summary>\n *\n * ```typescript\n * const resultsWithFilter = await vectorStore.similaritySearch(\"thud\", 1, { baz: \"bar\" });\n *\n * for (const doc of resultsWithFilter) {\n *   console.log(`* ${doc.pageContent} [${JSON.stringify(doc.metadata, null)}]`);\n * }\n * // Output: * foo [{\"baz\":\"bar\"}]\n * ```\n * </details>\n *\n * <br />\n *\n *\n * <details>\n * <summary><strong>Similarity search with score</strong></summary>\n *\n * ```typescript\n * const resultsWithScore = await vectorStore.similaritySearchWithScore(\"qux\", 1);\n * for (const [doc, score] of resultsWithScore) {\n *   console.log(`* [SIM=${score.toFixed(6)}] ${doc.pageContent} [${JSON.stringify(doc.metadata, null)}]`);\n * }\n * // Output: * [SIM=0.000000] qux [{\"bar\":\"baz\",\"baz\":\"bar\"}]\n * ```\n * </details>\n *\n * <br />\n *\n * <details>\n * <summary><strong>As a retriever</strong></summary>\n *\n * ```typescript\n * const retriever = vectorStore.asRetriever({\n *   searchType: \"mmr\", // Leave blank for standard similarity search\n *   k: 1,\n * });\n * const resultAsRetriever = await retriever.invoke(\"thud\");\n * console.log(resultAsRetriever);\n *\n * // Output: [Document({ metadata: { \"baz\":\"bar\" }, pageContent: \"thud\" })]\n * ```\n * </details>\n *\n * <br />\n */\nexport class PGVectorStore extends VectorStore {\n    _vectorstoreType() {\n        return \"pgvector\";\n    }\n    constructor(embeddings, config) {\n        super(embeddings, config);\n        Object.defineProperty(this, \"tableName\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"collectionTableName\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"collectionName\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: \"langchain\"\n        });\n        Object.defineProperty(this, \"collectionMetadata\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"schemaName\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"idColumnName\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"vectorColumnName\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"contentColumnName\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"extensionSchemaName\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"metadataColumnName\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"filter\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"_verbose\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"pool\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"client\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"chunkSize\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: 500\n        });\n        Object.defineProperty(this, \"distanceStrategy\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: \"cosine\"\n        });\n        this.tableName = config.tableName;\n        if (config.collectionName !== undefined &&\n            config.collectionTableName === undefined) {\n            throw new Error(`If supplying a \"collectionName\", you must also supply a \"collectionTableName\".`);\n        }\n        this.collectionTableName = config.collectionTableName;\n        this.collectionName = config.collectionName ?? \"langchain\";\n        this.collectionMetadata = config.collectionMetadata ?? null;\n        this.schemaName = config.schemaName ?? null;\n        this.extensionSchemaName = config.extensionSchemaName ?? null;\n        this.filter = config.filter;\n        this.vectorColumnName = config.columns?.vectorColumnName ?? \"embedding\";\n        this.contentColumnName = config.columns?.contentColumnName ?? \"text\";\n        this.idColumnName = config.columns?.idColumnName ?? \"id\";\n        this.metadataColumnName = config.columns?.metadataColumnName ?? \"metadata\";\n        if (!config.postgresConnectionOptions && !config.pool) {\n            throw new Error(\"You must provide either a `postgresConnectionOptions` object or a `pool` instance.\");\n        }\n        const pool = config.pool ?? new pg.Pool(config.postgresConnectionOptions);\n        this.pool = pool;\n        this.chunkSize = config.chunkSize ?? 500;\n        this.distanceStrategy = config.distanceStrategy ?? this.distanceStrategy;\n        const langchainVerbose = getEnvironmentVariable(\"LANGCHAIN_VERBOSE\");\n        if (langchainVerbose === \"true\") {\n            this._verbose = true;\n        }\n        else if (langchainVerbose === \"false\") {\n            this._verbose = false;\n        }\n        else {\n            this._verbose = config.verbose;\n        }\n    }\n    get computedTableName() {\n        return this.schemaName == null\n            ? `${this.tableName}`\n            : `\"${this.schemaName}\".\"${this.tableName}\"`;\n    }\n    get computedCollectionTableName() {\n        return this.schemaName == null\n            ? `${this.collectionTableName}`\n            : `\"${this.schemaName}\".\"${this.collectionTableName}\"`;\n    }\n    get computedOperatorString() {\n        let operator;\n        switch (this.distanceStrategy) {\n            case \"cosine\":\n                operator = \"<=>\";\n                break;\n            case \"innerProduct\":\n                operator = \"<#>\";\n                break;\n            case \"euclidean\":\n                operator = \"<->\";\n                break;\n            default:\n                throw new Error(`Unknown distance strategy: ${this.distanceStrategy}`);\n        }\n        return this.extensionSchemaName !== null\n            ? `OPERATOR(${this.extensionSchemaName}.${operator})`\n            : operator;\n    }\n    /**\n     * Static method to create a new `PGVectorStore` instance from a\n     * connection. It creates a table if one does not exist, and calls\n     * `connect` to return a new instance of `PGVectorStore`.\n     *\n     * @param embeddings - Embeddings instance.\n     * @param fields - `PGVectorStoreArgs` instance\n     * @param fields.dimensions Number of dimensions in your vector data type. For example, use 1536 for OpenAI's `text-embedding-3-small`. If not set, indexes like HNSW might not be used during query time.\n     * @returns A new instance of `PGVectorStore`.\n     */\n    static async initialize(embeddings, config) {\n        const { dimensions, ...rest } = config;\n        const postgresqlVectorStore = new PGVectorStore(embeddings, rest);\n        await postgresqlVectorStore._initializeClient();\n        await postgresqlVectorStore.ensureTableInDatabase(dimensions);\n        if (postgresqlVectorStore.collectionTableName) {\n            await postgresqlVectorStore.ensureCollectionTableInDatabase();\n        }\n        return postgresqlVectorStore;\n    }\n    async _initializeClient() {\n        this.client = await this.pool.connect();\n    }\n    /**\n     * Method to add documents to the vector store. It converts the documents into\n     * vectors, and adds them to the store.\n     *\n     * @param documents - Array of `Document` instances.\n     * @param options - Optional arguments for adding documents\n     * @returns Promise that resolves when the documents have been added.\n     */\n    async addDocuments(documents, options) {\n        const texts = documents.map(({ pageContent }) => pageContent);\n        return this.addVectors(await this.embeddings.embedDocuments(texts), documents, options);\n    }\n    /**\n     * Inserts a row for the collectionName provided at initialization if it does not\n     * exist and returns the collectionId.\n     *\n     * @returns The collectionId for the given collectionName.\n     */\n    async getOrCreateCollection() {\n        const queryString = `\n      SELECT uuid from ${this.computedCollectionTableName}\n      WHERE name = $1;\n    `;\n        const queryResult = await this.pool.query(queryString, [\n            this.collectionName,\n        ]);\n        let collectionId = queryResult.rows[0]?.uuid;\n        if (!collectionId) {\n            const insertString = `\n        INSERT INTO ${this.computedCollectionTableName}(\n          uuid,\n          name,\n          cmetadata\n        )\n        VALUES (\n          gen_random_uuid(),\n          $1,\n          $2\n        )\n        RETURNING uuid;\n      `;\n            const insertResult = await this.pool.query(insertString, [\n                this.collectionName,\n                this.collectionMetadata,\n            ]);\n            collectionId = insertResult.rows[0]?.uuid;\n        }\n        return collectionId;\n    }\n    /**\n     * Generates the SQL placeholders for a specific row at the provided index.\n     *\n     * @param index - The index of the row for which placeholders need to be generated.\n     * @param numOfColumns - The number of columns we are inserting data into.\n     * @returns The SQL placeholders for the row values.\n     */\n    generatePlaceholderForRowAt(index, numOfColumns) {\n        const placeholders = [];\n        for (let i = 0; i < numOfColumns; i += 1) {\n            placeholders.push(`$${index * numOfColumns + i + 1}`);\n        }\n        return `(${placeholders.join(\", \")})`;\n    }\n    /**\n     * Constructs the SQL query for inserting rows into the specified table.\n     *\n     * @param rows - The rows of data to be inserted, consisting of values and records.\n     * @returns The complete SQL INSERT INTO query string.\n     */\n    async buildInsertQuery(rows) {\n        let collectionId;\n        if (this.collectionTableName) {\n            collectionId = await this.getOrCreateCollection();\n        }\n        const columns = [\n            this.contentColumnName,\n            this.vectorColumnName,\n            this.metadataColumnName,\n        ];\n        if (collectionId) {\n            columns.push(\"collection_id\");\n        }\n        // Check if we have added ids to the rows.\n        if (rows.length !== 0 && columns.length === rows[0].length - 1) {\n            columns.push(this.idColumnName);\n        }\n        const valuesPlaceholders = rows\n            .map((_, j) => this.generatePlaceholderForRowAt(j, columns.length))\n            .join(\", \");\n        const text = `\n      INSERT INTO ${this.computedTableName}(\n        ${columns.map((column) => `\"${column}\"`).join(\", \")}\n      )\n      VALUES ${valuesPlaceholders}\n    `;\n        return text;\n    }\n    /**\n     * Method to add vectors to the vector store. It converts the vectors into\n     * rows and inserts them into the database.\n     *\n     * @param vectors - Array of vectors.\n     * @param documents - Array of `Document` instances.\n     * @param options - Optional arguments for adding documents\n     * @returns Promise that resolves when the vectors have been added.\n     */\n    async addVectors(vectors, documents, options) {\n        const ids = options?.ids;\n        // Either all documents have ids or none of them do to avoid confusion.\n        if (ids !== undefined && ids.length !== vectors.length) {\n            throw new Error(\"The number of ids must match the number of vectors provided.\");\n        }\n        const rows = [];\n        let collectionId;\n        if (this.collectionTableName) {\n            collectionId = await this.getOrCreateCollection();\n        }\n        for (let i = 0; i < vectors.length; i += 1) {\n            const values = [];\n            const embedding = vectors[i];\n            const embeddingString = `[${embedding.join(\",\")}]`;\n            values.push(documents[i].pageContent.replace(/\\0/g, \"\"), embeddingString.replace(/\\0/g, \"\"), documents[i].metadata);\n            if (collectionId) {\n                values.push(collectionId);\n            }\n            if (ids) {\n                values.push(ids[i]);\n            }\n            rows.push(values);\n        }\n        for (let i = 0; i < rows.length; i += this.chunkSize) {\n            const chunk = rows.slice(i, i + this.chunkSize);\n            const insertQuery = await this.buildInsertQuery(chunk);\n            const flatValues = chunk.flat();\n            try {\n                await this.pool.query(insertQuery, flatValues);\n            }\n            catch (e) {\n                console.error(e);\n                throw new Error(`Error inserting: ${e.message}`);\n            }\n        }\n    }\n    /**\n     * Method to delete documents from the vector store. It deletes the\n     * documents that match the provided ids.\n     *\n     * @param ids - Array of document ids.\n     * @returns Promise that resolves when the documents have been deleted.\n     */\n    async deleteById(ids) {\n        let collectionId;\n        if (this.collectionTableName) {\n            collectionId = await this.getOrCreateCollection();\n        }\n        // Set parameters of dynamically generated query\n        const params = collectionId ? [ids, collectionId] : [ids];\n        const queryString = `\n      DELETE FROM ${this.computedTableName}\n      WHERE ${collectionId ? \"collection_id = $2 AND \" : \"\"}${this.idColumnName} = ANY($1::uuid[])\n    `;\n        await this.pool.query(queryString, params);\n    }\n    /**\n     * Method to delete documents from the vector store. It deletes the\n     * documents whose metadata contains the filter.\n     *\n     * @param filter - An object representing the Metadata filter.\n     * @returns Promise that resolves when the documents have been deleted.\n     */\n    async deleteByFilter(filter) {\n        let collectionId;\n        if (this.collectionTableName) {\n            collectionId = await this.getOrCreateCollection();\n        }\n        // Set parameters of dynamically generated query\n        const params = collectionId ? [filter, collectionId] : [filter];\n        const queryString = `\n      DELETE FROM ${this.computedTableName}\n      WHERE ${collectionId ? \"collection_id = $2 AND \" : \"\"}${this.metadataColumnName}::jsonb @> $1\n    `;\n        return await this.pool.query(queryString, params);\n    }\n    /**\n     * Method to delete documents from the vector store. It deletes the\n     * documents that match the provided ids or metadata filter. Matches ids\n     * exactly and metadata filter according to postgres jsonb containment. Ids and filter\n     * are mutually exclusive.\n     *\n     * @param params - Object containing either an array of ids or a metadata filter object.\n     * @returns Promise that resolves when the documents have been deleted.\n     * @throws Error if neither ids nor filter are provided, or if both are provided.\n     * @example <caption>Delete by ids</caption>\n     * await vectorStore.delete({ ids: [\"id1\", \"id2\"] });\n     * @example <caption>Delete by filter</caption>\n     * await vectorStore.delete({ filter: { a: 1, b: 2 } });\n     */\n    async delete(params) {\n        const { ids, filter } = params;\n        if (!(ids || filter)) {\n            throw new Error(\"You must specify either ids or a filter when deleting documents.\");\n        }\n        if (ids && filter) {\n            throw new Error(\"You cannot specify both ids and a filter when deleting documents.\");\n        }\n        if (ids) {\n            await this.deleteById(ids);\n        }\n        else if (filter) {\n            await this.deleteByFilter(filter);\n        }\n    }\n    /**\n     * Method to perform a similarity search in the vector store. It returns the `k` most similar documents to the query text.\n     * @param query - Query vector.\n     * @param k - Number of most similar documents to return.\n     * @param filter - Optional filter to apply to the search.\n     * @param includeEmbedding Whether to include the embedding vectors in the results.\n     * @returns Promise that resolves with an array of tuples, each containing a `Document` and its similarity score.\n     */\n    async searchPostgres(query, k, filter, includeEmbedding) {\n        const embeddingString = `[${query.join(\",\")}]`;\n        const _filter = filter ?? {};\n        let collectionId;\n        if (this.collectionTableName) {\n            collectionId = await this.getOrCreateCollection();\n        }\n        // eslint-disable-next-line @typescript-eslint/no-explicit-any\n        const parameters = [embeddingString, k];\n        const whereClauses = [];\n        if (collectionId) {\n            whereClauses.push(\"collection_id = $3\");\n            parameters.push(collectionId);\n        }\n        let paramCount = parameters.length;\n        for (const [key, value] of Object.entries(_filter)) {\n            if (typeof value === \"object\" && value !== null) {\n                // eslint-disable-next-line @typescript-eslint/no-explicit-any\n                const _value = value;\n                const currentParamCount = paramCount;\n                if (Array.isArray(_value.in)) {\n                    const placeholders = _value.in\n                        .map((_, index) => `$${currentParamCount + index + 1}`)\n                        .join(\",\");\n                    whereClauses.push(`${this.metadataColumnName}->>'${key}' IN (${placeholders})`);\n                    parameters.push(..._value.in);\n                    paramCount += _value.in.length;\n                }\n                if (Array.isArray(_value.arrayContains)) {\n                    const placeholders = _value.arrayContains\n                        .map((_, index) => `$${currentParamCount + index + 1}`)\n                        .join(\",\");\n                    whereClauses.push(`${this.metadataColumnName}->'${key}' ?| array[${placeholders}]`);\n                    parameters.push(..._value.arrayContains);\n                    paramCount += _value.arrayContains.length;\n                }\n            }\n            else {\n                paramCount += 1;\n                whereClauses.push(`${this.metadataColumnName}->>'${key}' = $${paramCount}`);\n                parameters.push(value);\n            }\n        }\n        const whereClause = whereClauses.length\n            ? `WHERE ${whereClauses.join(\" AND \")}`\n            : \"\";\n        const queryString = `\n      SELECT *, \"${this.vectorColumnName}\" ${this.computedOperatorString} $1 as \"_distance\"\n      FROM ${this.computedTableName}\n      ${whereClause}\n      ORDER BY \"_distance\" ASC\n      LIMIT $2;\n      `;\n        const documents = (await this.pool.query(queryString, parameters)).rows;\n        const results = [];\n        for (const doc of documents) {\n            if (doc._distance != null && doc[this.contentColumnName] != null) {\n                const document = new Document({\n                    pageContent: doc[this.contentColumnName],\n                    metadata: doc[this.metadataColumnName],\n                    id: doc[this.idColumnName],\n                });\n                if (includeEmbedding) {\n                    document.metadata[this.vectorColumnName] = doc[this.vectorColumnName];\n                }\n                results.push([document, doc._distance]);\n            }\n        }\n        return results;\n    }\n    /**\n     * Method to perform a similarity search in the vector store. It returns\n     * the `k` most similar documents to the query vector, along with their\n     * similarity scores.\n     * @param query - Query vector.\n     * @param k - Number of most similar documents to return.\n     * @param filter - Optional filter to apply to the search.\n     * @returns Promise that resolves with an array of tuples, each containing a `Document` and its similarity score.\n     */\n    async similaritySearchVectorWithScore(query, k, filter) {\n        return this.searchPostgres(query, k, filter, false);\n    }\n    /**\n     * Method to ensure the existence of the table in the database. It creates\n     * the table if it does not already exist.\n     * @param dimensions Number of dimensions in your vector data type. For example, use 1536 for OpenAI's `text-embedding-3-small`. If not set, indexes like HNSW might not be used during query time.\n     * @returns Promise that resolves when the table has been ensured.\n     */\n    async ensureTableInDatabase(dimensions) {\n        const vectorQuery = this.extensionSchemaName == null\n            ? \"CREATE EXTENSION IF NOT EXISTS vector;\"\n            : `CREATE EXTENSION IF NOT EXISTS vector WITH SCHEMA \"${this.extensionSchemaName}\";`;\n        const extensionName = this.extensionSchemaName == null\n            ? \"vector\"\n            : `\"${this.extensionSchemaName}\".\"vector\"`;\n        const vectorColumnType = dimensions\n            ? `${extensionName}(${dimensions})`\n            : extensionName;\n        const tableQuery = `\n      CREATE TABLE IF NOT EXISTS ${this.computedTableName} (\n        \"${this.idColumnName}\" uuid NOT NULL DEFAULT gen_random_uuid() PRIMARY KEY,\n        \"${this.contentColumnName}\" text,\n        \"${this.metadataColumnName}\" jsonb,\n        \"${this.vectorColumnName}\" ${vectorColumnType}\n      );\n    `;\n        await this.pool.query(vectorQuery);\n        await this.pool.query(tableQuery);\n    }\n    /**\n     * Method to ensure the existence of the collection table in the database.\n     * It creates the table if it does not already exist.\n     *\n     * @returns Promise that resolves when the collection table has been ensured.\n     */\n    async ensureCollectionTableInDatabase() {\n        try {\n            const queryString = `\n        CREATE TABLE IF NOT EXISTS ${this.computedCollectionTableName} (\n          uuid uuid NOT NULL DEFAULT gen_random_uuid() PRIMARY KEY,\n          name character varying,\n          cmetadata jsonb\n        );\n\n        CREATE INDEX IF NOT EXISTS idx_${this.collectionTableName}_name ON ${this.computedCollectionTableName}(name);\n\n        ALTER TABLE ${this.computedTableName}\n          ADD COLUMN collection_id uuid;\n\n        ALTER TABLE ${this.computedTableName}\n          ADD CONSTRAINT ${this.tableName}_collection_id_fkey\n          FOREIGN KEY (collection_id)\n          REFERENCES ${this.computedCollectionTableName}(uuid)\n          ON DELETE CASCADE;\n      `;\n            await this.pool.query(queryString);\n        }\n        catch (e) {\n            if (!e.message.includes(\"already exists\")) {\n                console.error(e);\n                throw new Error(`Error adding column or creating index: ${e.message}`);\n            }\n        }\n    }\n    /**\n     * Static method to create a new `PGVectorStore` instance from an\n     * array of texts and their metadata. It converts the texts into\n     * `Document` instances and adds them to the store.\n     *\n     * @param texts - Array of texts.\n     * @param metadatas - Array of metadata objects or a single metadata object.\n     * @param embeddings - Embeddings instance.\n     * @param dbConfig - `PGVectorStoreArgs` instance.\n     * @returns Promise that resolves with a new instance of `PGVectorStore`.\n     */\n    static async fromTexts(texts, metadatas, embeddings, dbConfig) {\n        const docs = [];\n        for (let i = 0; i < texts.length; i += 1) {\n            const metadata = Array.isArray(metadatas) ? metadatas[i] : metadatas;\n            const newDoc = new Document({\n                pageContent: texts[i],\n                metadata,\n            });\n            docs.push(newDoc);\n        }\n        return PGVectorStore.fromDocuments(docs, embeddings, dbConfig);\n    }\n    /**\n     * Static method to create a new `PGVectorStore` instance from an\n     * array of `Document` instances. It adds the documents to the store.\n     *\n     * @param docs - Array of `Document` instances.\n     * @param embeddings - Embeddings instance.\n     * @param dbConfig - `PGVectorStoreArgs` instance.\n     * @returns Promise that resolves with a new instance of `PGVectorStore`.\n     */\n    static async fromDocuments(docs, embeddings, dbConfig) {\n        const instance = await PGVectorStore.initialize(embeddings, dbConfig);\n        await instance.addDocuments(docs, { ids: dbConfig.ids });\n        return instance;\n    }\n    /**\n     * Closes all the clients in the pool and terminates the pool.\n     *\n     * @returns Promise that resolves when all clients are closed and the pool is terminated.\n     */\n    async end() {\n        this.client?.release();\n        return this.pool.end();\n    }\n    /**\n     * Method to create the HNSW index on the vector column.\n     *\n     * @param dimensions - Defines the number of dimensions in your vector data type, up to 2000. For example, use 1536 for OpenAI's text-embedding-ada-002 and Amazon's amazon.titan-embed-text-v1 models.\n     * @param m - The max number of connections per layer (16 by default). Index build time improves with smaller values, while higher values can speed up search queries.\n     * @param efConstruction -  The size of the dynamic candidate list for constructing the graph (64 by default). A higher value can potentially improve the index quality at the cost of index build time.\n     * @param distanceFunction -  The distance function name you want to use, is automatically selected based on the distanceStrategy.\n     * @param namespace -  The namespace is used to create the index with a specific name. This is useful when you want to create multiple indexes on the same database schema (within the same schema in PostgreSQL, the index name must be unique across all tables).\n     * @returns Promise that resolves with the query response of creating the index.\n     */\n    async createHnswIndex(config) {\n        let idxDistanceFunction = config?.distanceFunction || \"vector_cosine_ops\";\n        const prefix = config?.namespace ? `${config.namespace}_` : \"\";\n        switch (this.distanceStrategy) {\n            case \"cosine\":\n                idxDistanceFunction = \"vector_cosine_ops\";\n                break;\n            case \"innerProduct\":\n                idxDistanceFunction = \"vector_ip_ops\";\n                break;\n            case \"euclidean\":\n                idxDistanceFunction = \"vector_l2_ops\";\n                break;\n            default:\n                throw new Error(`Unknown distance strategy: ${this.distanceStrategy}`);\n        }\n        const createIndexQuery = `CREATE INDEX IF NOT EXISTS ${prefix}${this.vectorColumnName}_embedding_hnsw_idx\n        ON ${this.computedTableName} USING hnsw ((${this.vectorColumnName}::vector(${config.dimensions})) ${idxDistanceFunction})\n        WITH (\n            m=${config?.m || 16},\n            ef_construction=${config?.efConstruction || 64}\n        );`;\n        try {\n            await this.pool.query(createIndexQuery);\n        }\n        catch (e) {\n            console.error(`Failed to create HNSW index on table ${this.computedTableName}, error: ${e}`);\n        }\n    }\n    /**\n     * Return documents selected using the maximal marginal relevance.\n     * Maximal marginal relevance optimizes for similarity to the query AND\n     * diversity among selected documents.\n     * @param query Text to look up documents similar to.\n     * @param options.k=4 Number of documents to return.\n     * @param options.fetchK=20 Number of documents to fetch before passing to\n     *     the MMR algorithm.\n     * @param options.lambda=0.5 Number between 0 and 1 that determines the\n     *     degree of diversity among the results, where 0 corresponds to maximum\n     *     diversity and 1 to minimum diversity.\n     * @returns List of documents selected by maximal marginal relevance.\n     */\n    async maxMarginalRelevanceSearch(query, options) {\n        const { k = 4, fetchK = 20, lambda = 0.5, filter } = options;\n        const queryEmbedding = await this.embeddings.embedQuery(query);\n        const docs = await this.searchPostgres(queryEmbedding, fetchK, filter, true);\n        const embeddingList = docs.map((doc) => JSON.parse(doc[0].metadata[this.vectorColumnName]));\n        const mmrIndexes = maximalMarginalRelevance(queryEmbedding, embeddingList, lambda, k);\n        const mmrDocs = mmrIndexes.map((index) => {\n            const doc = docs[index][0];\n            delete doc.metadata[this.vectorColumnName];\n            return docs[index][0];\n        });\n        return mmrDocs;\n    }\n}\n"],"names":[],"mappings":";;;AAAA;AACA;AAAA;AACA;AAAA;AACA;AAAA;AACA;AAAA;;;;;;;;;;AAqJO,MAAM,sBAAsB,6JAAA,CAAA,cAAW;IAC1C,mBAAmB;QACf,OAAO;IACX;IACA,YAAY,UAAU,EAAE,MAAM,CAAE;QAC5B,KAAK,CAAC,YAAY;QAClB,OAAO,cAAc,CAAC,IAAI,EAAE,aAAa;YACrC,YAAY;YACZ,cAAc;YACd,UAAU;YACV,OAAO,KAAK;QAChB;QACA,OAAO,cAAc,CAAC,IAAI,EAAE,uBAAuB;YAC/C,YAAY;YACZ,cAAc;YACd,UAAU;YACV,OAAO,KAAK;QAChB;QACA,OAAO,cAAc,CAAC,IAAI,EAAE,kBAAkB;YAC1C,YAAY;YACZ,cAAc;YACd,UAAU;YACV,OAAO;QACX;QACA,OAAO,cAAc,CAAC,IAAI,EAAE,sBAAsB;YAC9C,YAAY;YACZ,cAAc;YACd,UAAU;YACV,OAAO,KAAK;QAChB;QACA,OAAO,cAAc,CAAC,IAAI,EAAE,cAAc;YACtC,YAAY;YACZ,cAAc;YACd,UAAU;YACV,OAAO,KAAK;QAChB;QACA,OAAO,cAAc,CAAC,IAAI,EAAE,gBAAgB;YACxC,YAAY;YACZ,cAAc;YACd,UAAU;YACV,OAAO,KAAK;QAChB;QACA,OAAO,cAAc,CAAC,IAAI,EAAE,oBAAoB;YAC5C,YAAY;YACZ,cAAc;YACd,UAAU;YACV,OAAO,KAAK;QAChB;QACA,OAAO,cAAc,CAAC,IAAI,EAAE,qBAAqB;YAC7C,YAAY;YACZ,cAAc;YACd,UAAU;YACV,OAAO,KAAK;QAChB;QACA,OAAO,cAAc,CAAC,IAAI,EAAE,uBAAuB;YAC/C,YAAY;YACZ,cAAc;YACd,UAAU;YACV,OAAO,KAAK;QAChB;QACA,OAAO,cAAc,CAAC,IAAI,EAAE,sBAAsB;YAC9C,YAAY;YACZ,cAAc;YACd,UAAU;YACV,OAAO,KAAK;QAChB;QACA,OAAO,cAAc,CAAC,IAAI,EAAE,UAAU;YAClC,YAAY;YACZ,cAAc;YACd,UAAU;YACV,OAAO,KAAK;QAChB;QACA,OAAO,cAAc,CAAC,IAAI,EAAE,YAAY;YACpC,YAAY;YACZ,cAAc;YACd,UAAU;YACV,OAAO,KAAK;QAChB;QACA,OAAO,cAAc,CAAC,IAAI,EAAE,QAAQ;YAChC,YAAY;YACZ,cAAc;YACd,UAAU;YACV,OAAO,KAAK;QAChB;QACA,OAAO,cAAc,CAAC,IAAI,EAAE,UAAU;YAClC,YAAY;YACZ,cAAc;YACd,UAAU;YACV,OAAO,KAAK;QAChB;QACA,OAAO,cAAc,CAAC,IAAI,EAAE,aAAa;YACrC,YAAY;YACZ,cAAc;YACd,UAAU;YACV,OAAO;QACX;QACA,OAAO,cAAc,CAAC,IAAI,EAAE,oBAAoB;YAC5C,YAAY;YACZ,cAAc;YACd,UAAU;YACV,OAAO;QACX;QACA,IAAI,CAAC,SAAS,GAAG,OAAO,SAAS;QACjC,IAAI,OAAO,cAAc,KAAK,aAC1B,OAAO,mBAAmB,KAAK,WAAW;YAC1C,MAAM,IAAI,MAAM,CAAC,8EAA8E,CAAC;QACpG;QACA,IAAI,CAAC,mBAAmB,GAAG,OAAO,mBAAmB;QACrD,IAAI,CAAC,cAAc,GAAG,OAAO,cAAc,IAAI;QAC/C,IAAI,CAAC,kBAAkB,GAAG,OAAO,kBAAkB,IAAI;QACvD,IAAI,CAAC,UAAU,GAAG,OAAO,UAAU,IAAI;QACvC,IAAI,CAAC,mBAAmB,GAAG,OAAO,mBAAmB,IAAI;QACzD,IAAI,CAAC,MAAM,GAAG,OAAO,MAAM;QAC3B,IAAI,CAAC,gBAAgB,GAAG,OAAO,OAAO,EAAE,oBAAoB;QAC5D,IAAI,CAAC,iBAAiB,GAAG,OAAO,OAAO,EAAE,qBAAqB;QAC9D,IAAI,CAAC,YAAY,GAAG,OAAO,OAAO,EAAE,gBAAgB;QACpD,IAAI,CAAC,kBAAkB,GAAG,OAAO,OAAO,EAAE,sBAAsB;QAChE,IAAI,CAAC,OAAO,yBAAyB,IAAI,CAAC,OAAO,IAAI,EAAE;YACnD,MAAM,IAAI,MAAM;QACpB;QACA,MAAM,OAAO,OAAO,IAAI,IAAI,IAAI,oGAAA,CAAA,UAAE,CAAC,IAAI,CAAC,OAAO,yBAAyB;QACxE,IAAI,CAAC,IAAI,GAAG;QACZ,IAAI,CAAC,SAAS,GAAG,OAAO,SAAS,IAAI;QACrC,IAAI,CAAC,gBAAgB,GAAG,OAAO,gBAAgB,IAAI,IAAI,CAAC,gBAAgB;QACxE,MAAM,mBAAmB,CAAA,GAAA,6JAAA,CAAA,yBAAsB,AAAD,EAAE;QAChD,IAAI,qBAAqB,QAAQ;YAC7B,IAAI,CAAC,QAAQ,GAAG;QACpB,OACK,IAAI,qBAAqB,SAAS;YACnC,IAAI,CAAC,QAAQ,GAAG;QACpB,OACK;YACD,IAAI,CAAC,QAAQ,GAAG,OAAO,OAAO;QAClC;IACJ;IACA,IAAI,oBAAoB;QACpB,OAAO,IAAI,CAAC,UAAU,IAAI,OACpB,GAAG,IAAI,CAAC,SAAS,EAAE,GACnB,CAAC,CAAC,EAAE,IAAI,CAAC,UAAU,CAAC,GAAG,EAAE,IAAI,CAAC,SAAS,CAAC,CAAC,CAAC;IACpD;IACA,IAAI,8BAA8B;QAC9B,OAAO,IAAI,CAAC,UAAU,IAAI,OACpB,GAAG,IAAI,CAAC,mBAAmB,EAAE,GAC7B,CAAC,CAAC,EAAE,IAAI,CAAC,UAAU,CAAC,GAAG,EAAE,IAAI,CAAC,mBAAmB,CAAC,CAAC,CAAC;IAC9D;IACA,IAAI,yBAAyB;QACzB,IAAI;QACJ,OAAQ,IAAI,CAAC,gBAAgB;YACzB,KAAK;gBACD,WAAW;gBACX;YACJ,KAAK;gBACD,WAAW;gBACX;YACJ,KAAK;gBACD,WAAW;gBACX;YACJ;gBACI,MAAM,IAAI,MAAM,CAAC,2BAA2B,EAAE,IAAI,CAAC,gBAAgB,EAAE;QAC7E;QACA,OAAO,IAAI,CAAC,mBAAmB,KAAK,OAC9B,CAAC,SAAS,EAAE,IAAI,CAAC,mBAAmB,CAAC,CAAC,EAAE,SAAS,CAAC,CAAC,GACnD;IACV;IACA;;;;;;;;;KASC,GACD,aAAa,WAAW,UAAU,EAAE,MAAM,EAAE;QACxC,MAAM,EAAE,UAAU,EAAE,GAAG,MAAM,GAAG;QAChC,MAAM,wBAAwB,IAAI,cAAc,YAAY;QAC5D,MAAM,sBAAsB,iBAAiB;QAC7C,MAAM,sBAAsB,qBAAqB,CAAC;QAClD,IAAI,sBAAsB,mBAAmB,EAAE;YAC3C,MAAM,sBAAsB,+BAA+B;QAC/D;QACA,OAAO;IACX;IACA,MAAM,oBAAoB;QACtB,IAAI,CAAC,MAAM,GAAG,MAAM,IAAI,CAAC,IAAI,CAAC,OAAO;IACzC;IACA;;;;;;;KAOC,GACD,MAAM,aAAa,SAAS,EAAE,OAAO,EAAE;QACnC,MAAM,QAAQ,UAAU,GAAG,CAAC,CAAC,EAAE,WAAW,EAAE,GAAK;QACjD,OAAO,IAAI,CAAC,UAAU,CAAC,MAAM,IAAI,CAAC,UAAU,CAAC,cAAc,CAAC,QAAQ,WAAW;IACnF;IACA;;;;;KAKC,GACD,MAAM,wBAAwB;QAC1B,MAAM,cAAc,CAAC;uBACN,EAAE,IAAI,CAAC,2BAA2B,CAAC;;IAEtD,CAAC;QACG,MAAM,cAAc,MAAM,IAAI,CAAC,IAAI,CAAC,KAAK,CAAC,aAAa;YACnD,IAAI,CAAC,cAAc;SACtB;QACD,IAAI,eAAe,YAAY,IAAI,CAAC,EAAE,EAAE;QACxC,IAAI,CAAC,cAAc;YACf,MAAM,eAAe,CAAC;oBACd,EAAE,IAAI,CAAC,2BAA2B,CAAC;;;;;;;;;;;MAWjD,CAAC;YACK,MAAM,eAAe,MAAM,IAAI,CAAC,IAAI,CAAC,KAAK,CAAC,cAAc;gBACrD,IAAI,CAAC,cAAc;gBACnB,IAAI,CAAC,kBAAkB;aAC1B;YACD,eAAe,aAAa,IAAI,CAAC,EAAE,EAAE;QACzC;QACA,OAAO;IACX;IACA;;;;;;KAMC,GACD,4BAA4B,KAAK,EAAE,YAAY,EAAE;QAC7C,MAAM,eAAe,EAAE;QACvB,IAAK,IAAI,IAAI,GAAG,IAAI,cAAc,KAAK,EAAG;YACtC,aAAa,IAAI,CAAC,CAAC,CAAC,EAAE,QAAQ,eAAe,IAAI,GAAG;QACxD;QACA,OAAO,CAAC,CAAC,EAAE,aAAa,IAAI,CAAC,MAAM,CAAC,CAAC;IACzC;IACA;;;;;KAKC,GACD,MAAM,iBAAiB,IAAI,EAAE;QACzB,IAAI;QACJ,IAAI,IAAI,CAAC,mBAAmB,EAAE;YAC1B,eAAe,MAAM,IAAI,CAAC,qBAAqB;QACnD;QACA,MAAM,UAAU;YACZ,IAAI,CAAC,iBAAiB;YACtB,IAAI,CAAC,gBAAgB;YACrB,IAAI,CAAC,kBAAkB;SAC1B;QACD,IAAI,cAAc;YACd,QAAQ,IAAI,CAAC;QACjB;QACA,0CAA0C;QAC1C,IAAI,KAAK,MAAM,KAAK,KAAK,QAAQ,MAAM,KAAK,IAAI,CAAC,EAAE,CAAC,MAAM,GAAG,GAAG;YAC5D,QAAQ,IAAI,CAAC,IAAI,CAAC,YAAY;QAClC;QACA,MAAM,qBAAqB,KACtB,GAAG,CAAC,CAAC,GAAG,IAAM,IAAI,CAAC,2BAA2B,CAAC,GAAG,QAAQ,MAAM,GAChE,IAAI,CAAC;QACV,MAAM,OAAO,CAAC;kBACJ,EAAE,IAAI,CAAC,iBAAiB,CAAC;QACnC,EAAE,QAAQ,GAAG,CAAC,CAAC,SAAW,CAAC,CAAC,EAAE,OAAO,CAAC,CAAC,EAAE,IAAI,CAAC,MAAM;;aAE/C,EAAE,mBAAmB;IAC9B,CAAC;QACG,OAAO;IACX;IACA;;;;;;;;KAQC,GACD,MAAM,WAAW,OAAO,EAAE,SAAS,EAAE,OAAO,EAAE;QAC1C,MAAM,MAAM,SAAS;QACrB,uEAAuE;QACvE,IAAI,QAAQ,aAAa,IAAI,MAAM,KAAK,QAAQ,MAAM,EAAE;YACpD,MAAM,IAAI,MAAM;QACpB;QACA,MAAM,OAAO,EAAE;QACf,IAAI;QACJ,IAAI,IAAI,CAAC,mBAAmB,EAAE;YAC1B,eAAe,MAAM,IAAI,CAAC,qBAAqB;QACnD;QACA,IAAK,IAAI,IAAI,GAAG,IAAI,QAAQ,MAAM,EAAE,KAAK,EAAG;YACxC,MAAM,SAAS,EAAE;YACjB,MAAM,YAAY,OAAO,CAAC,EAAE;YAC5B,MAAM,kBAAkB,CAAC,CAAC,EAAE,UAAU,IAAI,CAAC,KAAK,CAAC,CAAC;YAClD,OAAO,IAAI,CAAC,SAAS,CAAC,EAAE,CAAC,WAAW,CAAC,OAAO,CAAC,OAAO,KAAK,gBAAgB,OAAO,CAAC,OAAO,KAAK,SAAS,CAAC,EAAE,CAAC,QAAQ;YAClH,IAAI,cAAc;gBACd,OAAO,IAAI,CAAC;YAChB;YACA,IAAI,KAAK;gBACL,OAAO,IAAI,CAAC,GAAG,CAAC,EAAE;YACtB;YACA,KAAK,IAAI,CAAC;QACd;QACA,IAAK,IAAI,IAAI,GAAG,IAAI,KAAK,MAAM,EAAE,KAAK,IAAI,CAAC,SAAS,CAAE;YAClD,MAAM,QAAQ,KAAK,KAAK,CAAC,GAAG,IAAI,IAAI,CAAC,SAAS;YAC9C,MAAM,cAAc,MAAM,IAAI,CAAC,gBAAgB,CAAC;YAChD,MAAM,aAAa,MAAM,IAAI;YAC7B,IAAI;gBACA,MAAM,IAAI,CAAC,IAAI,CAAC,KAAK,CAAC,aAAa;YACvC,EACA,OAAO,GAAG;gBACN,QAAQ,KAAK,CAAC;gBACd,MAAM,IAAI,MAAM,CAAC,iBAAiB,EAAE,EAAE,OAAO,EAAE;YACnD;QACJ;IACJ;IACA;;;;;;KAMC,GACD,MAAM,WAAW,GAAG,EAAE;QAClB,IAAI;QACJ,IAAI,IAAI,CAAC,mBAAmB,EAAE;YAC1B,eAAe,MAAM,IAAI,CAAC,qBAAqB;QACnD;QACA,gDAAgD;QAChD,MAAM,SAAS,eAAe;YAAC;YAAK;SAAa,GAAG;YAAC;SAAI;QACzD,MAAM,cAAc,CAAC;kBACX,EAAE,IAAI,CAAC,iBAAiB,CAAC;YAC/B,EAAE,eAAe,4BAA4B,KAAK,IAAI,CAAC,YAAY,CAAC;IAC5E,CAAC;QACG,MAAM,IAAI,CAAC,IAAI,CAAC,KAAK,CAAC,aAAa;IACvC;IACA;;;;;;KAMC,GACD,MAAM,eAAe,MAAM,EAAE;QACzB,IAAI;QACJ,IAAI,IAAI,CAAC,mBAAmB,EAAE;YAC1B,eAAe,MAAM,IAAI,CAAC,qBAAqB;QACnD;QACA,gDAAgD;QAChD,MAAM,SAAS,eAAe;YAAC;YAAQ;SAAa,GAAG;YAAC;SAAO;QAC/D,MAAM,cAAc,CAAC;kBACX,EAAE,IAAI,CAAC,iBAAiB,CAAC;YAC/B,EAAE,eAAe,4BAA4B,KAAK,IAAI,CAAC,kBAAkB,CAAC;IAClF,CAAC;QACG,OAAO,MAAM,IAAI,CAAC,IAAI,CAAC,KAAK,CAAC,aAAa;IAC9C;IACA;;;;;;;;;;;;;KAaC,GACD,MAAM,OAAO,MAAM,EAAE;QACjB,MAAM,EAAE,GAAG,EAAE,MAAM,EAAE,GAAG;QACxB,IAAI,CAAC,CAAC,OAAO,MAAM,GAAG;YAClB,MAAM,IAAI,MAAM;QACpB;QACA,IAAI,OAAO,QAAQ;YACf,MAAM,IAAI,MAAM;QACpB;QACA,IAAI,KAAK;YACL,MAAM,IAAI,CAAC,UAAU,CAAC;QAC1B,OACK,IAAI,QAAQ;YACb,MAAM,IAAI,CAAC,cAAc,CAAC;QAC9B;IACJ;IACA;;;;;;;KAOC,GACD,MAAM,eAAe,KAAK,EAAE,CAAC,EAAE,MAAM,EAAE,gBAAgB,EAAE;QACrD,MAAM,kBAAkB,CAAC,CAAC,EAAE,MAAM,IAAI,CAAC,KAAK,CAAC,CAAC;QAC9C,MAAM,UAAU,UAAU,CAAC;QAC3B,IAAI;QACJ,IAAI,IAAI,CAAC,mBAAmB,EAAE;YAC1B,eAAe,MAAM,IAAI,CAAC,qBAAqB;QACnD;QACA,8DAA8D;QAC9D,MAAM,aAAa;YAAC;YAAiB;SAAE;QACvC,MAAM,eAAe,EAAE;QACvB,IAAI,cAAc;YACd,aAAa,IAAI,CAAC;YAClB,WAAW,IAAI,CAAC;QACpB;QACA,IAAI,aAAa,WAAW,MAAM;QAClC,KAAK,MAAM,CAAC,KAAK,MAAM,IAAI,OAAO,OAAO,CAAC,SAAU;YAChD,IAAI,OAAO,UAAU,YAAY,UAAU,MAAM;gBAC7C,8DAA8D;gBAC9D,MAAM,SAAS;gBACf,MAAM,oBAAoB;gBAC1B,IAAI,MAAM,OAAO,CAAC,OAAO,EAAE,GAAG;oBAC1B,MAAM,eAAe,OAAO,EAAE,CACzB,GAAG,CAAC,CAAC,GAAG,QAAU,CAAC,CAAC,EAAE,oBAAoB,QAAQ,GAAG,EACrD,IAAI,CAAC;oBACV,aAAa,IAAI,CAAC,GAAG,IAAI,CAAC,kBAAkB,CAAC,IAAI,EAAE,IAAI,MAAM,EAAE,aAAa,CAAC,CAAC;oBAC9E,WAAW,IAAI,IAAI,OAAO,EAAE;oBAC5B,cAAc,OAAO,EAAE,CAAC,MAAM;gBAClC;gBACA,IAAI,MAAM,OAAO,CAAC,OAAO,aAAa,GAAG;oBACrC,MAAM,eAAe,OAAO,aAAa,CACpC,GAAG,CAAC,CAAC,GAAG,QAAU,CAAC,CAAC,EAAE,oBAAoB,QAAQ,GAAG,EACrD,IAAI,CAAC;oBACV,aAAa,IAAI,CAAC,GAAG,IAAI,CAAC,kBAAkB,CAAC,GAAG,EAAE,IAAI,WAAW,EAAE,aAAa,CAAC,CAAC;oBAClF,WAAW,IAAI,IAAI,OAAO,aAAa;oBACvC,cAAc,OAAO,aAAa,CAAC,MAAM;gBAC7C;YACJ,OACK;gBACD,cAAc;gBACd,aAAa,IAAI,CAAC,GAAG,IAAI,CAAC,kBAAkB,CAAC,IAAI,EAAE,IAAI,KAAK,EAAE,YAAY;gBAC1E,WAAW,IAAI,CAAC;YACpB;QACJ;QACA,MAAM,cAAc,aAAa,MAAM,GACjC,CAAC,MAAM,EAAE,aAAa,IAAI,CAAC,UAAU,GACrC;QACN,MAAM,cAAc,CAAC;iBACZ,EAAE,IAAI,CAAC,gBAAgB,CAAC,EAAE,EAAE,IAAI,CAAC,sBAAsB,CAAC;WAC9D,EAAE,IAAI,CAAC,iBAAiB,CAAC;MAC9B,EAAE,YAAY;;;MAGd,CAAC;QACC,MAAM,YAAY,CAAC,MAAM,IAAI,CAAC,IAAI,CAAC,KAAK,CAAC,aAAa,WAAW,EAAE,IAAI;QACvE,MAAM,UAAU,EAAE;QAClB,KAAK,MAAM,OAAO,UAAW;YACzB,IAAI,IAAI,SAAS,IAAI,QAAQ,GAAG,CAAC,IAAI,CAAC,iBAAiB,CAAC,IAAI,MAAM;gBAC9D,MAAM,WAAW,IAAI,sKAAA,CAAA,WAAQ,CAAC;oBAC1B,aAAa,GAAG,CAAC,IAAI,CAAC,iBAAiB,CAAC;oBACxC,UAAU,GAAG,CAAC,IAAI,CAAC,kBAAkB,CAAC;oBACtC,IAAI,GAAG,CAAC,IAAI,CAAC,YAAY,CAAC;gBAC9B;gBACA,IAAI,kBAAkB;oBAClB,SAAS,QAAQ,CAAC,IAAI,CAAC,gBAAgB,CAAC,GAAG,GAAG,CAAC,IAAI,CAAC,gBAAgB,CAAC;gBACzE;gBACA,QAAQ,IAAI,CAAC;oBAAC;oBAAU,IAAI,SAAS;iBAAC;YAC1C;QACJ;QACA,OAAO;IACX;IACA;;;;;;;;KAQC,GACD,MAAM,gCAAgC,KAAK,EAAE,CAAC,EAAE,MAAM,EAAE;QACpD,OAAO,IAAI,CAAC,cAAc,CAAC,OAAO,GAAG,QAAQ;IACjD;IACA;;;;;KAKC,GACD,MAAM,sBAAsB,UAAU,EAAE;QACpC,MAAM,cAAc,IAAI,CAAC,mBAAmB,IAAI,OAC1C,2CACA,CAAC,mDAAmD,EAAE,IAAI,CAAC,mBAAmB,CAAC,EAAE,CAAC;QACxF,MAAM,gBAAgB,IAAI,CAAC,mBAAmB,IAAI,OAC5C,WACA,CAAC,CAAC,EAAE,IAAI,CAAC,mBAAmB,CAAC,UAAU,CAAC;QAC9C,MAAM,mBAAmB,aACnB,GAAG,cAAc,CAAC,EAAE,WAAW,CAAC,CAAC,GACjC;QACN,MAAM,aAAa,CAAC;iCACK,EAAE,IAAI,CAAC,iBAAiB,CAAC;SACjD,EAAE,IAAI,CAAC,YAAY,CAAC;SACpB,EAAE,IAAI,CAAC,iBAAiB,CAAC;SACzB,EAAE,IAAI,CAAC,kBAAkB,CAAC;SAC1B,EAAE,IAAI,CAAC,gBAAgB,CAAC,EAAE,EAAE,iBAAiB;;IAElD,CAAC;QACG,MAAM,IAAI,CAAC,IAAI,CAAC,KAAK,CAAC;QACtB,MAAM,IAAI,CAAC,IAAI,CAAC,KAAK,CAAC;IAC1B;IACA;;;;;KAKC,GACD,MAAM,kCAAkC;QACpC,IAAI;YACA,MAAM,cAAc,CAAC;mCACE,EAAE,IAAI,CAAC,2BAA2B,CAAC;;;;;;uCAM/B,EAAE,IAAI,CAAC,mBAAmB,CAAC,SAAS,EAAE,IAAI,CAAC,2BAA2B,CAAC;;oBAE1F,EAAE,IAAI,CAAC,iBAAiB,CAAC;;;oBAGzB,EAAE,IAAI,CAAC,iBAAiB,CAAC;yBACpB,EAAE,IAAI,CAAC,SAAS,CAAC;;qBAErB,EAAE,IAAI,CAAC,2BAA2B,CAAC;;MAElD,CAAC;YACK,MAAM,IAAI,CAAC,IAAI,CAAC,KAAK,CAAC;QAC1B,EACA,OAAO,GAAG;YACN,IAAI,CAAC,EAAE,OAAO,CAAC,QAAQ,CAAC,mBAAmB;gBACvC,QAAQ,KAAK,CAAC;gBACd,MAAM,IAAI,MAAM,CAAC,uCAAuC,EAAE,EAAE,OAAO,EAAE;YACzE;QACJ;IACJ;IACA;;;;;;;;;;KAUC,GACD,aAAa,UAAU,KAAK,EAAE,SAAS,EAAE,UAAU,EAAE,QAAQ,EAAE;QAC3D,MAAM,OAAO,EAAE;QACf,IAAK,IAAI,IAAI,GAAG,IAAI,MAAM,MAAM,EAAE,KAAK,EAAG;YACtC,MAAM,WAAW,MAAM,OAAO,CAAC,aAAa,SAAS,CAAC,EAAE,GAAG;YAC3D,MAAM,SAAS,IAAI,sKAAA,CAAA,WAAQ,CAAC;gBACxB,aAAa,KAAK,CAAC,EAAE;gBACrB;YACJ;YACA,KAAK,IAAI,CAAC;QACd;QACA,OAAO,cAAc,aAAa,CAAC,MAAM,YAAY;IACzD;IACA;;;;;;;;KAQC,GACD,aAAa,cAAc,IAAI,EAAE,UAAU,EAAE,QAAQ,EAAE;QACnD,MAAM,WAAW,MAAM,cAAc,UAAU,CAAC,YAAY;QAC5D,MAAM,SAAS,YAAY,CAAC,MAAM;YAAE,KAAK,SAAS,GAAG;QAAC;QACtD,OAAO;IACX;IACA;;;;KAIC,GACD,MAAM,MAAM;QACR,IAAI,CAAC,MAAM,EAAE;QACb,OAAO,IAAI,CAAC,IAAI,CAAC,GAAG;IACxB;IACA;;;;;;;;;KASC,GACD,MAAM,gBAAgB,MAAM,EAAE;QAC1B,IAAI,sBAAsB,QAAQ,oBAAoB;QACtD,MAAM,SAAS,QAAQ,YAAY,GAAG,OAAO,SAAS,CAAC,CAAC,CAAC,GAAG;QAC5D,OAAQ,IAAI,CAAC,gBAAgB;YACzB,KAAK;gBACD,sBAAsB;gBACtB;YACJ,KAAK;gBACD,sBAAsB;gBACtB;YACJ,KAAK;gBACD,sBAAsB;gBACtB;YACJ;gBACI,MAAM,IAAI,MAAM,CAAC,2BAA2B,EAAE,IAAI,CAAC,gBAAgB,EAAE;QAC7E;QACA,MAAM,mBAAmB,CAAC,2BAA2B,EAAE,SAAS,IAAI,CAAC,gBAAgB,CAAC;WACnF,EAAE,IAAI,CAAC,iBAAiB,CAAC,cAAc,EAAE,IAAI,CAAC,gBAAgB,CAAC,SAAS,EAAE,OAAO,UAAU,CAAC,GAAG,EAAE,oBAAoB;;cAElH,EAAE,QAAQ,KAAK,GAAG;4BACJ,EAAE,QAAQ,kBAAkB,GAAG;UACjD,CAAC;QACH,IAAI;YACA,MAAM,IAAI,CAAC,IAAI,CAAC,KAAK,CAAC;QAC1B,EACA,OAAO,GAAG;YACN,QAAQ,KAAK,CAAC,CAAC,qCAAqC,EAAE,IAAI,CAAC,iBAAiB,CAAC,SAAS,EAAE,GAAG;QAC/F;IACJ;IACA;;;;;;;;;;;;KAYC,GACD,MAAM,2BAA2B,KAAK,EAAE,OAAO,EAAE;QAC7C,MAAM,EAAE,IAAI,CAAC,EAAE,SAAS,EAAE,EAAE,SAAS,GAAG,EAAE,MAAM,EAAE,GAAG;QACrD,MAAM,iBAAiB,MAAM,IAAI,CAAC,UAAU,CAAC,UAAU,CAAC;QACxD,MAAM,OAAO,MAAM,IAAI,CAAC,cAAc,CAAC,gBAAgB,QAAQ,QAAQ;QACvE,MAAM,gBAAgB,KAAK,GAAG,CAAC,CAAC,MAAQ,KAAK,KAAK,CAAC,GAAG,CAAC,EAAE,CAAC,QAAQ,CAAC,IAAI,CAAC,gBAAgB,CAAC;QACzF,MAAM,aAAa,CAAA,GAAA,8JAAA,CAAA,2BAAwB,AAAD,EAAE,gBAAgB,eAAe,QAAQ;QACnF,MAAM,UAAU,WAAW,GAAG,CAAC,CAAC;YAC5B,MAAM,MAAM,IAAI,CAAC,MAAM,CAAC,EAAE;YAC1B,OAAO,IAAI,QAAQ,CAAC,IAAI,CAAC,gBAAgB,CAAC;YAC1C,OAAO,IAAI,CAAC,MAAM,CAAC,EAAE;QACzB;QACA,OAAO;IACX;AACJ","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 962, "column": 0}, "map": {"version":3,"sources":["file:///Users/dylanchua/Documents/Personal/Code/neurodocument/node_modules/%40langchain/community/vectorstores/pgvector.js"],"sourcesContent":["export * from '../dist/vectorstores/pgvector.js'"],"names":[],"mappings":";AAAA","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 991, "column": 0}, "map": {"version":3,"sources":["file:///Users/dylanchua/Documents/Personal/Code/neurodocument/node_modules/%40langchain/google-genai/dist/utils/zod_to_genai_parameters.js"],"sourcesContent":["/* eslint-disable @typescript-eslint/no-unused-vars */\nimport { isZodSchema } from \"@langchain/core/utils/types\";\nimport { zodToJsonSchema } from \"zod-to-json-schema\";\nexport function removeAdditionalProperties(\n// eslint-disable-next-line @typescript-eslint/no-explicit-any\nobj) {\n    if (typeof obj === \"object\" && obj !== null) {\n        const newObj = { ...obj };\n        if (\"additionalProperties\" in newObj) {\n            delete newObj.additionalProperties;\n        }\n        if (\"$schema\" in newObj) {\n            delete newObj.$schema;\n        }\n        if (\"strict\" in newObj) {\n            delete newObj.strict;\n        }\n        for (const key in newObj) {\n            if (key in newObj) {\n                if (Array.isArray(newObj[key])) {\n                    newObj[key] = newObj[key].map(removeAdditionalProperties);\n                }\n                else if (typeof newObj[key] === \"object\" && newObj[key] !== null) {\n                    newObj[key] = removeAdditionalProperties(newObj[key]);\n                }\n            }\n        }\n        return newObj;\n    }\n    return obj;\n}\nexport function schemaToGenerativeAIParameters(schema) {\n    // GenerativeAI doesn't accept either the $schema or additionalProperties\n    // attributes, so we need to explicitly remove them.\n    const jsonSchema = removeAdditionalProperties(isZodSchema(schema) ? zodToJsonSchema(schema) : schema);\n    const { $schema, ...rest } = jsonSchema;\n    return rest;\n}\nexport function jsonSchemaToGeminiParameters(\n// eslint-disable-next-line @typescript-eslint/no-explicit-any\nschema) {\n    // Gemini doesn't accept either the $schema or additionalProperties\n    // attributes, so we need to explicitly remove them.\n    // eslint-disable-next-line @typescript-eslint/no-explicit-any\n    const jsonSchema = removeAdditionalProperties(schema);\n    const { $schema, ...rest } = jsonSchema;\n    return rest;\n}\n"],"names":[],"mappings":"AAAA,oDAAoD;;;;;AACpD;AAAA;AACA;AAAA;;;AACO,SAAS,2BAChB,8DAA8D;AAC9D,GAAG;IACC,IAAI,OAAO,QAAQ,YAAY,QAAQ,MAAM;QACzC,MAAM,SAAS;YAAE,GAAG,GAAG;QAAC;QACxB,IAAI,0BAA0B,QAAQ;YAClC,OAAO,OAAO,oBAAoB;QACtC;QACA,IAAI,aAAa,QAAQ;YACrB,OAAO,OAAO,OAAO;QACzB;QACA,IAAI,YAAY,QAAQ;YACpB,OAAO,OAAO,MAAM;QACxB;QACA,IAAK,MAAM,OAAO,OAAQ;YACtB,IAAI,OAAO,QAAQ;gBACf,IAAI,MAAM,OAAO,CAAC,MAAM,CAAC,IAAI,GAAG;oBAC5B,MAAM,CAAC,IAAI,GAAG,MAAM,CAAC,IAAI,CAAC,GAAG,CAAC;gBAClC,OACK,IAAI,OAAO,MAAM,CAAC,IAAI,KAAK,YAAY,MAAM,CAAC,IAAI,KAAK,MAAM;oBAC9D,MAAM,CAAC,IAAI,GAAG,2BAA2B,MAAM,CAAC,IAAI;gBACxD;YACJ;QACJ;QACA,OAAO;IACX;IACA,OAAO;AACX;AACO,SAAS,+BAA+B,MAAM;IACjD,yEAAyE;IACzE,oDAAoD;IACpD,MAAM,aAAa,2BAA2B,CAAA,GAAA,gLAAA,CAAA,cAAW,AAAD,EAAE,UAAU,CAAA,GAAA,+KAAA,CAAA,kBAAe,AAAD,EAAE,UAAU;IAC9F,MAAM,EAAE,OAAO,EAAE,GAAG,MAAM,GAAG;IAC7B,OAAO;AACX;AACO,SAAS,6BAChB,8DAA8D;AAC9D,MAAM;IACF,mEAAmE;IACnE,oDAAoD;IACpD,8DAA8D;IAC9D,MAAM,aAAa,2BAA2B;IAC9C,MAAM,EAAE,OAAO,EAAE,GAAG,MAAM,GAAG;IAC7B,OAAO;AACX","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 1052, "column": 0}, "map": {"version":3,"sources":["file:///Users/dylanchua/Documents/Personal/Code/neurodocument/node_modules/%40langchain/google-genai/dist/utils/common.js"],"sourcesContent":["import { AIMessage, AIMessageChunk, ChatMessage, isAIMessage, isBaseMessage, isToolMessage, } from \"@langchain/core/messages\";\nimport { ChatGenerationChunk, } from \"@langchain/core/outputs\";\nimport { isLangChainTool } from \"@langchain/core/utils/function_calling\";\nimport { isOpenAITool } from \"@langchain/core/language_models/base\";\nimport { v4 as uuidv4 } from \"uuid\";\nimport { jsonSchemaToGeminiParameters, schemaToGenerativeAIParameters, } from \"./zod_to_genai_parameters.js\";\nexport function getMessageAuthor(message) {\n    const type = message._getType();\n    if (ChatMessage.isInstance(message)) {\n        return message.role;\n    }\n    if (type === \"tool\") {\n        return type;\n    }\n    return message.name ?? type;\n}\n/**\n * Maps a message type to a Google Generative AI chat author.\n * @param message The message to map.\n * @param model The model to use for mapping.\n * @returns The message type mapped to a Google Generative AI chat author.\n */\nexport function convertAuthorToRole(author) {\n    switch (author) {\n        /**\n         *  Note: Gemini currently is not supporting system messages\n         *  we will convert them to human messages and merge with following\n         * */\n        case \"supervisor\":\n        case \"ai\":\n        case \"model\": // getMessageAuthor returns message.name. code ex.: return message.name ?? type;\n            return \"model\";\n        case \"system\":\n            return \"system\";\n        case \"human\":\n            return \"user\";\n        case \"tool\":\n        case \"function\":\n            return \"function\";\n        default:\n            throw new Error(`Unknown / unsupported author: ${author}`);\n    }\n}\nfunction messageContentMedia(content) {\n    if (\"mimeType\" in content && \"data\" in content) {\n        return {\n            inlineData: {\n                mimeType: content.mimeType,\n                data: content.data,\n            },\n        };\n    }\n    if (\"mimeType\" in content && \"fileUri\" in content) {\n        return {\n            fileData: {\n                mimeType: content.mimeType,\n                fileUri: content.fileUri,\n            },\n        };\n    }\n    throw new Error(\"Invalid media content\");\n}\nfunction inferToolNameFromPreviousMessages(message, previousMessages) {\n    return previousMessages\n        .map((msg) => {\n        if (isAIMessage(msg)) {\n            return msg.tool_calls ?? [];\n        }\n        return [];\n    })\n        .flat()\n        .find((toolCall) => {\n        return toolCall.id === message.tool_call_id;\n    })?.name;\n}\nexport function convertMessageContentToParts(message, isMultimodalModel, previousMessages) {\n    if (isToolMessage(message)) {\n        const messageName = message.name ??\n            inferToolNameFromPreviousMessages(message, previousMessages);\n        if (messageName === undefined) {\n            throw new Error(`Google requires a tool name for each tool call response, and we could not infer a called tool name for ToolMessage \"${message.id}\" from your passed messages. Please populate a \"name\" field on that ToolMessage explicitly.`);\n        }\n        return [\n            {\n                functionResponse: {\n                    name: messageName,\n                    response: typeof message.content === \"string\"\n                        ? { result: message.content }\n                        : message.content,\n                },\n            },\n        ];\n    }\n    let functionCalls = [];\n    const messageParts = [];\n    if (typeof message.content === \"string\" && message.content) {\n        messageParts.push({ text: message.content });\n    }\n    if (Array.isArray(message.content)) {\n        message.content.forEach((c) => {\n            if (c.type === \"text\") {\n                messageParts.push({ text: c.text });\n            }\n            else if (c.type === \"executableCode\") {\n                messageParts.push({ executableCode: c.executableCode });\n            }\n            else if (c.type === \"codeExecutionResult\") {\n                messageParts.push({ codeExecutionResult: c.codeExecutionResult });\n            }\n            else if (c.type === \"image_url\") {\n                if (!isMultimodalModel) {\n                    throw new Error(`This model does not support images`);\n                }\n                let source;\n                if (typeof c.image_url === \"string\") {\n                    source = c.image_url;\n                }\n                else if (typeof c.image_url === \"object\" && \"url\" in c.image_url) {\n                    source = c.image_url.url;\n                }\n                else {\n                    throw new Error(\"Please provide image as base64 encoded data URL\");\n                }\n                const [dm, data] = source.split(\",\");\n                if (!dm.startsWith(\"data:\")) {\n                    throw new Error(\"Please provide image as base64 encoded data URL\");\n                }\n                const [mimeType, encoding] = dm.replace(/^data:/, \"\").split(\";\");\n                if (encoding !== \"base64\") {\n                    throw new Error(\"Please provide image as base64 encoded data URL\");\n                }\n                messageParts.push({\n                    inlineData: {\n                        data,\n                        mimeType,\n                    },\n                });\n            }\n            else if (c.type === \"media\") {\n                messageParts.push(messageContentMedia(c));\n            }\n            else if (c.type === \"tool_use\") {\n                functionCalls.push({\n                    functionCall: {\n                        name: c.name,\n                        args: c.input,\n                    },\n                });\n            }\n            else if (c.type?.includes(\"/\") &&\n                // Ensure it's a single slash.\n                c.type.split(\"/\").length === 2 &&\n                \"data\" in c &&\n                typeof c.data === \"string\") {\n                messageParts.push({\n                    inlineData: {\n                        mimeType: c.type,\n                        data: c.data,\n                    },\n                });\n            }\n            else if (\"functionCall\" in c) {\n                // No action needed here — function calls will be added later from message.tool_calls\n            }\n            else {\n                if (\"type\" in c) {\n                    throw new Error(`Unknown content type ${c.type}`);\n                }\n                else {\n                    throw new Error(`Unknown content ${JSON.stringify(c)}`);\n                }\n            }\n        });\n    }\n    if (isAIMessage(message) && message.tool_calls?.length) {\n        functionCalls = message.tool_calls.map((tc) => {\n            return {\n                functionCall: {\n                    name: tc.name,\n                    args: tc.args,\n                },\n            };\n        });\n    }\n    return [...messageParts, ...functionCalls];\n}\nexport function convertBaseMessagesToContent(messages, isMultimodalModel, convertSystemMessageToHumanContent = false) {\n    return messages.reduce((acc, message, index) => {\n        if (!isBaseMessage(message)) {\n            throw new Error(\"Unsupported message input\");\n        }\n        const author = getMessageAuthor(message);\n        if (author === \"system\" && index !== 0) {\n            throw new Error(\"System message should be the first one\");\n        }\n        const role = convertAuthorToRole(author);\n        const prevContent = acc.content[acc.content.length];\n        if (!acc.mergeWithPreviousContent &&\n            prevContent &&\n            prevContent.role === role) {\n            throw new Error(\"Google Generative AI requires alternate messages between authors\");\n        }\n        const parts = convertMessageContentToParts(message, isMultimodalModel, messages.slice(0, index));\n        if (acc.mergeWithPreviousContent) {\n            const prevContent = acc.content[acc.content.length - 1];\n            if (!prevContent) {\n                throw new Error(\"There was a problem parsing your system message. Please try a prompt without one.\");\n            }\n            prevContent.parts.push(...parts);\n            return {\n                mergeWithPreviousContent: false,\n                content: acc.content,\n            };\n        }\n        let actualRole = role;\n        if (actualRole === \"function\" ||\n            (actualRole === \"system\" && !convertSystemMessageToHumanContent)) {\n            // GenerativeAI API will throw an error if the role is not \"user\" or \"model.\"\n            actualRole = \"user\";\n        }\n        const content = {\n            role: actualRole,\n            parts,\n        };\n        return {\n            mergeWithPreviousContent: author === \"system\" && !convertSystemMessageToHumanContent,\n            content: [...acc.content, content],\n        };\n    }, { content: [], mergeWithPreviousContent: false }).content;\n}\nexport function mapGenerateContentResultToChatResult(response, extra) {\n    // if rejected or error, return empty generations with reason in filters\n    if (!response.candidates ||\n        response.candidates.length === 0 ||\n        !response.candidates[0]) {\n        return {\n            generations: [],\n            llmOutput: {\n                filters: response.promptFeedback,\n            },\n        };\n    }\n    const functionCalls = response.functionCalls();\n    const [candidate] = response.candidates;\n    const { content: candidateContent, ...generationInfo } = candidate;\n    let content;\n    if (candidateContent?.parts.length === 1 && candidateContent.parts[0].text) {\n        content = candidateContent.parts[0].text;\n    }\n    else {\n        content = candidateContent.parts.map((p) => {\n            if (\"text\" in p) {\n                return {\n                    type: \"text\",\n                    text: p.text,\n                };\n            }\n            else if (\"executableCode\" in p) {\n                return {\n                    type: \"executableCode\",\n                    executableCode: p.executableCode,\n                };\n            }\n            else if (\"codeExecutionResult\" in p) {\n                return {\n                    type: \"codeExecutionResult\",\n                    codeExecutionResult: p.codeExecutionResult,\n                };\n            }\n            return p;\n        });\n    }\n    let text = \"\";\n    if (typeof content === \"string\") {\n        text = content;\n    }\n    else if (\"text\" in content[0]) {\n        text = content[0].text;\n    }\n    const generation = {\n        text,\n        message: new AIMessage({\n            content,\n            tool_calls: functionCalls?.map((fc) => {\n                return {\n                    ...fc,\n                    type: \"tool_call\",\n                    id: \"id\" in fc && typeof fc.id === \"string\" ? fc.id : uuidv4(),\n                };\n            }),\n            additional_kwargs: {\n                ...generationInfo,\n            },\n            usage_metadata: extra?.usageMetadata,\n        }),\n        generationInfo,\n    };\n    return {\n        generations: [generation],\n        llmOutput: {\n            tokenUsage: {\n                promptTokens: extra?.usageMetadata?.input_tokens,\n                completionTokens: extra?.usageMetadata?.output_tokens,\n                totalTokens: extra?.usageMetadata?.total_tokens,\n            },\n        },\n    };\n}\nexport function convertResponseContentToChatGenerationChunk(response, extra) {\n    if (!response.candidates || response.candidates.length === 0) {\n        return null;\n    }\n    const functionCalls = response.functionCalls();\n    const [candidate] = response.candidates;\n    const { content: candidateContent, ...generationInfo } = candidate;\n    let content;\n    // Checks if some parts do not have text. If false, it means that the content is a string.\n    if (candidateContent?.parts &&\n        candidateContent.parts.every((p) => \"text\" in p)) {\n        content = candidateContent.parts.map((p) => p.text).join(\"\");\n    }\n    else if (candidateContent.parts) {\n        content = candidateContent.parts.map((p) => {\n            if (\"text\" in p) {\n                return {\n                    type: \"text\",\n                    text: p.text,\n                };\n            }\n            else if (\"executableCode\" in p) {\n                return {\n                    type: \"executableCode\",\n                    executableCode: p.executableCode,\n                };\n            }\n            else if (\"codeExecutionResult\" in p) {\n                return {\n                    type: \"codeExecutionResult\",\n                    codeExecutionResult: p.codeExecutionResult,\n                };\n            }\n            return p;\n        });\n    }\n    let text = \"\";\n    if (content && typeof content === \"string\") {\n        text = content;\n    }\n    else if (content && typeof content === \"object\" && \"text\" in content[0]) {\n        text = content[0].text;\n    }\n    const toolCallChunks = [];\n    if (functionCalls) {\n        toolCallChunks.push(...functionCalls.map((fc) => ({\n            ...fc,\n            args: JSON.stringify(fc.args),\n            index: extra.index,\n            type: \"tool_call_chunk\",\n            id: \"id\" in fc && typeof fc.id === \"string\" ? fc.id : uuidv4(),\n        })));\n    }\n    return new ChatGenerationChunk({\n        text,\n        message: new AIMessageChunk({\n            content: content || \"\",\n            name: !candidateContent ? undefined : candidateContent.role,\n            tool_call_chunks: toolCallChunks,\n            // Each chunk can have unique \"generationInfo\", and merging strategy is unclear,\n            // so leave blank for now.\n            additional_kwargs: {},\n            usage_metadata: extra.usageMetadata,\n        }),\n        generationInfo,\n    });\n}\nexport function convertToGenerativeAITools(tools) {\n    if (tools.every((tool) => \"functionDeclarations\" in tool &&\n        Array.isArray(tool.functionDeclarations))) {\n        return tools;\n    }\n    return [\n        {\n            functionDeclarations: tools.map((tool) => {\n                if (isLangChainTool(tool)) {\n                    const jsonSchema = schemaToGenerativeAIParameters(tool.schema);\n                    if (jsonSchema.type === \"object\" &&\n                        \"properties\" in jsonSchema &&\n                        Object.keys(jsonSchema.properties).length === 0) {\n                        return {\n                            name: tool.name,\n                            description: tool.description,\n                        };\n                    }\n                    return {\n                        name: tool.name,\n                        description: tool.description,\n                        parameters: jsonSchema,\n                    };\n                }\n                if (isOpenAITool(tool)) {\n                    return {\n                        name: tool.function.name,\n                        description: tool.function.description ?? `A function available to call.`,\n                        parameters: jsonSchemaToGeminiParameters(tool.function.parameters),\n                    };\n                }\n                return tool;\n            }),\n        },\n    ];\n}\n"],"names":[],"mappings":";;;;;;;;;AAAA;AAAA;AAAA;AAAA;AAAA;AACA;AAAA;AACA;AAAA;AACA;AAAA;AACA;AACA;;;;;;;AACO,SAAS,iBAAiB,OAAO;IACpC,MAAM,OAAO,QAAQ,QAAQ;IAC7B,IAAI,iKAAA,CAAA,cAAW,CAAC,UAAU,CAAC,UAAU;QACjC,OAAO,QAAQ,IAAI;IACvB;IACA,IAAI,SAAS,QAAQ;QACjB,OAAO;IACX;IACA,OAAO,QAAQ,IAAI,IAAI;AAC3B;AAOO,SAAS,oBAAoB,MAAM;IACtC,OAAQ;QACJ;;;WAGG,GACH,KAAK;QACL,KAAK;QACL,KAAK;YACD,OAAO;QACX,KAAK;YACD,OAAO;QACX,KAAK;YACD,OAAO;QACX,KAAK;QACL,KAAK;YACD,OAAO;QACX;YACI,MAAM,IAAI,MAAM,CAAC,8BAA8B,EAAE,QAAQ;IACjE;AACJ;AACA,SAAS,oBAAoB,OAAO;IAChC,IAAI,cAAc,WAAW,UAAU,SAAS;QAC5C,OAAO;YACH,YAAY;gBACR,UAAU,QAAQ,QAAQ;gBAC1B,MAAM,QAAQ,IAAI;YACtB;QACJ;IACJ;IACA,IAAI,cAAc,WAAW,aAAa,SAAS;QAC/C,OAAO;YACH,UAAU;gBACN,UAAU,QAAQ,QAAQ;gBAC1B,SAAS,QAAQ,OAAO;YAC5B;QACJ;IACJ;IACA,MAAM,IAAI,MAAM;AACpB;AACA,SAAS,kCAAkC,OAAO,EAAE,gBAAgB;IAChE,OAAO,iBACF,GAAG,CAAC,CAAC;QACN,IAAI,CAAA,GAAA,+JAAA,CAAA,cAAW,AAAD,EAAE,MAAM;YAClB,OAAO,IAAI,UAAU,IAAI,EAAE;QAC/B;QACA,OAAO,EAAE;IACb,GACK,IAAI,GACJ,IAAI,CAAC,CAAC;QACP,OAAO,SAAS,EAAE,KAAK,QAAQ,YAAY;IAC/C,IAAI;AACR;AACO,SAAS,6BAA6B,OAAO,EAAE,iBAAiB,EAAE,gBAAgB;IACrF,IAAI,CAAA,GAAA,iKAAA,CAAA,gBAAa,AAAD,EAAE,UAAU;QACxB,MAAM,cAAc,QAAQ,IAAI,IAC5B,kCAAkC,SAAS;QAC/C,IAAI,gBAAgB,WAAW;YAC3B,MAAM,IAAI,MAAM,CAAC,oHAAoH,EAAE,QAAQ,EAAE,CAAC,2FAA2F,CAAC;QAClP;QACA,OAAO;YACH;gBACI,kBAAkB;oBACd,MAAM;oBACN,UAAU,OAAO,QAAQ,OAAO,KAAK,WAC/B;wBAAE,QAAQ,QAAQ,OAAO;oBAAC,IAC1B,QAAQ,OAAO;gBACzB;YACJ;SACH;IACL;IACA,IAAI,gBAAgB,EAAE;IACtB,MAAM,eAAe,EAAE;IACvB,IAAI,OAAO,QAAQ,OAAO,KAAK,YAAY,QAAQ,OAAO,EAAE;QACxD,aAAa,IAAI,CAAC;YAAE,MAAM,QAAQ,OAAO;QAAC;IAC9C;IACA,IAAI,MAAM,OAAO,CAAC,QAAQ,OAAO,GAAG;QAChC,QAAQ,OAAO,CAAC,OAAO,CAAC,CAAC;YACrB,IAAI,EAAE,IAAI,KAAK,QAAQ;gBACnB,aAAa,IAAI,CAAC;oBAAE,MAAM,EAAE,IAAI;gBAAC;YACrC,OACK,IAAI,EAAE,IAAI,KAAK,kBAAkB;gBAClC,aAAa,IAAI,CAAC;oBAAE,gBAAgB,EAAE,cAAc;gBAAC;YACzD,OACK,IAAI,EAAE,IAAI,KAAK,uBAAuB;gBACvC,aAAa,IAAI,CAAC;oBAAE,qBAAqB,EAAE,mBAAmB;gBAAC;YACnE,OACK,IAAI,EAAE,IAAI,KAAK,aAAa;gBAC7B,IAAI,CAAC,mBAAmB;oBACpB,MAAM,IAAI,MAAM,CAAC,kCAAkC,CAAC;gBACxD;gBACA,IAAI;gBACJ,IAAI,OAAO,EAAE,SAAS,KAAK,UAAU;oBACjC,SAAS,EAAE,SAAS;gBACxB,OACK,IAAI,OAAO,EAAE,SAAS,KAAK,YAAY,SAAS,EAAE,SAAS,EAAE;oBAC9D,SAAS,EAAE,SAAS,CAAC,GAAG;gBAC5B,OACK;oBACD,MAAM,IAAI,MAAM;gBACpB;gBACA,MAAM,CAAC,IAAI,KAAK,GAAG,OAAO,KAAK,CAAC;gBAChC,IAAI,CAAC,GAAG,UAAU,CAAC,UAAU;oBACzB,MAAM,IAAI,MAAM;gBACpB;gBACA,MAAM,CAAC,UAAU,SAAS,GAAG,GAAG,OAAO,CAAC,UAAU,IAAI,KAAK,CAAC;gBAC5D,IAAI,aAAa,UAAU;oBACvB,MAAM,IAAI,MAAM;gBACpB;gBACA,aAAa,IAAI,CAAC;oBACd,YAAY;wBACR;wBACA;oBACJ;gBACJ;YACJ,OACK,IAAI,EAAE,IAAI,KAAK,SAAS;gBACzB,aAAa,IAAI,CAAC,oBAAoB;YAC1C,OACK,IAAI,EAAE,IAAI,KAAK,YAAY;gBAC5B,cAAc,IAAI,CAAC;oBACf,cAAc;wBACV,MAAM,EAAE,IAAI;wBACZ,MAAM,EAAE,KAAK;oBACjB;gBACJ;YACJ,OACK,IAAI,EAAE,IAAI,EAAE,SAAS,QACtB,8BAA8B;YAC9B,EAAE,IAAI,CAAC,KAAK,CAAC,KAAK,MAAM,KAAK,KAC7B,UAAU,KACV,OAAO,EAAE,IAAI,KAAK,UAAU;gBAC5B,aAAa,IAAI,CAAC;oBACd,YAAY;wBACR,UAAU,EAAE,IAAI;wBAChB,MAAM,EAAE,IAAI;oBAChB;gBACJ;YACJ,OACK,IAAI,kBAAkB,GAAG;YAC1B,qFAAqF;YACzF,OACK;gBACD,IAAI,UAAU,GAAG;oBACb,MAAM,IAAI,MAAM,CAAC,qBAAqB,EAAE,EAAE,IAAI,EAAE;gBACpD,OACK;oBACD,MAAM,IAAI,MAAM,CAAC,gBAAgB,EAAE,KAAK,SAAS,CAAC,IAAI;gBAC1D;YACJ;QACJ;IACJ;IACA,IAAI,CAAA,GAAA,+JAAA,CAAA,cAAW,AAAD,EAAE,YAAY,QAAQ,UAAU,EAAE,QAAQ;QACpD,gBAAgB,QAAQ,UAAU,CAAC,GAAG,CAAC,CAAC;YACpC,OAAO;gBACH,cAAc;oBACV,MAAM,GAAG,IAAI;oBACb,MAAM,GAAG,IAAI;gBACjB;YACJ;QACJ;IACJ;IACA,OAAO;WAAI;WAAiB;KAAc;AAC9C;AACO,SAAS,6BAA6B,QAAQ,EAAE,iBAAiB,EAAE,qCAAqC,KAAK;IAChH,OAAO,SAAS,MAAM,CAAC,CAAC,KAAK,SAAS;QAClC,IAAI,CAAC,CAAA,GAAA,iKAAA,CAAA,gBAAa,AAAD,EAAE,UAAU;YACzB,MAAM,IAAI,MAAM;QACpB;QACA,MAAM,SAAS,iBAAiB;QAChC,IAAI,WAAW,YAAY,UAAU,GAAG;YACpC,MAAM,IAAI,MAAM;QACpB;QACA,MAAM,OAAO,oBAAoB;QACjC,MAAM,cAAc,IAAI,OAAO,CAAC,IAAI,OAAO,CAAC,MAAM,CAAC;QACnD,IAAI,CAAC,IAAI,wBAAwB,IAC7B,eACA,YAAY,IAAI,KAAK,MAAM;YAC3B,MAAM,IAAI,MAAM;QACpB;QACA,MAAM,QAAQ,6BAA6B,SAAS,mBAAmB,SAAS,KAAK,CAAC,GAAG;QACzF,IAAI,IAAI,wBAAwB,EAAE;YAC9B,MAAM,cAAc,IAAI,OAAO,CAAC,IAAI,OAAO,CAAC,MAAM,GAAG,EAAE;YACvD,IAAI,CAAC,aAAa;gBACd,MAAM,IAAI,MAAM;YACpB;YACA,YAAY,KAAK,CAAC,IAAI,IAAI;YAC1B,OAAO;gBACH,0BAA0B;gBAC1B,SAAS,IAAI,OAAO;YACxB;QACJ;QACA,IAAI,aAAa;QACjB,IAAI,eAAe,cACd,eAAe,YAAY,CAAC,oCAAqC;YAClE,6EAA6E;YAC7E,aAAa;QACjB;QACA,MAAM,UAAU;YACZ,MAAM;YACN;QACJ;QACA,OAAO;YACH,0BAA0B,WAAW,YAAY,CAAC;YAClD,SAAS;mBAAI,IAAI,OAAO;gBAAE;aAAQ;QACtC;IACJ,GAAG;QAAE,SAAS,EAAE;QAAE,0BAA0B;IAAM,GAAG,OAAO;AAChE;AACO,SAAS,qCAAqC,QAAQ,EAAE,KAAK;IAChE,wEAAwE;IACxE,IAAI,CAAC,SAAS,UAAU,IACpB,SAAS,UAAU,CAAC,MAAM,KAAK,KAC/B,CAAC,SAAS,UAAU,CAAC,EAAE,EAAE;QACzB,OAAO;YACH,aAAa,EAAE;YACf,WAAW;gBACP,SAAS,SAAS,cAAc;YACpC;QACJ;IACJ;IACA,MAAM,gBAAgB,SAAS,aAAa;IAC5C,MAAM,CAAC,UAAU,GAAG,SAAS,UAAU;IACvC,MAAM,EAAE,SAAS,gBAAgB,EAAE,GAAG,gBAAgB,GAAG;IACzD,IAAI;IACJ,IAAI,kBAAkB,MAAM,WAAW,KAAK,iBAAiB,KAAK,CAAC,EAAE,CAAC,IAAI,EAAE;QACxE,UAAU,iBAAiB,KAAK,CAAC,EAAE,CAAC,IAAI;IAC5C,OACK;QACD,UAAU,iBAAiB,KAAK,CAAC,GAAG,CAAC,CAAC;YAClC,IAAI,UAAU,GAAG;gBACb,OAAO;oBACH,MAAM;oBACN,MAAM,EAAE,IAAI;gBAChB;YACJ,OACK,IAAI,oBAAoB,GAAG;gBAC5B,OAAO;oBACH,MAAM;oBACN,gBAAgB,EAAE,cAAc;gBACpC;YACJ,OACK,IAAI,yBAAyB,GAAG;gBACjC,OAAO;oBACH,MAAM;oBACN,qBAAqB,EAAE,mBAAmB;gBAC9C;YACJ;YACA,OAAO;QACX;IACJ;IACA,IAAI,OAAO;IACX,IAAI,OAAO,YAAY,UAAU;QAC7B,OAAO;IACX,OACK,IAAI,UAAU,OAAO,CAAC,EAAE,EAAE;QAC3B,OAAO,OAAO,CAAC,EAAE,CAAC,IAAI;IAC1B;IACA,MAAM,aAAa;QACf;QACA,SAAS,IAAI,+JAAA,CAAA,YAAS,CAAC;YACnB;YACA,YAAY,eAAe,IAAI,CAAC;gBAC5B,OAAO;oBACH,GAAG,EAAE;oBACL,MAAM;oBACN,IAAI,QAAQ,MAAM,OAAO,GAAG,EAAE,KAAK,WAAW,GAAG,EAAE,GAAG,CAAA,GAAA,8NAAA,CAAA,KAAM,AAAD;gBAC/D;YACJ;YACA,mBAAmB;gBACf,GAAG,cAAc;YACrB;YACA,gBAAgB,OAAO;QAC3B;QACA;IACJ;IACA,OAAO;QACH,aAAa;YAAC;SAAW;QACzB,WAAW;YACP,YAAY;gBACR,cAAc,OAAO,eAAe;gBACpC,kBAAkB,OAAO,eAAe;gBACxC,aAAa,OAAO,eAAe;YACvC;QACJ;IACJ;AACJ;AACO,SAAS,4CAA4C,QAAQ,EAAE,KAAK;IACvE,IAAI,CAAC,SAAS,UAAU,IAAI,SAAS,UAAU,CAAC,MAAM,KAAK,GAAG;QAC1D,OAAO;IACX;IACA,MAAM,gBAAgB,SAAS,aAAa;IAC5C,MAAM,CAAC,UAAU,GAAG,SAAS,UAAU;IACvC,MAAM,EAAE,SAAS,gBAAgB,EAAE,GAAG,gBAAgB,GAAG;IACzD,IAAI;IACJ,0FAA0F;IAC1F,IAAI,kBAAkB,SAClB,iBAAiB,KAAK,CAAC,KAAK,CAAC,CAAC,IAAM,UAAU,IAAI;QAClD,UAAU,iBAAiB,KAAK,CAAC,GAAG,CAAC,CAAC,IAAM,EAAE,IAAI,EAAE,IAAI,CAAC;IAC7D,OACK,IAAI,iBAAiB,KAAK,EAAE;QAC7B,UAAU,iBAAiB,KAAK,CAAC,GAAG,CAAC,CAAC;YAClC,IAAI,UAAU,GAAG;gBACb,OAAO;oBACH,MAAM;oBACN,MAAM,EAAE,IAAI;gBAChB;YACJ,OACK,IAAI,oBAAoB,GAAG;gBAC5B,OAAO;oBACH,MAAM;oBACN,gBAAgB,EAAE,cAAc;gBACpC;YACJ,OACK,IAAI,yBAAyB,GAAG;gBACjC,OAAO;oBACH,MAAM;oBACN,qBAAqB,EAAE,mBAAmB;gBAC9C;YACJ;YACA,OAAO;QACX;IACJ;IACA,IAAI,OAAO;IACX,IAAI,WAAW,OAAO,YAAY,UAAU;QACxC,OAAO;IACX,OACK,IAAI,WAAW,OAAO,YAAY,YAAY,UAAU,OAAO,CAAC,EAAE,EAAE;QACrE,OAAO,OAAO,CAAC,EAAE,CAAC,IAAI;IAC1B;IACA,MAAM,iBAAiB,EAAE;IACzB,IAAI,eAAe;QACf,eAAe,IAAI,IAAI,cAAc,GAAG,CAAC,CAAC,KAAO,CAAC;gBAC9C,GAAG,EAAE;gBACL,MAAM,KAAK,SAAS,CAAC,GAAG,IAAI;gBAC5B,OAAO,MAAM,KAAK;gBAClB,MAAM;gBACN,IAAI,QAAQ,MAAM,OAAO,GAAG,EAAE,KAAK,WAAW,GAAG,EAAE,GAAG,CAAA,GAAA,8NAAA,CAAA,KAAM,AAAD;YAC/D,CAAC;IACL;IACA,OAAO,IAAI,wJAAA,CAAA,sBAAmB,CAAC;QAC3B;QACA,SAAS,IAAI,+JAAA,CAAA,iBAAc,CAAC;YACxB,SAAS,WAAW;YACpB,MAAM,CAAC,mBAAmB,YAAY,iBAAiB,IAAI;YAC3D,kBAAkB;YAClB,gFAAgF;YAChF,0BAA0B;YAC1B,mBAAmB,CAAC;YACpB,gBAAgB,MAAM,aAAa;QACvC;QACA;IACJ;AACJ;AACO,SAAS,2BAA2B,KAAK;IAC5C,IAAI,MAAM,KAAK,CAAC,CAAC,OAAS,0BAA0B,QAChD,MAAM,OAAO,CAAC,KAAK,oBAAoB,IAAI;QAC3C,OAAO;IACX;IACA,OAAO;QACH;YACI,sBAAsB,MAAM,GAAG,CAAC,CAAC;gBAC7B,IAAI,CAAA,GAAA,+JAAA,CAAA,kBAAe,AAAD,EAAE,OAAO;oBACvB,MAAM,aAAa,CAAA,GAAA,4LAAA,CAAA,iCAA8B,AAAD,EAAE,KAAK,MAAM;oBAC7D,IAAI,WAAW,IAAI,KAAK,YACpB,gBAAgB,cAChB,OAAO,IAAI,CAAC,WAAW,UAAU,EAAE,MAAM,KAAK,GAAG;wBACjD,OAAO;4BACH,MAAM,KAAK,IAAI;4BACf,aAAa,KAAK,WAAW;wBACjC;oBACJ;oBACA,OAAO;wBACH,MAAM,KAAK,IAAI;wBACf,aAAa,KAAK,WAAW;wBAC7B,YAAY;oBAChB;gBACJ;gBACA,IAAI,CAAA,GAAA,wKAAA,CAAA,eAAY,AAAD,EAAE,OAAO;oBACpB,OAAO;wBACH,MAAM,KAAK,QAAQ,CAAC,IAAI;wBACxB,aAAa,KAAK,QAAQ,CAAC,WAAW,IAAI,CAAC,6BAA6B,CAAC;wBACzE,YAAY,CAAA,GAAA,4LAAA,CAAA,+BAA4B,AAAD,EAAE,KAAK,QAAQ,CAAC,UAAU;oBACrE;gBACJ;gBACA,OAAO;YACX;QACJ;KACH;AACL","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 1468, "column": 0}, "map": {"version":3,"sources":["file:///Users/dylanchua/Documents/Personal/Code/neurodocument/node_modules/%40langchain/google-genai/dist/output_parsers.js"],"sourcesContent":["import { BaseLLMOutputParser, OutputParserException, } from \"@langchain/core/output_parsers\";\nexport class GoogleGenerativeAIToolsOutputParser extends BaseLLMOutputParser {\n    static lc_name() {\n        return \"GoogleGenerativeAIToolsOutputParser\";\n    }\n    constructor(params) {\n        super(params);\n        Object.defineProperty(this, \"lc_namespace\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: [\"langchain\", \"google_genai\", \"output_parsers\"]\n        });\n        Object.defineProperty(this, \"returnId\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: false\n        });\n        /** The type of tool calls to return. */\n        Object.defineProperty(this, \"keyName\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        /** Whether to return only the first tool call. */\n        Object.defineProperty(this, \"returnSingle\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: false\n        });\n        Object.defineProperty(this, \"zodSchema\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        this.keyName = params.keyName;\n        this.returnSingle = params.returnSingle ?? this.returnSingle;\n        this.zodSchema = params.zodSchema;\n    }\n    async _validateResult(result) {\n        if (this.zodSchema === undefined) {\n            return result;\n        }\n        const zodParsedResult = await this.zodSchema.safeParseAsync(result);\n        if (zodParsedResult.success) {\n            return zodParsedResult.data;\n        }\n        else {\n            throw new OutputParserException(`Failed to parse. Text: \"${JSON.stringify(result, null, 2)}\". Error: ${JSON.stringify(zodParsedResult.error.errors)}`, JSON.stringify(result, null, 2));\n        }\n    }\n    async parseResult(generations) {\n        const tools = generations.flatMap((generation) => {\n            const { message } = generation;\n            if (!(\"tool_calls\" in message) || !Array.isArray(message.tool_calls)) {\n                return [];\n            }\n            return message.tool_calls;\n        });\n        if (tools[0] === undefined) {\n            throw new Error(\"No parseable tool calls provided to GoogleGenerativeAIToolsOutputParser.\");\n        }\n        const [tool] = tools;\n        const validatedResult = await this._validateResult(tool.args);\n        return validatedResult;\n    }\n}\n"],"names":[],"mappings":";;;AAAA;AAAA;;AACO,MAAM,4CAA4C,uKAAA,CAAA,sBAAmB;IACxE,OAAO,UAAU;QACb,OAAO;IACX;IACA,YAAY,MAAM,CAAE;QAChB,KAAK,CAAC;QACN,OAAO,cAAc,CAAC,IAAI,EAAE,gBAAgB;YACxC,YAAY;YACZ,cAAc;YACd,UAAU;YACV,OAAO;gBAAC;gBAAa;gBAAgB;aAAiB;QAC1D;QACA,OAAO,cAAc,CAAC,IAAI,EAAE,YAAY;YACpC,YAAY;YACZ,cAAc;YACd,UAAU;YACV,OAAO;QACX;QACA,sCAAsC,GACtC,OAAO,cAAc,CAAC,IAAI,EAAE,WAAW;YACnC,YAAY;YACZ,cAAc;YACd,UAAU;YACV,OAAO,KAAK;QAChB;QACA,gDAAgD,GAChD,OAAO,cAAc,CAAC,IAAI,EAAE,gBAAgB;YACxC,YAAY;YACZ,cAAc;YACd,UAAU;YACV,OAAO;QACX;QACA,OAAO,cAAc,CAAC,IAAI,EAAE,aAAa;YACrC,YAAY;YACZ,cAAc;YACd,UAAU;YACV,OAAO,KAAK;QAChB;QACA,IAAI,CAAC,OAAO,GAAG,OAAO,OAAO;QAC7B,IAAI,CAAC,YAAY,GAAG,OAAO,YAAY,IAAI,IAAI,CAAC,YAAY;QAC5D,IAAI,CAAC,SAAS,GAAG,OAAO,SAAS;IACrC;IACA,MAAM,gBAAgB,MAAM,EAAE;QAC1B,IAAI,IAAI,CAAC,SAAS,KAAK,WAAW;YAC9B,OAAO;QACX;QACA,MAAM,kBAAkB,MAAM,IAAI,CAAC,SAAS,CAAC,cAAc,CAAC;QAC5D,IAAI,gBAAgB,OAAO,EAAE;YACzB,OAAO,gBAAgB,IAAI;QAC/B,OACK;YACD,MAAM,IAAI,uKAAA,CAAA,wBAAqB,CAAC,CAAC,wBAAwB,EAAE,KAAK,SAAS,CAAC,QAAQ,MAAM,GAAG,UAAU,EAAE,KAAK,SAAS,CAAC,gBAAgB,KAAK,CAAC,MAAM,GAAG,EAAE,KAAK,SAAS,CAAC,QAAQ,MAAM;QACxL;IACJ;IACA,MAAM,YAAY,WAAW,EAAE;QAC3B,MAAM,QAAQ,YAAY,OAAO,CAAC,CAAC;YAC/B,MAAM,EAAE,OAAO,EAAE,GAAG;YACpB,IAAI,CAAC,CAAC,gBAAgB,OAAO,KAAK,CAAC,MAAM,OAAO,CAAC,QAAQ,UAAU,GAAG;gBAClE,OAAO,EAAE;YACb;YACA,OAAO,QAAQ,UAAU;QAC7B;QACA,IAAI,KAAK,CAAC,EAAE,KAAK,WAAW;YACxB,MAAM,IAAI,MAAM;QACpB;QACA,MAAM,CAAC,KAAK,GAAG;QACf,MAAM,kBAAkB,MAAM,IAAI,CAAC,eAAe,CAAC,KAAK,IAAI;QAC5D,OAAO;IACX;AACJ","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 1551, "column": 0}, "map": {"version":3,"sources":["file:///Users/dylanchua/Documents/Personal/Code/neurodocument/node_modules/%40langchain/google-genai/dist/utils/tools.js"],"sourcesContent":["import { FunctionCallingMode, } from \"@google/generative-ai\";\nimport { isLangChainTool } from \"@langchain/core/utils/function_calling\";\nimport { isOpenAITool, } from \"@langchain/core/language_models/base\";\nimport { convertToGenerativeAITools } from \"./common.js\";\nimport { removeAdditionalProperties } from \"./zod_to_genai_parameters.js\";\nexport function convertToolsToGenAI(tools, extra) {\n    // Extract function declaration processing to a separate function\n    const genAITools = processTools(tools);\n    // Simplify tool config creation\n    const toolConfig = createToolConfig(genAITools, extra);\n    return { tools: genAITools, toolConfig };\n}\nfunction processTools(tools) {\n    let functionDeclarationTools = [];\n    const genAITools = [];\n    tools.forEach((tool) => {\n        if (isLangChainTool(tool)) {\n            const [convertedTool] = convertToGenerativeAITools([\n                tool,\n            ]);\n            if (convertedTool.functionDeclarations) {\n                functionDeclarationTools.push(...convertedTool.functionDeclarations);\n            }\n        }\n        else if (isOpenAITool(tool)) {\n            const { functionDeclarations } = convertOpenAIToolToGenAI(tool);\n            if (functionDeclarations) {\n                functionDeclarationTools.push(...functionDeclarations);\n            }\n            else {\n                throw new Error(\"Failed to convert OpenAI structured tool to GenerativeAI tool\");\n            }\n        }\n        else {\n            genAITools.push(tool);\n        }\n    });\n    const genAIFunctionDeclaration = genAITools.find((t) => \"functionDeclarations\" in t);\n    if (genAIFunctionDeclaration) {\n        return genAITools.map((tool) => {\n            if (functionDeclarationTools?.length > 0 &&\n                \"functionDeclarations\" in tool) {\n                const newTool = {\n                    functionDeclarations: [\n                        ...(tool.functionDeclarations || []),\n                        ...functionDeclarationTools,\n                    ],\n                };\n                // Clear the functionDeclarationTools array so it is not passed again\n                functionDeclarationTools = [];\n                return newTool;\n            }\n            return tool;\n        });\n    }\n    return [\n        ...genAITools,\n        ...(functionDeclarationTools.length > 0\n            ? [\n                {\n                    functionDeclarations: functionDeclarationTools,\n                },\n            ]\n            : []),\n    ];\n}\nfunction convertOpenAIToolToGenAI(tool) {\n    return {\n        functionDeclarations: [\n            {\n                name: tool.function.name,\n                description: tool.function.description,\n                parameters: removeAdditionalProperties(tool.function.parameters),\n            },\n        ],\n    };\n}\nfunction createToolConfig(genAITools, extra) {\n    if (!genAITools.length || !extra)\n        return undefined;\n    const { toolChoice, allowedFunctionNames } = extra;\n    const modeMap = {\n        any: FunctionCallingMode.ANY,\n        auto: FunctionCallingMode.AUTO,\n        none: FunctionCallingMode.NONE,\n    };\n    if (toolChoice && [\"any\", \"auto\", \"none\"].includes(toolChoice)) {\n        return {\n            functionCallingConfig: {\n                mode: modeMap[toolChoice] ?? \"MODE_UNSPECIFIED\",\n                allowedFunctionNames,\n            },\n        };\n    }\n    if (typeof toolChoice === \"string\" || allowedFunctionNames) {\n        return {\n            functionCallingConfig: {\n                mode: FunctionCallingMode.ANY,\n                allowedFunctionNames: [\n                    ...(allowedFunctionNames ?? []),\n                    ...(toolChoice && typeof toolChoice === \"string\" ? [toolChoice] : []),\n                ],\n            },\n        };\n    }\n    return undefined;\n}\n"],"names":[],"mappings":";;;AAAA;AACA;AAAA;AACA;AAAA;AACA;AACA;;;;;;AACO,SAAS,oBAAoB,KAAK,EAAE,KAAK;IAC5C,iEAAiE;IACjE,MAAM,aAAa,aAAa;IAChC,gCAAgC;IAChC,MAAM,aAAa,iBAAiB,YAAY;IAChD,OAAO;QAAE,OAAO;QAAY;IAAW;AAC3C;AACA,SAAS,aAAa,KAAK;IACvB,IAAI,2BAA2B,EAAE;IACjC,MAAM,aAAa,EAAE;IACrB,MAAM,OAAO,CAAC,CAAC;QACX,IAAI,CAAA,GAAA,+JAAA,CAAA,kBAAe,AAAD,EAAE,OAAO;YACvB,MAAM,CAAC,cAAc,GAAG,CAAA,GAAA,2KAAA,CAAA,6BAA0B,AAAD,EAAE;gBAC/C;aACH;YACD,IAAI,cAAc,oBAAoB,EAAE;gBACpC,yBAAyB,IAAI,IAAI,cAAc,oBAAoB;YACvE;QACJ,OACK,IAAI,CAAA,GAAA,wKAAA,CAAA,eAAY,AAAD,EAAE,OAAO;YACzB,MAAM,EAAE,oBAAoB,EAAE,GAAG,yBAAyB;YAC1D,IAAI,sBAAsB;gBACtB,yBAAyB,IAAI,IAAI;YACrC,OACK;gBACD,MAAM,IAAI,MAAM;YACpB;QACJ,OACK;YACD,WAAW,IAAI,CAAC;QACpB;IACJ;IACA,MAAM,2BAA2B,WAAW,IAAI,CAAC,CAAC,IAAM,0BAA0B;IAClF,IAAI,0BAA0B;QAC1B,OAAO,WAAW,GAAG,CAAC,CAAC;YACnB,IAAI,0BAA0B,SAAS,KACnC,0BAA0B,MAAM;gBAChC,MAAM,UAAU;oBACZ,sBAAsB;2BACd,KAAK,oBAAoB,IAAI,EAAE;2BAChC;qBACN;gBACL;gBACA,qEAAqE;gBACrE,2BAA2B,EAAE;gBAC7B,OAAO;YACX;YACA,OAAO;QACX;IACJ;IACA,OAAO;WACA;WACC,yBAAyB,MAAM,GAAG,IAChC;YACE;gBACI,sBAAsB;YAC1B;SACH,GACC,EAAE;KACX;AACL;AACA,SAAS,yBAAyB,IAAI;IAClC,OAAO;QACH,sBAAsB;YAClB;gBACI,MAAM,KAAK,QAAQ,CAAC,IAAI;gBACxB,aAAa,KAAK,QAAQ,CAAC,WAAW;gBACtC,YAAY,CAAA,GAAA,4LAAA,CAAA,6BAA0B,AAAD,EAAE,KAAK,QAAQ,CAAC,UAAU;YACnE;SACH;IACL;AACJ;AACA,SAAS,iBAAiB,UAAU,EAAE,KAAK;IACvC,IAAI,CAAC,WAAW,MAAM,IAAI,CAAC,OACvB,OAAO;IACX,MAAM,EAAE,UAAU,EAAE,oBAAoB,EAAE,GAAG;IAC7C,MAAM,UAAU;QACZ,KAAK,gKAAA,CAAA,sBAAmB,CAAC,GAAG;QAC5B,MAAM,gKAAA,CAAA,sBAAmB,CAAC,IAAI;QAC9B,MAAM,gKAAA,CAAA,sBAAmB,CAAC,IAAI;IAClC;IACA,IAAI,cAAc;QAAC;QAAO;QAAQ;KAAO,CAAC,QAAQ,CAAC,aAAa;QAC5D,OAAO;YACH,uBAAuB;gBACnB,MAAM,OAAO,CAAC,WAAW,IAAI;gBAC7B;YACJ;QACJ;IACJ;IACA,IAAI,OAAO,eAAe,YAAY,sBAAsB;QACxD,OAAO;YACH,uBAAuB;gBACnB,MAAM,gKAAA,CAAA,sBAAmB,CAAC,GAAG;gBAC7B,sBAAsB;uBACd,wBAAwB,EAAE;uBAC1B,cAAc,OAAO,eAAe,WAAW;wBAAC;qBAAW,GAAG,EAAE;iBACvE;YACL;QACJ;IACJ;IACA,OAAO;AACX","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 1676, "column": 0}, "map": {"version":3,"sources":["file:///Users/dylanchua/Documents/Personal/Code/neurodocument/node_modules/%40langchain/google-genai/dist/chat_models.js"],"sourcesContent":["import { GoogleGenerativeAI as GenerativeAI, } from \"@google/generative-ai\";\nimport { getEnvironmentVariable } from \"@langchain/core/utils/env\";\nimport { BaseChatModel, } from \"@langchain/core/language_models/chat_models\";\nimport { RunnablePassthrough, RunnableSequence, } from \"@langchain/core/runnables\";\nimport { isZodSchema } from \"@langchain/core/utils/types\";\nimport { JsonOutputParser, } from \"@langchain/core/output_parsers\";\nimport { schemaToGenerativeAIParameters, removeAdditionalProperties, } from \"./utils/zod_to_genai_parameters.js\";\nimport { convertBaseMessagesToContent, convertResponseContentToChatGenerationChunk, mapGenerateContentResultToChatResult, } from \"./utils/common.js\";\nimport { GoogleGenerativeAIToolsOutputParser } from \"./output_parsers.js\";\nimport { convertToolsToGenAI } from \"./utils/tools.js\";\n/**\n * Google Generative AI chat model integration.\n *\n * Setup:\n * Install `@langchain/google-genai` and set an environment variable named `GOOGLE_API_KEY`.\n *\n * ```bash\n * npm install @langchain/google-genai\n * export GOOGLE_API_KEY=\"your-api-key\"\n * ```\n *\n * ## [Constructor args](https://api.js.langchain.com/classes/langchain_google_genai.ChatGoogleGenerativeAI.html#constructor)\n *\n * ## [Runtime args](https://api.js.langchain.com/interfaces/langchain_google_genai.GoogleGenerativeAIChatCallOptions.html)\n *\n * Runtime args can be passed as the second argument to any of the base runnable methods `.invoke`. `.stream`, `.batch`, etc.\n * They can also be passed via `.bind`, or the second arg in `.bindTools`, like shown in the examples below:\n *\n * ```typescript\n * // When calling `.bind`, call options should be passed via the first argument\n * const llmWithArgsBound = llm.bind({\n *   stop: [\"\\n\"],\n *   tools: [...],\n * });\n *\n * // When calling `.bindTools`, call options should be passed via the second argument\n * const llmWithTools = llm.bindTools(\n *   [...],\n *   {\n *     stop: [\"\\n\"],\n *   }\n * );\n * ```\n *\n * ## Examples\n *\n * <details open>\n * <summary><strong>Instantiate</strong></summary>\n *\n * ```typescript\n * import { ChatGoogleGenerativeAI } from '@langchain/google-genai';\n *\n * const llm = new ChatGoogleGenerativeAI({\n *   model: \"gemini-1.5-flash\",\n *   temperature: 0,\n *   maxRetries: 2,\n *   // apiKey: \"...\",\n *   // other params...\n * });\n * ```\n * </details>\n *\n * <br />\n *\n * <details>\n * <summary><strong>Invoking</strong></summary>\n *\n * ```typescript\n * const input = `Translate \"I love programming\" into French.`;\n *\n * // Models also accept a list of chat messages or a formatted prompt\n * const result = await llm.invoke(input);\n * console.log(result);\n * ```\n *\n * ```txt\n * AIMessage {\n *   \"content\": \"There are a few ways to translate \\\"I love programming\\\" into French, depending on the level of formality and nuance you want to convey:\\n\\n**Formal:**\\n\\n* **J'aime la programmation.** (This is the most literal and formal translation.)\\n\\n**Informal:**\\n\\n* **J'adore programmer.** (This is a more enthusiastic and informal translation.)\\n* **J'aime beaucoup programmer.** (This is a slightly less enthusiastic but still informal translation.)\\n\\n**More specific:**\\n\\n* **J'aime beaucoup coder.** (This specifically refers to writing code.)\\n* **J'aime beaucoup développer des logiciels.** (This specifically refers to developing software.)\\n\\nThe best translation will depend on the context and your intended audience. \\n\",\n *   \"response_metadata\": {\n *     \"finishReason\": \"STOP\",\n *     \"index\": 0,\n *     \"safetyRatings\": [\n *       {\n *         \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n *         \"probability\": \"NEGLIGIBLE\"\n *       },\n *       {\n *         \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n *         \"probability\": \"NEGLIGIBLE\"\n *       },\n *       {\n *         \"category\": \"HARM_CATEGORY_HARASSMENT\",\n *         \"probability\": \"NEGLIGIBLE\"\n *       },\n *       {\n *         \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n *         \"probability\": \"NEGLIGIBLE\"\n *       }\n *     ]\n *   },\n *   \"usage_metadata\": {\n *     \"input_tokens\": 10,\n *     \"output_tokens\": 149,\n *     \"total_tokens\": 159\n *   }\n * }\n * ```\n * </details>\n *\n * <br />\n *\n * <details>\n * <summary><strong>Streaming Chunks</strong></summary>\n *\n * ```typescript\n * for await (const chunk of await llm.stream(input)) {\n *   console.log(chunk);\n * }\n * ```\n *\n * ```txt\n * AIMessageChunk {\n *   \"content\": \"There\",\n *   \"response_metadata\": {\n *     \"index\": 0\n *   }\n *   \"usage_metadata\": {\n *     \"input_tokens\": 10,\n *     \"output_tokens\": 1,\n *     \"total_tokens\": 11\n *   }\n * }\n * AIMessageChunk {\n *   \"content\": \" are a few ways to translate \\\"I love programming\\\" into French, depending on\",\n * }\n * AIMessageChunk {\n *   \"content\": \" the level of formality and nuance you want to convey:\\n\\n**Formal:**\\n\\n\",\n * }\n * AIMessageChunk {\n *   \"content\": \"* **J'aime la programmation.** (This is the most literal and formal translation.)\\n\\n**Informal:**\\n\\n* **J'adore programmer.** (This\",\n * }\n * AIMessageChunk {\n *   \"content\": \" is a more enthusiastic and informal translation.)\\n* **J'aime beaucoup programmer.** (This is a slightly less enthusiastic but still informal translation.)\\n\\n**More\",\n * }\n * AIMessageChunk {\n *   \"content\": \" specific:**\\n\\n* **J'aime beaucoup coder.** (This specifically refers to writing code.)\\n* **J'aime beaucoup développer des logiciels.** (This specifically refers to developing software.)\\n\\nThe best translation will depend on the context and\",\n * }\n * AIMessageChunk {\n *   \"content\": \" your intended audience. \\n\",\n * }\n * ```\n * </details>\n *\n * <br />\n *\n * <details>\n * <summary><strong>Aggregate Streamed Chunks</strong></summary>\n *\n * ```typescript\n * import { AIMessageChunk } from '@langchain/core/messages';\n * import { concat } from '@langchain/core/utils/stream';\n *\n * const stream = await llm.stream(input);\n * let full: AIMessageChunk | undefined;\n * for await (const chunk of stream) {\n *   full = !full ? chunk : concat(full, chunk);\n * }\n * console.log(full);\n * ```\n *\n * ```txt\n * AIMessageChunk {\n *   \"content\": \"There are a few ways to translate \\\"I love programming\\\" into French, depending on the level of formality and nuance you want to convey:\\n\\n**Formal:**\\n\\n* **J'aime la programmation.** (This is the most literal and formal translation.)\\n\\n**Informal:**\\n\\n* **J'adore programmer.** (This is a more enthusiastic and informal translation.)\\n* **J'aime beaucoup programmer.** (This is a slightly less enthusiastic but still informal translation.)\\n\\n**More specific:**\\n\\n* **J'aime beaucoup coder.** (This specifically refers to writing code.)\\n* **J'aime beaucoup développer des logiciels.** (This specifically refers to developing software.)\\n\\nThe best translation will depend on the context and your intended audience. \\n\",\n *   \"usage_metadata\": {\n *     \"input_tokens\": 10,\n *     \"output_tokens\": 277,\n *     \"total_tokens\": 287\n *   }\n * }\n * ```\n * </details>\n *\n * <br />\n *\n * <details>\n * <summary><strong>Bind tools</strong></summary>\n *\n * ```typescript\n * import { z } from 'zod';\n *\n * const GetWeather = {\n *   name: \"GetWeather\",\n *   description: \"Get the current weather in a given location\",\n *   schema: z.object({\n *     location: z.string().describe(\"The city and state, e.g. San Francisco, CA\")\n *   }),\n * }\n *\n * const GetPopulation = {\n *   name: \"GetPopulation\",\n *   description: \"Get the current population in a given location\",\n *   schema: z.object({\n *     location: z.string().describe(\"The city and state, e.g. San Francisco, CA\")\n *   }),\n * }\n *\n * const llmWithTools = llm.bindTools([GetWeather, GetPopulation]);\n * const aiMsg = await llmWithTools.invoke(\n *   \"Which city is hotter today and which is bigger: LA or NY?\"\n * );\n * console.log(aiMsg.tool_calls);\n * ```\n *\n * ```txt\n * [\n *   {\n *     name: 'GetWeather',\n *     args: { location: 'Los Angeles, CA' },\n *     type: 'tool_call'\n *   },\n *   {\n *     name: 'GetWeather',\n *     args: { location: 'New York, NY' },\n *     type: 'tool_call'\n *   },\n *   {\n *     name: 'GetPopulation',\n *     args: { location: 'Los Angeles, CA' },\n *     type: 'tool_call'\n *   },\n *   {\n *     name: 'GetPopulation',\n *     args: { location: 'New York, NY' },\n *     type: 'tool_call'\n *   }\n * ]\n * ```\n * </details>\n *\n * <br />\n *\n * <details>\n * <summary><strong>Structured Output</strong></summary>\n *\n * ```typescript\n * const Joke = z.object({\n *   setup: z.string().describe(\"The setup of the joke\"),\n *   punchline: z.string().describe(\"The punchline to the joke\"),\n *   rating: z.number().optional().describe(\"How funny the joke is, from 1 to 10\")\n * }).describe('Joke to tell user.');\n *\n * const structuredLlm = llm.withStructuredOutput(Joke, { name: \"Joke\" });\n * const jokeResult = await structuredLlm.invoke(\"Tell me a joke about cats\");\n * console.log(jokeResult);\n * ```\n *\n * ```txt\n * {\n *   setup: \"Why don\\\\'t cats play poker?\",\n *   punchline: \"Why don\\\\'t cats play poker? Because they always have an ace up their sleeve!\"\n * }\n * ```\n * </details>\n *\n * <br />\n *\n * <details>\n * <summary><strong>Multimodal</strong></summary>\n *\n * ```typescript\n * import { HumanMessage } from '@langchain/core/messages';\n *\n * const imageUrl = \"https://example.com/image.jpg\";\n * const imageData = await fetch(imageUrl).then(res => res.arrayBuffer());\n * const base64Image = Buffer.from(imageData).toString('base64');\n *\n * const message = new HumanMessage({\n *   content: [\n *     { type: \"text\", text: \"describe the weather in this image\" },\n *     {\n *       type: \"image_url\",\n *       image_url: { url: `data:image/jpeg;base64,${base64Image}` },\n *     },\n *   ]\n * });\n *\n * const imageDescriptionAiMsg = await llm.invoke([message]);\n * console.log(imageDescriptionAiMsg.content);\n * ```\n *\n * ```txt\n * The weather in the image appears to be clear and sunny. The sky is mostly blue with a few scattered white clouds, indicating fair weather. The bright sunlight is casting shadows on the green, grassy hill, suggesting it is a pleasant day with good visibility. There are no signs of rain or stormy conditions.\n * ```\n * </details>\n *\n * <br />\n *\n * <details>\n * <summary><strong>Usage Metadata</strong></summary>\n *\n * ```typescript\n * const aiMsgForMetadata = await llm.invoke(input);\n * console.log(aiMsgForMetadata.usage_metadata);\n * ```\n *\n * ```txt\n * { input_tokens: 10, output_tokens: 149, total_tokens: 159 }\n * ```\n * </details>\n *\n * <br />\n *\n * <details>\n * <summary><strong>Response Metadata</strong></summary>\n *\n * ```typescript\n * const aiMsgForResponseMetadata = await llm.invoke(input);\n * console.log(aiMsgForResponseMetadata.response_metadata);\n * ```\n *\n * ```txt\n * {\n *   finishReason: 'STOP',\n *   index: 0,\n *   safetyRatings: [\n *     {\n *       category: 'HARM_CATEGORY_SEXUALLY_EXPLICIT',\n *       probability: 'NEGLIGIBLE'\n *     },\n *     {\n *       category: 'HARM_CATEGORY_HATE_SPEECH',\n *       probability: 'NEGLIGIBLE'\n *     },\n *     { category: 'HARM_CATEGORY_HARASSMENT', probability: 'NEGLIGIBLE' },\n *     {\n *       category: 'HARM_CATEGORY_DANGEROUS_CONTENT',\n *       probability: 'NEGLIGIBLE'\n *     }\n *   ]\n * }\n * ```\n * </details>\n *\n * <br />\n *\n * <details>\n * <summary><strong>Document Messages</strong></summary>\n *\n * This example will show you how to pass documents such as PDFs to Google\n * Generative AI through messages.\n *\n * ```typescript\n * const pdfPath = \"/Users/my_user/Downloads/invoice.pdf\";\n * const pdfBase64 = await fs.readFile(pdfPath, \"base64\");\n *\n * const response = await llm.invoke([\n *   [\"system\", \"Use the provided documents to answer the question\"],\n *   [\n *     \"user\",\n *     [\n *       {\n *         type: \"application/pdf\", // If the `type` field includes a single slash (`/`), it will be treated as inline data.\n *         data: pdfBase64,\n *       },\n *       {\n *         type: \"text\",\n *         text: \"Summarize the contents of this PDF\",\n *       },\n *     ],\n *   ],\n * ]);\n *\n * console.log(response.content);\n * ```\n *\n * ```txt\n * This is a billing invoice from Twitter Developers for X API Basic Access. The transaction date is January 7, 2025,\n * and the amount is $194.34, which has been paid. The subscription period is from January 7, 2025 21:02 to February 7, 2025 00:00 (UTC).\n * The tax is $0.00, with a tax rate of 0%. The total amount is $194.34. The payment was made using a Visa card ending in 7022,\n * expiring in 12/2026. The billing address is Brace Sproul, 1234 Main Street, San Francisco, CA, US 94103. The company being billed is\n * X Corp, located at 865 FM 1209 Building 2, Bastrop, TX, US 78602. Terms and conditions apply.\n * ```\n * </details>\n *\n * <br />\n */\nexport class ChatGoogleGenerativeAI extends BaseChatModel {\n    static lc_name() {\n        return \"ChatGoogleGenerativeAI\";\n    }\n    get lc_secrets() {\n        return {\n            apiKey: \"GOOGLE_API_KEY\",\n        };\n    }\n    get lc_aliases() {\n        return {\n            apiKey: \"google_api_key\",\n        };\n    }\n    get _isMultimodalModel() {\n        return (this.model.includes(\"vision\") ||\n            this.model.startsWith(\"gemini-1.5\") ||\n            this.model.startsWith(\"gemini-2\"));\n    }\n    constructor(fields) {\n        super(fields);\n        Object.defineProperty(this, \"lc_serializable\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: true\n        });\n        Object.defineProperty(this, \"lc_namespace\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: [\"langchain\", \"chat_models\", \"google_genai\"]\n        });\n        Object.defineProperty(this, \"model\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"temperature\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        }); // default value chosen based on model\n        Object.defineProperty(this, \"maxOutputTokens\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"topP\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        }); // default value chosen based on model\n        Object.defineProperty(this, \"topK\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        }); // default value chosen based on model\n        Object.defineProperty(this, \"stopSequences\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: []\n        });\n        Object.defineProperty(this, \"safetySettings\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"apiKey\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"streaming\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: false\n        });\n        Object.defineProperty(this, \"json\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"streamUsage\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: true\n        });\n        Object.defineProperty(this, \"convertSystemMessageToHumanContent\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"client\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        this.model = fields.model.replace(/^models\\//, \"\");\n        this.maxOutputTokens = fields.maxOutputTokens ?? this.maxOutputTokens;\n        if (this.maxOutputTokens && this.maxOutputTokens < 0) {\n            throw new Error(\"`maxOutputTokens` must be a positive integer\");\n        }\n        this.temperature = fields.temperature ?? this.temperature;\n        if (this.temperature && (this.temperature < 0 || this.temperature > 2)) {\n            throw new Error(\"`temperature` must be in the range of [0.0,2.0]\");\n        }\n        this.topP = fields.topP ?? this.topP;\n        if (this.topP && this.topP < 0) {\n            throw new Error(\"`topP` must be a positive integer\");\n        }\n        if (this.topP && this.topP > 1) {\n            throw new Error(\"`topP` must be below 1.\");\n        }\n        this.topK = fields.topK ?? this.topK;\n        if (this.topK && this.topK < 0) {\n            throw new Error(\"`topK` must be a positive integer\");\n        }\n        this.stopSequences = fields.stopSequences ?? this.stopSequences;\n        this.apiKey = fields.apiKey ?? getEnvironmentVariable(\"GOOGLE_API_KEY\");\n        if (!this.apiKey) {\n            throw new Error(\"Please set an API key for Google GenerativeAI \" +\n                \"in the environment variable GOOGLE_API_KEY \" +\n                \"or in the `apiKey` field of the \" +\n                \"ChatGoogleGenerativeAI constructor\");\n        }\n        this.safetySettings = fields.safetySettings ?? this.safetySettings;\n        if (this.safetySettings && this.safetySettings.length > 0) {\n            const safetySettingsSet = new Set(this.safetySettings.map((s) => s.category));\n            if (safetySettingsSet.size !== this.safetySettings.length) {\n                throw new Error(\"The categories in `safetySettings` array must be unique\");\n            }\n        }\n        this.streaming = fields.streaming ?? this.streaming;\n        this.json = fields.json;\n        this.client = new GenerativeAI(this.apiKey).getGenerativeModel({\n            model: this.model,\n            safetySettings: this.safetySettings,\n            generationConfig: {\n                stopSequences: this.stopSequences,\n                maxOutputTokens: this.maxOutputTokens,\n                temperature: this.temperature,\n                topP: this.topP,\n                topK: this.topK,\n                ...(this.json ? { responseMimeType: \"application/json\" } : {}),\n            },\n        }, {\n            apiVersion: fields.apiVersion,\n            baseUrl: fields.baseUrl,\n        });\n        this.streamUsage = fields.streamUsage ?? this.streamUsage;\n    }\n    useCachedContent(cachedContent, modelParams, requestOptions) {\n        if (!this.apiKey)\n            return;\n        this.client = new GenerativeAI(this.apiKey).getGenerativeModelFromCachedContent(cachedContent, modelParams, requestOptions);\n    }\n    get useSystemInstruction() {\n        return typeof this.convertSystemMessageToHumanContent === \"boolean\"\n            ? !this.convertSystemMessageToHumanContent\n            : this.computeUseSystemInstruction;\n    }\n    get computeUseSystemInstruction() {\n        // This works on models from April 2024 and later\n        //   Vertex AI: gemini-1.5-pro and gemini-1.0-002 and later\n        //   AI Studio: gemini-1.5-pro-latest\n        if (this.model === \"gemini-1.0-pro-001\") {\n            return false;\n        }\n        else if (this.model.startsWith(\"gemini-pro-vision\")) {\n            return false;\n        }\n        else if (this.model.startsWith(\"gemini-1.0-pro-vision\")) {\n            return false;\n        }\n        else if (this.model === \"gemini-pro\") {\n            // on AI Studio gemini-pro is still pointing at gemini-1.0-pro-001\n            return false;\n        }\n        return true;\n    }\n    getLsParams(options) {\n        return {\n            ls_provider: \"google_genai\",\n            ls_model_name: this.model,\n            ls_model_type: \"chat\",\n            ls_temperature: this.client.generationConfig.temperature,\n            ls_max_tokens: this.client.generationConfig.maxOutputTokens,\n            ls_stop: options.stop,\n        };\n    }\n    _combineLLMOutput() {\n        return [];\n    }\n    _llmType() {\n        return \"googlegenerativeai\";\n    }\n    bindTools(tools, kwargs) {\n        return this.bind({ tools: convertToolsToGenAI(tools)?.tools, ...kwargs });\n    }\n    invocationParams(options) {\n        const toolsAndConfig = options?.tools?.length\n            ? convertToolsToGenAI(options.tools, {\n                toolChoice: options.tool_choice,\n                allowedFunctionNames: options.allowedFunctionNames,\n            })\n            : undefined;\n        if (options?.responseSchema) {\n            this.client.generationConfig.responseSchema = options.responseSchema;\n            this.client.generationConfig.responseMimeType = \"application/json\";\n        }\n        else {\n            this.client.generationConfig.responseSchema = undefined;\n            this.client.generationConfig.responseMimeType = this.json\n                ? \"application/json\"\n                : undefined;\n        }\n        return {\n            ...(toolsAndConfig?.tools ? { tools: toolsAndConfig.tools } : {}),\n            ...(toolsAndConfig?.toolConfig\n                ? { toolConfig: toolsAndConfig.toolConfig }\n                : {}),\n        };\n    }\n    async _generate(messages, options, runManager) {\n        const prompt = convertBaseMessagesToContent(messages, this._isMultimodalModel, this.useSystemInstruction);\n        let actualPrompt = prompt;\n        if (prompt[0].role === \"system\") {\n            const [systemInstruction] = prompt;\n            this.client.systemInstruction = systemInstruction;\n            actualPrompt = prompt.slice(1);\n        }\n        const parameters = this.invocationParams(options);\n        // Handle streaming\n        if (this.streaming) {\n            const tokenUsage = {};\n            const stream = this._streamResponseChunks(messages, options, runManager);\n            const finalChunks = {};\n            for await (const chunk of stream) {\n                const index = chunk.generationInfo?.completion ?? 0;\n                if (finalChunks[index] === undefined) {\n                    finalChunks[index] = chunk;\n                }\n                else {\n                    finalChunks[index] = finalChunks[index].concat(chunk);\n                }\n            }\n            const generations = Object.entries(finalChunks)\n                .sort(([aKey], [bKey]) => parseInt(aKey, 10) - parseInt(bKey, 10))\n                .map(([_, value]) => value);\n            return { generations, llmOutput: { estimatedTokenUsage: tokenUsage } };\n        }\n        const res = await this.completionWithRetry({\n            ...parameters,\n            contents: actualPrompt,\n        });\n        let usageMetadata;\n        if (\"usageMetadata\" in res.response) {\n            const genAIUsageMetadata = res.response.usageMetadata;\n            usageMetadata = {\n                input_tokens: genAIUsageMetadata.promptTokenCount ?? 0,\n                output_tokens: genAIUsageMetadata.candidatesTokenCount ?? 0,\n                total_tokens: genAIUsageMetadata.totalTokenCount ?? 0,\n            };\n        }\n        const generationResult = mapGenerateContentResultToChatResult(res.response, {\n            usageMetadata,\n        });\n        await runManager?.handleLLMNewToken(generationResult.generations[0].text ?? \"\");\n        return generationResult;\n    }\n    async *_streamResponseChunks(messages, options, runManager) {\n        const prompt = convertBaseMessagesToContent(messages, this._isMultimodalModel, this.useSystemInstruction);\n        let actualPrompt = prompt;\n        if (prompt[0].role === \"system\") {\n            const [systemInstruction] = prompt;\n            this.client.systemInstruction = systemInstruction;\n            actualPrompt = prompt.slice(1);\n        }\n        const parameters = this.invocationParams(options);\n        const request = {\n            ...parameters,\n            contents: actualPrompt,\n        };\n        const stream = await this.caller.callWithOptions({ signal: options?.signal }, async () => {\n            const { stream } = await this.client.generateContentStream(request);\n            return stream;\n        });\n        let usageMetadata;\n        let index = 0;\n        for await (const response of stream) {\n            if (\"usageMetadata\" in response &&\n                this.streamUsage !== false &&\n                options.streamUsage !== false) {\n                const genAIUsageMetadata = response.usageMetadata;\n                if (!usageMetadata) {\n                    usageMetadata = {\n                        input_tokens: genAIUsageMetadata.promptTokenCount ?? 0,\n                        output_tokens: genAIUsageMetadata.candidatesTokenCount ?? 0,\n                        total_tokens: genAIUsageMetadata.totalTokenCount ?? 0,\n                    };\n                }\n                else {\n                    // Under the hood, LangChain combines the prompt tokens. Google returns the updated\n                    // total each time, so we need to find the difference between the tokens.\n                    const outputTokenDiff = (genAIUsageMetadata.candidatesTokenCount ?? 0) -\n                        usageMetadata.output_tokens;\n                    usageMetadata = {\n                        input_tokens: 0,\n                        output_tokens: outputTokenDiff,\n                        total_tokens: outputTokenDiff,\n                    };\n                }\n            }\n            const chunk = convertResponseContentToChatGenerationChunk(response, {\n                usageMetadata,\n                index,\n            });\n            index += 1;\n            if (!chunk) {\n                continue;\n            }\n            yield chunk;\n            await runManager?.handleLLMNewToken(chunk.text ?? \"\");\n        }\n    }\n    async completionWithRetry(request, options) {\n        return this.caller.callWithOptions({ signal: options?.signal }, async () => {\n            try {\n                return await this.client.generateContent(request);\n                // eslint-disable-next-line @typescript-eslint/no-explicit-any\n            }\n            catch (e) {\n                // TODO: Improve error handling\n                if (e.message?.includes(\"400 Bad Request\")) {\n                    e.status = 400;\n                }\n                throw e;\n            }\n        });\n    }\n    withStructuredOutput(outputSchema, config) {\n        // eslint-disable-next-line @typescript-eslint/no-explicit-any\n        const schema = outputSchema;\n        const name = config?.name;\n        const method = config?.method;\n        const includeRaw = config?.includeRaw;\n        if (method === \"jsonMode\") {\n            throw new Error(`ChatGoogleGenerativeAI only supports \"jsonSchema\" or \"functionCalling\" as a method.`);\n        }\n        let llm;\n        let outputParser;\n        if (method === \"functionCalling\") {\n            let functionName = name ?? \"extract\";\n            let tools;\n            if (isZodSchema(schema)) {\n                const jsonSchema = schemaToGenerativeAIParameters(schema);\n                tools = [\n                    {\n                        functionDeclarations: [\n                            {\n                                name: functionName,\n                                description: jsonSchema.description ?? \"A function available to call.\",\n                                parameters: jsonSchema,\n                            },\n                        ],\n                    },\n                ];\n                outputParser = new GoogleGenerativeAIToolsOutputParser({\n                    returnSingle: true,\n                    keyName: functionName,\n                    zodSchema: schema,\n                });\n            }\n            else {\n                let geminiFunctionDefinition;\n                if (typeof schema.name === \"string\" &&\n                    typeof schema.parameters === \"object\" &&\n                    schema.parameters != null) {\n                    geminiFunctionDefinition = schema;\n                    geminiFunctionDefinition.parameters = removeAdditionalProperties(schema.parameters);\n                    functionName = schema.name;\n                }\n                else {\n                    geminiFunctionDefinition = {\n                        name: functionName,\n                        description: schema.description ?? \"\",\n                        parameters: removeAdditionalProperties(schema),\n                    };\n                }\n                tools = [\n                    {\n                        functionDeclarations: [geminiFunctionDefinition],\n                    },\n                ];\n                outputParser = new GoogleGenerativeAIToolsOutputParser({\n                    returnSingle: true,\n                    keyName: functionName,\n                });\n            }\n            llm = this.bind({\n                tools,\n                tool_choice: functionName,\n            });\n        }\n        else {\n            const jsonSchema = schemaToGenerativeAIParameters(schema);\n            llm = this.bind({\n                responseSchema: jsonSchema,\n            });\n            outputParser = new JsonOutputParser();\n        }\n        if (!includeRaw) {\n            return llm.pipe(outputParser).withConfig({\n                runName: \"ChatGoogleGenerativeAIStructuredOutput\",\n            });\n        }\n        const parserAssign = RunnablePassthrough.assign({\n            // eslint-disable-next-line @typescript-eslint/no-explicit-any\n            parsed: (input, config) => outputParser.invoke(input.raw, config),\n        });\n        const parserNone = RunnablePassthrough.assign({\n            parsed: () => null,\n        });\n        const parsedWithFallback = parserAssign.withFallbacks({\n            fallbacks: [parserNone],\n        });\n        return RunnableSequence.from([\n            {\n                raw: llm,\n            },\n            parsedWithFallback,\n        ]).withConfig({\n            runName: \"StructuredOutputRunnable\",\n        });\n    }\n}\n"],"names":[],"mappings":";;;AAAA;AACA;AAAA;AACA;AAAA;AACA;AAAA;AAAA;AACA;AAAA;AACA;AAAA;AACA;AACA;AACA;AACA;;;;;;;;;;;AAyXO,MAAM,+BAA+B,+KAAA,CAAA,gBAAa;IACrD,OAAO,UAAU;QACb,OAAO;IACX;IACA,IAAI,aAAa;QACb,OAAO;YACH,QAAQ;QACZ;IACJ;IACA,IAAI,aAAa;QACb,OAAO;YACH,QAAQ;QACZ;IACJ;IACA,IAAI,qBAAqB;QACrB,OAAQ,IAAI,CAAC,KAAK,CAAC,QAAQ,CAAC,aACxB,IAAI,CAAC,KAAK,CAAC,UAAU,CAAC,iBACtB,IAAI,CAAC,KAAK,CAAC,UAAU,CAAC;IAC9B;IACA,YAAY,MAAM,CAAE;QAChB,KAAK,CAAC;QACN,OAAO,cAAc,CAAC,IAAI,EAAE,mBAAmB;YAC3C,YAAY;YACZ,cAAc;YACd,UAAU;YACV,OAAO;QACX;QACA,OAAO,cAAc,CAAC,IAAI,EAAE,gBAAgB;YACxC,YAAY;YACZ,cAAc;YACd,UAAU;YACV,OAAO;gBAAC;gBAAa;gBAAe;aAAe;QACvD;QACA,OAAO,cAAc,CAAC,IAAI,EAAE,SAAS;YACjC,YAAY;YACZ,cAAc;YACd,UAAU;YACV,OAAO,KAAK;QAChB;QACA,OAAO,cAAc,CAAC,IAAI,EAAE,eAAe;YACvC,YAAY;YACZ,cAAc;YACd,UAAU;YACV,OAAO,KAAK;QAChB,IAAI,sCAAsC;QAC1C,OAAO,cAAc,CAAC,IAAI,EAAE,mBAAmB;YAC3C,YAAY;YACZ,cAAc;YACd,UAAU;YACV,OAAO,KAAK;QAChB;QACA,OAAO,cAAc,CAAC,IAAI,EAAE,QAAQ;YAChC,YAAY;YACZ,cAAc;YACd,UAAU;YACV,OAAO,KAAK;QAChB,IAAI,sCAAsC;QAC1C,OAAO,cAAc,CAAC,IAAI,EAAE,QAAQ;YAChC,YAAY;YACZ,cAAc;YACd,UAAU;YACV,OAAO,KAAK;QAChB,IAAI,sCAAsC;QAC1C,OAAO,cAAc,CAAC,IAAI,EAAE,iBAAiB;YACzC,YAAY;YACZ,cAAc;YACd,UAAU;YACV,OAAO,EAAE;QACb;QACA,OAAO,cAAc,CAAC,IAAI,EAAE,kBAAkB;YAC1C,YAAY;YACZ,cAAc;YACd,UAAU;YACV,OAAO,KAAK;QAChB;QACA,OAAO,cAAc,CAAC,IAAI,EAAE,UAAU;YAClC,YAAY;YACZ,cAAc;YACd,UAAU;YACV,OAAO,KAAK;QAChB;QACA,OAAO,cAAc,CAAC,IAAI,EAAE,aAAa;YACrC,YAAY;YACZ,cAAc;YACd,UAAU;YACV,OAAO;QACX;QACA,OAAO,cAAc,CAAC,IAAI,EAAE,QAAQ;YAChC,YAAY;YACZ,cAAc;YACd,UAAU;YACV,OAAO,KAAK;QAChB;QACA,OAAO,cAAc,CAAC,IAAI,EAAE,eAAe;YACvC,YAAY;YACZ,cAAc;YACd,UAAU;YACV,OAAO;QACX;QACA,OAAO,cAAc,CAAC,IAAI,EAAE,sCAAsC;YAC9D,YAAY;YACZ,cAAc;YACd,UAAU;YACV,OAAO,KAAK;QAChB;QACA,OAAO,cAAc,CAAC,IAAI,EAAE,UAAU;YAClC,YAAY;YACZ,cAAc;YACd,UAAU;YACV,OAAO,KAAK;QAChB;QACA,IAAI,CAAC,KAAK,GAAG,OAAO,KAAK,CAAC,OAAO,CAAC,aAAa;QAC/C,IAAI,CAAC,eAAe,GAAG,OAAO,eAAe,IAAI,IAAI,CAAC,eAAe;QACrE,IAAI,IAAI,CAAC,eAAe,IAAI,IAAI,CAAC,eAAe,GAAG,GAAG;YAClD,MAAM,IAAI,MAAM;QACpB;QACA,IAAI,CAAC,WAAW,GAAG,OAAO,WAAW,IAAI,IAAI,CAAC,WAAW;QACzD,IAAI,IAAI,CAAC,WAAW,IAAI,CAAC,IAAI,CAAC,WAAW,GAAG,KAAK,IAAI,CAAC,WAAW,GAAG,CAAC,GAAG;YACpE,MAAM,IAAI,MAAM;QACpB;QACA,IAAI,CAAC,IAAI,GAAG,OAAO,IAAI,IAAI,IAAI,CAAC,IAAI;QACpC,IAAI,IAAI,CAAC,IAAI,IAAI,IAAI,CAAC,IAAI,GAAG,GAAG;YAC5B,MAAM,IAAI,MAAM;QACpB;QACA,IAAI,IAAI,CAAC,IAAI,IAAI,IAAI,CAAC,IAAI,GAAG,GAAG;YAC5B,MAAM,IAAI,MAAM;QACpB;QACA,IAAI,CAAC,IAAI,GAAG,OAAO,IAAI,IAAI,IAAI,CAAC,IAAI;QACpC,IAAI,IAAI,CAAC,IAAI,IAAI,IAAI,CAAC,IAAI,GAAG,GAAG;YAC5B,MAAM,IAAI,MAAM;QACpB;QACA,IAAI,CAAC,aAAa,GAAG,OAAO,aAAa,IAAI,IAAI,CAAC,aAAa;QAC/D,IAAI,CAAC,MAAM,GAAG,OAAO,MAAM,IAAI,CAAA,GAAA,6JAAA,CAAA,yBAAsB,AAAD,EAAE;QACtD,IAAI,CAAC,IAAI,CAAC,MAAM,EAAE;YACd,MAAM,IAAI,MAAM,mDACZ,gDACA,qCACA;QACR;QACA,IAAI,CAAC,cAAc,GAAG,OAAO,cAAc,IAAI,IAAI,CAAC,cAAc;QAClE,IAAI,IAAI,CAAC,cAAc,IAAI,IAAI,CAAC,cAAc,CAAC,MAAM,GAAG,GAAG;YACvD,MAAM,oBAAoB,IAAI,IAAI,IAAI,CAAC,cAAc,CAAC,GAAG,CAAC,CAAC,IAAM,EAAE,QAAQ;YAC3E,IAAI,kBAAkB,IAAI,KAAK,IAAI,CAAC,cAAc,CAAC,MAAM,EAAE;gBACvD,MAAM,IAAI,MAAM;YACpB;QACJ;QACA,IAAI,CAAC,SAAS,GAAG,OAAO,SAAS,IAAI,IAAI,CAAC,SAAS;QACnD,IAAI,CAAC,IAAI,GAAG,OAAO,IAAI;QACvB,IAAI,CAAC,MAAM,GAAG,IAAI,gKAAA,CAAA,qBAAY,CAAC,IAAI,CAAC,MAAM,EAAE,kBAAkB,CAAC;YAC3D,OAAO,IAAI,CAAC,KAAK;YACjB,gBAAgB,IAAI,CAAC,cAAc;YACnC,kBAAkB;gBACd,eAAe,IAAI,CAAC,aAAa;gBACjC,iBAAiB,IAAI,CAAC,eAAe;gBACrC,aAAa,IAAI,CAAC,WAAW;gBAC7B,MAAM,IAAI,CAAC,IAAI;gBACf,MAAM,IAAI,CAAC,IAAI;gBACf,GAAI,IAAI,CAAC,IAAI,GAAG;oBAAE,kBAAkB;gBAAmB,IAAI,CAAC,CAAC;YACjE;QACJ,GAAG;YACC,YAAY,OAAO,UAAU;YAC7B,SAAS,OAAO,OAAO;QAC3B;QACA,IAAI,CAAC,WAAW,GAAG,OAAO,WAAW,IAAI,IAAI,CAAC,WAAW;IAC7D;IACA,iBAAiB,aAAa,EAAE,WAAW,EAAE,cAAc,EAAE;QACzD,IAAI,CAAC,IAAI,CAAC,MAAM,EACZ;QACJ,IAAI,CAAC,MAAM,GAAG,IAAI,gKAAA,CAAA,qBAAY,CAAC,IAAI,CAAC,MAAM,EAAE,mCAAmC,CAAC,eAAe,aAAa;IAChH;IACA,IAAI,uBAAuB;QACvB,OAAO,OAAO,IAAI,CAAC,kCAAkC,KAAK,YACpD,CAAC,IAAI,CAAC,kCAAkC,GACxC,IAAI,CAAC,2BAA2B;IAC1C;IACA,IAAI,8BAA8B;QAC9B,iDAAiD;QACjD,2DAA2D;QAC3D,qCAAqC;QACrC,IAAI,IAAI,CAAC,KAAK,KAAK,sBAAsB;YACrC,OAAO;QACX,OACK,IAAI,IAAI,CAAC,KAAK,CAAC,UAAU,CAAC,sBAAsB;YACjD,OAAO;QACX,OACK,IAAI,IAAI,CAAC,KAAK,CAAC,UAAU,CAAC,0BAA0B;YACrD,OAAO;QACX,OACK,IAAI,IAAI,CAAC,KAAK,KAAK,cAAc;YAClC,kEAAkE;YAClE,OAAO;QACX;QACA,OAAO;IACX;IACA,YAAY,OAAO,EAAE;QACjB,OAAO;YACH,aAAa;YACb,eAAe,IAAI,CAAC,KAAK;YACzB,eAAe;YACf,gBAAgB,IAAI,CAAC,MAAM,CAAC,gBAAgB,CAAC,WAAW;YACxD,eAAe,IAAI,CAAC,MAAM,CAAC,gBAAgB,CAAC,eAAe;YAC3D,SAAS,QAAQ,IAAI;QACzB;IACJ;IACA,oBAAoB;QAChB,OAAO,EAAE;IACb;IACA,WAAW;QACP,OAAO;IACX;IACA,UAAU,KAAK,EAAE,MAAM,EAAE;QACrB,OAAO,IAAI,CAAC,IAAI,CAAC;YAAE,OAAO,CAAA,GAAA,0KAAA,CAAA,sBAAmB,AAAD,EAAE,QAAQ;YAAO,GAAG,MAAM;QAAC;IAC3E;IACA,iBAAiB,OAAO,EAAE;QACtB,MAAM,iBAAiB,SAAS,OAAO,SACjC,CAAA,GAAA,0KAAA,CAAA,sBAAmB,AAAD,EAAE,QAAQ,KAAK,EAAE;YACjC,YAAY,QAAQ,WAAW;YAC/B,sBAAsB,QAAQ,oBAAoB;QACtD,KACE;QACN,IAAI,SAAS,gBAAgB;YACzB,IAAI,CAAC,MAAM,CAAC,gBAAgB,CAAC,cAAc,GAAG,QAAQ,cAAc;YACpE,IAAI,CAAC,MAAM,CAAC,gBAAgB,CAAC,gBAAgB,GAAG;QACpD,OACK;YACD,IAAI,CAAC,MAAM,CAAC,gBAAgB,CAAC,cAAc,GAAG;YAC9C,IAAI,CAAC,MAAM,CAAC,gBAAgB,CAAC,gBAAgB,GAAG,IAAI,CAAC,IAAI,GACnD,qBACA;QACV;QACA,OAAO;YACH,GAAI,gBAAgB,QAAQ;gBAAE,OAAO,eAAe,KAAK;YAAC,IAAI,CAAC,CAAC;YAChE,GAAI,gBAAgB,aACd;gBAAE,YAAY,eAAe,UAAU;YAAC,IACxC,CAAC,CAAC;QACZ;IACJ;IACA,MAAM,UAAU,QAAQ,EAAE,OAAO,EAAE,UAAU,EAAE;QAC3C,MAAM,SAAS,CAAA,GAAA,2KAAA,CAAA,+BAA4B,AAAD,EAAE,UAAU,IAAI,CAAC,kBAAkB,EAAE,IAAI,CAAC,oBAAoB;QACxG,IAAI,eAAe;QACnB,IAAI,MAAM,CAAC,EAAE,CAAC,IAAI,KAAK,UAAU;YAC7B,MAAM,CAAC,kBAAkB,GAAG;YAC5B,IAAI,CAAC,MAAM,CAAC,iBAAiB,GAAG;YAChC,eAAe,OAAO,KAAK,CAAC;QAChC;QACA,MAAM,aAAa,IAAI,CAAC,gBAAgB,CAAC;QACzC,mBAAmB;QACnB,IAAI,IAAI,CAAC,SAAS,EAAE;YAChB,MAAM,aAAa,CAAC;YACpB,MAAM,SAAS,IAAI,CAAC,qBAAqB,CAAC,UAAU,SAAS;YAC7D,MAAM,cAAc,CAAC;YACrB,WAAW,MAAM,SAAS,OAAQ;gBAC9B,MAAM,QAAQ,MAAM,cAAc,EAAE,cAAc;gBAClD,IAAI,WAAW,CAAC,MAAM,KAAK,WAAW;oBAClC,WAAW,CAAC,MAAM,GAAG;gBACzB,OACK;oBACD,WAAW,CAAC,MAAM,GAAG,WAAW,CAAC,MAAM,CAAC,MAAM,CAAC;gBACnD;YACJ;YACA,MAAM,cAAc,OAAO,OAAO,CAAC,aAC9B,IAAI,CAAC,CAAC,CAAC,KAAK,EAAE,CAAC,KAAK,GAAK,SAAS,MAAM,MAAM,SAAS,MAAM,KAC7D,GAAG,CAAC,CAAC,CAAC,GAAG,MAAM,GAAK;YACzB,OAAO;gBAAE;gBAAa,WAAW;oBAAE,qBAAqB;gBAAW;YAAE;QACzE;QACA,MAAM,MAAM,MAAM,IAAI,CAAC,mBAAmB,CAAC;YACvC,GAAG,UAAU;YACb,UAAU;QACd;QACA,IAAI;QACJ,IAAI,mBAAmB,IAAI,QAAQ,EAAE;YACjC,MAAM,qBAAqB,IAAI,QAAQ,CAAC,aAAa;YACrD,gBAAgB;gBACZ,cAAc,mBAAmB,gBAAgB,IAAI;gBACrD,eAAe,mBAAmB,oBAAoB,IAAI;gBAC1D,cAAc,mBAAmB,eAAe,IAAI;YACxD;QACJ;QACA,MAAM,mBAAmB,CAAA,GAAA,2KAAA,CAAA,uCAAoC,AAAD,EAAE,IAAI,QAAQ,EAAE;YACxE;QACJ;QACA,MAAM,YAAY,kBAAkB,iBAAiB,WAAW,CAAC,EAAE,CAAC,IAAI,IAAI;QAC5E,OAAO;IACX;IACA,OAAO,sBAAsB,QAAQ,EAAE,OAAO,EAAE,UAAU,EAAE;QACxD,MAAM,SAAS,CAAA,GAAA,2KAAA,CAAA,+BAA4B,AAAD,EAAE,UAAU,IAAI,CAAC,kBAAkB,EAAE,IAAI,CAAC,oBAAoB;QACxG,IAAI,eAAe;QACnB,IAAI,MAAM,CAAC,EAAE,CAAC,IAAI,KAAK,UAAU;YAC7B,MAAM,CAAC,kBAAkB,GAAG;YAC5B,IAAI,CAAC,MAAM,CAAC,iBAAiB,GAAG;YAChC,eAAe,OAAO,KAAK,CAAC;QAChC;QACA,MAAM,aAAa,IAAI,CAAC,gBAAgB,CAAC;QACzC,MAAM,UAAU;YACZ,GAAG,UAAU;YACb,UAAU;QACd;QACA,MAAM,SAAS,MAAM,IAAI,CAAC,MAAM,CAAC,eAAe,CAAC;YAAE,QAAQ,SAAS;QAAO,GAAG;YAC1E,MAAM,EAAE,MAAM,EAAE,GAAG,MAAM,IAAI,CAAC,MAAM,CAAC,qBAAqB,CAAC;YAC3D,OAAO;QACX;QACA,IAAI;QACJ,IAAI,QAAQ;QACZ,WAAW,MAAM,YAAY,OAAQ;YACjC,IAAI,mBAAmB,YACnB,IAAI,CAAC,WAAW,KAAK,SACrB,QAAQ,WAAW,KAAK,OAAO;gBAC/B,MAAM,qBAAqB,SAAS,aAAa;gBACjD,IAAI,CAAC,eAAe;oBAChB,gBAAgB;wBACZ,cAAc,mBAAmB,gBAAgB,IAAI;wBACrD,eAAe,mBAAmB,oBAAoB,IAAI;wBAC1D,cAAc,mBAAmB,eAAe,IAAI;oBACxD;gBACJ,OACK;oBACD,mFAAmF;oBACnF,yEAAyE;oBACzE,MAAM,kBAAkB,CAAC,mBAAmB,oBAAoB,IAAI,CAAC,IACjE,cAAc,aAAa;oBAC/B,gBAAgB;wBACZ,cAAc;wBACd,eAAe;wBACf,cAAc;oBAClB;gBACJ;YACJ;YACA,MAAM,QAAQ,CAAA,GAAA,2KAAA,CAAA,8CAA2C,AAAD,EAAE,UAAU;gBAChE;gBACA;YACJ;YACA,SAAS;YACT,IAAI,CAAC,OAAO;gBACR;YACJ;YACA,MAAM;YACN,MAAM,YAAY,kBAAkB,MAAM,IAAI,IAAI;QACtD;IACJ;IACA,MAAM,oBAAoB,OAAO,EAAE,OAAO,EAAE;QACxC,OAAO,IAAI,CAAC,MAAM,CAAC,eAAe,CAAC;YAAE,QAAQ,SAAS;QAAO,GAAG;YAC5D,IAAI;gBACA,OAAO,MAAM,IAAI,CAAC,MAAM,CAAC,eAAe,CAAC;YACzC,8DAA8D;YAClE,EACA,OAAO,GAAG;gBACN,+BAA+B;gBAC/B,IAAI,EAAE,OAAO,EAAE,SAAS,oBAAoB;oBACxC,EAAE,MAAM,GAAG;gBACf;gBACA,MAAM;YACV;QACJ;IACJ;IACA,qBAAqB,YAAY,EAAE,MAAM,EAAE;QACvC,8DAA8D;QAC9D,MAAM,SAAS;QACf,MAAM,OAAO,QAAQ;QACrB,MAAM,SAAS,QAAQ;QACvB,MAAM,aAAa,QAAQ;QAC3B,IAAI,WAAW,YAAY;YACvB,MAAM,IAAI,MAAM,CAAC,mFAAmF,CAAC;QACzG;QACA,IAAI;QACJ,IAAI;QACJ,IAAI,WAAW,mBAAmB;YAC9B,IAAI,eAAe,QAAQ;YAC3B,IAAI;YACJ,IAAI,CAAA,GAAA,gLAAA,CAAA,cAAW,AAAD,EAAE,SAAS;gBACrB,MAAM,aAAa,CAAA,GAAA,4LAAA,CAAA,iCAA8B,AAAD,EAAE;gBAClD,QAAQ;oBACJ;wBACI,sBAAsB;4BAClB;gCACI,MAAM;gCACN,aAAa,WAAW,WAAW,IAAI;gCACvC,YAAY;4BAChB;yBACH;oBACL;iBACH;gBACD,eAAe,IAAI,0KAAA,CAAA,sCAAmC,CAAC;oBACnD,cAAc;oBACd,SAAS;oBACT,WAAW;gBACf;YACJ,OACK;gBACD,IAAI;gBACJ,IAAI,OAAO,OAAO,IAAI,KAAK,YACvB,OAAO,OAAO,UAAU,KAAK,YAC7B,OAAO,UAAU,IAAI,MAAM;oBAC3B,2BAA2B;oBAC3B,yBAAyB,UAAU,GAAG,CAAA,GAAA,4LAAA,CAAA,6BAA0B,AAAD,EAAE,OAAO,UAAU;oBAClF,eAAe,OAAO,IAAI;gBAC9B,OACK;oBACD,2BAA2B;wBACvB,MAAM;wBACN,aAAa,OAAO,WAAW,IAAI;wBACnC,YAAY,CAAA,GAAA,4LAAA,CAAA,6BAA0B,AAAD,EAAE;oBAC3C;gBACJ;gBACA,QAAQ;oBACJ;wBACI,sBAAsB;4BAAC;yBAAyB;oBACpD;iBACH;gBACD,eAAe,IAAI,0KAAA,CAAA,sCAAmC,CAAC;oBACnD,cAAc;oBACd,SAAS;gBACb;YACJ;YACA,MAAM,IAAI,CAAC,IAAI,CAAC;gBACZ;gBACA,aAAa;YACjB;QACJ,OACK;YACD,MAAM,aAAa,CAAA,GAAA,4LAAA,CAAA,iCAA8B,AAAD,EAAE;YAClD,MAAM,IAAI,CAAC,IAAI,CAAC;gBACZ,gBAAgB;YACpB;YACA,eAAe,IAAI,uLAAA,CAAA,mBAAgB;QACvC;QACA,IAAI,CAAC,YAAY;YACb,OAAO,IAAI,IAAI,CAAC,cAAc,UAAU,CAAC;gBACrC,SAAS;YACb;QACJ;QACA,MAAM,eAAe,yKAAA,CAAA,sBAAmB,CAAC,MAAM,CAAC;YAC5C,8DAA8D;YAC9D,QAAQ,CAAC,OAAO,SAAW,aAAa,MAAM,CAAC,MAAM,GAAG,EAAE;QAC9D;QACA,MAAM,aAAa,yKAAA,CAAA,sBAAmB,CAAC,MAAM,CAAC;YAC1C,QAAQ,IAAM;QAClB;QACA,MAAM,qBAAqB,aAAa,aAAa,CAAC;YAClD,WAAW;gBAAC;aAAW;QAC3B;QACA,OAAO,kKAAA,CAAA,mBAAgB,CAAC,IAAI,CAAC;YACzB;gBACI,KAAK;YACT;YACA;SACH,EAAE,UAAU,CAAC;YACV,SAAS;QACb;IACJ;AACJ","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 2156, "column": 0}, "map": {"version":3,"sources":["file:///Users/dylanchua/Documents/Personal/Code/neurodocument/node_modules/%40langchain/google-genai/dist/embeddings.js"],"sourcesContent":["import { GoogleGenerativeAI } from \"@google/generative-ai\";\nimport { getEnvironmentVariable } from \"@langchain/core/utils/env\";\nimport { Embeddings } from \"@langchain/core/embeddings\";\nimport { chunkArray } from \"@langchain/core/utils/chunk_array\";\n/**\n * Class that extends the Embeddings class and provides methods for\n * generating embeddings using the Google Palm API.\n * @example\n * ```typescript\n * const model = new GoogleGenerativeAIEmbeddings({\n *   apiKey: \"<YOUR API KEY>\",\n *   modelName: \"embedding-001\",\n * });\n *\n * // Embed a single query\n * const res = await model.embedQuery(\n *   \"What would be a good company name for a company that makes colorful socks?\"\n * );\n * console.log({ res });\n *\n * // Embed multiple documents\n * const documentRes = await model.embedDocuments([\"Hello world\", \"Bye bye\"]);\n * console.log({ documentRes });\n * ```\n */\nexport class GoogleGenerativeAIEmbeddings extends Embeddings {\n    constructor(fields) {\n        super(fields ?? {});\n        Object.defineProperty(this, \"apiKey\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"modelName\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: \"embedding-001\"\n        });\n        Object.defineProperty(this, \"model\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: \"embedding-001\"\n        });\n        Object.defineProperty(this, \"taskType\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"title\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"stripNewLines\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: true\n        });\n        Object.defineProperty(this, \"maxBatchSize\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: 100\n        }); // Max batch size for embedDocuments set by GenerativeModel client's batchEmbedContents call\n        Object.defineProperty(this, \"client\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        this.modelName =\n            fields?.model?.replace(/^models\\//, \"\") ??\n                fields?.modelName?.replace(/^models\\//, \"\") ??\n                this.modelName;\n        this.model = this.modelName;\n        this.taskType = fields?.taskType ?? this.taskType;\n        this.title = fields?.title ?? this.title;\n        if (this.title && this.taskType !== \"RETRIEVAL_DOCUMENT\") {\n            throw new Error(\"title can only be sepcified with TaskType.RETRIEVAL_DOCUMENT\");\n        }\n        this.apiKey = fields?.apiKey ?? getEnvironmentVariable(\"GOOGLE_API_KEY\");\n        if (!this.apiKey) {\n            throw new Error(\"Please set an API key for Google GenerativeAI \" +\n                \"in the environmentb variable GOOGLE_API_KEY \" +\n                \"or in the `apiKey` field of the \" +\n                \"GoogleGenerativeAIEmbeddings constructor\");\n        }\n        this.client = new GoogleGenerativeAI(this.apiKey).getGenerativeModel({\n            model: this.model,\n        });\n    }\n    _convertToContent(text) {\n        const cleanedText = this.stripNewLines ? text.replace(/\\n/g, \" \") : text;\n        return {\n            content: { role: \"user\", parts: [{ text: cleanedText }] },\n            taskType: this.taskType,\n            title: this.title,\n        };\n    }\n    async _embedQueryContent(text) {\n        const req = this._convertToContent(text);\n        const res = await this.client.embedContent(req);\n        return res.embedding.values ?? [];\n    }\n    async _embedDocumentsContent(documents) {\n        const batchEmbedChunks = chunkArray(documents, this.maxBatchSize);\n        const batchEmbedRequests = batchEmbedChunks.map((chunk) => ({\n            requests: chunk.map((doc) => this._convertToContent(doc)),\n        }));\n        const responses = await Promise.allSettled(batchEmbedRequests.map((req) => this.client.batchEmbedContents(req)));\n        const embeddings = responses.flatMap((res, idx) => {\n            if (res.status === \"fulfilled\") {\n                return res.value.embeddings.map((e) => e.values || []);\n            }\n            else {\n                return Array(batchEmbedChunks[idx].length).fill([]);\n            }\n        });\n        return embeddings;\n    }\n    /**\n     * Method that takes a document as input and returns a promise that\n     * resolves to an embedding for the document. It calls the _embedText\n     * method with the document as the input.\n     * @param document Document for which to generate an embedding.\n     * @returns Promise that resolves to an embedding for the input document.\n     */\n    embedQuery(document) {\n        return this.caller.call(this._embedQueryContent.bind(this), document);\n    }\n    /**\n     * Method that takes an array of documents as input and returns a promise\n     * that resolves to a 2D array of embeddings for each document. It calls\n     * the _embedText method for each document in the array.\n     * @param documents Array of documents for which to generate embeddings.\n     * @returns Promise that resolves to a 2D array of embeddings for each input document.\n     */\n    embedDocuments(documents) {\n        return this.caller.call(this._embedDocumentsContent.bind(this), documents);\n    }\n}\n"],"names":[],"mappings":";;;AAAA;AACA;AAAA;AACA;AAAA;AACA;AAAA;;;;;AAsBO,MAAM,qCAAqC,2JAAA,CAAA,aAAU;IACxD,YAAY,MAAM,CAAE;QAChB,KAAK,CAAC,UAAU,CAAC;QACjB,OAAO,cAAc,CAAC,IAAI,EAAE,UAAU;YAClC,YAAY;YACZ,cAAc;YACd,UAAU;YACV,OAAO,KAAK;QAChB;QACA,OAAO,cAAc,CAAC,IAAI,EAAE,aAAa;YACrC,YAAY;YACZ,cAAc;YACd,UAAU;YACV,OAAO;QACX;QACA,OAAO,cAAc,CAAC,IAAI,EAAE,SAAS;YACjC,YAAY;YACZ,cAAc;YACd,UAAU;YACV,OAAO;QACX;QACA,OAAO,cAAc,CAAC,IAAI,EAAE,YAAY;YACpC,YAAY;YACZ,cAAc;YACd,UAAU;YACV,OAAO,KAAK;QAChB;QACA,OAAO,cAAc,CAAC,IAAI,EAAE,SAAS;YACjC,YAAY;YACZ,cAAc;YACd,UAAU;YACV,OAAO,KAAK;QAChB;QACA,OAAO,cAAc,CAAC,IAAI,EAAE,iBAAiB;YACzC,YAAY;YACZ,cAAc;YACd,UAAU;YACV,OAAO;QACX;QACA,OAAO,cAAc,CAAC,IAAI,EAAE,gBAAgB;YACxC,YAAY;YACZ,cAAc;YACd,UAAU;YACV,OAAO;QACX,IAAI,4FAA4F;QAChG,OAAO,cAAc,CAAC,IAAI,EAAE,UAAU;YAClC,YAAY;YACZ,cAAc;YACd,UAAU;YACV,OAAO,KAAK;QAChB;QACA,IAAI,CAAC,SAAS,GACV,QAAQ,OAAO,QAAQ,aAAa,OAChC,QAAQ,WAAW,QAAQ,aAAa,OACxC,IAAI,CAAC,SAAS;QACtB,IAAI,CAAC,KAAK,GAAG,IAAI,CAAC,SAAS;QAC3B,IAAI,CAAC,QAAQ,GAAG,QAAQ,YAAY,IAAI,CAAC,QAAQ;QACjD,IAAI,CAAC,KAAK,GAAG,QAAQ,SAAS,IAAI,CAAC,KAAK;QACxC,IAAI,IAAI,CAAC,KAAK,IAAI,IAAI,CAAC,QAAQ,KAAK,sBAAsB;YACtD,MAAM,IAAI,MAAM;QACpB;QACA,IAAI,CAAC,MAAM,GAAG,QAAQ,UAAU,CAAA,GAAA,6JAAA,CAAA,yBAAsB,AAAD,EAAE;QACvD,IAAI,CAAC,IAAI,CAAC,MAAM,EAAE;YACd,MAAM,IAAI,MAAM,mDACZ,iDACA,qCACA;QACR;QACA,IAAI,CAAC,MAAM,GAAG,IAAI,gKAAA,CAAA,qBAAkB,CAAC,IAAI,CAAC,MAAM,EAAE,kBAAkB,CAAC;YACjE,OAAO,IAAI,CAAC,KAAK;QACrB;IACJ;IACA,kBAAkB,IAAI,EAAE;QACpB,MAAM,cAAc,IAAI,CAAC,aAAa,GAAG,KAAK,OAAO,CAAC,OAAO,OAAO;QACpE,OAAO;YACH,SAAS;gBAAE,MAAM;gBAAQ,OAAO;oBAAC;wBAAE,MAAM;oBAAY;iBAAE;YAAC;YACxD,UAAU,IAAI,CAAC,QAAQ;YACvB,OAAO,IAAI,CAAC,KAAK;QACrB;IACJ;IACA,MAAM,mBAAmB,IAAI,EAAE;QAC3B,MAAM,MAAM,IAAI,CAAC,iBAAiB,CAAC;QACnC,MAAM,MAAM,MAAM,IAAI,CAAC,MAAM,CAAC,YAAY,CAAC;QAC3C,OAAO,IAAI,SAAS,CAAC,MAAM,IAAI,EAAE;IACrC;IACA,MAAM,uBAAuB,SAAS,EAAE;QACpC,MAAM,mBAAmB,CAAA,GAAA,qKAAA,CAAA,aAAU,AAAD,EAAE,WAAW,IAAI,CAAC,YAAY;QAChE,MAAM,qBAAqB,iBAAiB,GAAG,CAAC,CAAC,QAAU,CAAC;gBACxD,UAAU,MAAM,GAAG,CAAC,CAAC,MAAQ,IAAI,CAAC,iBAAiB,CAAC;YACxD,CAAC;QACD,MAAM,YAAY,MAAM,QAAQ,UAAU,CAAC,mBAAmB,GAAG,CAAC,CAAC,MAAQ,IAAI,CAAC,MAAM,CAAC,kBAAkB,CAAC;QAC1G,MAAM,aAAa,UAAU,OAAO,CAAC,CAAC,KAAK;YACvC,IAAI,IAAI,MAAM,KAAK,aAAa;gBAC5B,OAAO,IAAI,KAAK,CAAC,UAAU,CAAC,GAAG,CAAC,CAAC,IAAM,EAAE,MAAM,IAAI,EAAE;YACzD,OACK;gBACD,OAAO,MAAM,gBAAgB,CAAC,IAAI,CAAC,MAAM,EAAE,IAAI,CAAC,EAAE;YACtD;QACJ;QACA,OAAO;IACX;IACA;;;;;;KAMC,GACD,WAAW,QAAQ,EAAE;QACjB,OAAO,IAAI,CAAC,MAAM,CAAC,IAAI,CAAC,IAAI,CAAC,kBAAkB,CAAC,IAAI,CAAC,IAAI,GAAG;IAChE;IACA;;;;;;KAMC,GACD,eAAe,SAAS,EAAE;QACtB,OAAO,IAAI,CAAC,MAAM,CAAC,IAAI,CAAC,IAAI,CAAC,sBAAsB,CAAC,IAAI,CAAC,IAAI,GAAG;IACpE;AACJ","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 2296, "column": 0}, "map": {"version":3,"sources":["file:///Users/dylanchua/Documents/Personal/Code/neurodocument/node_modules/%40langchain/google-genai/dist/index.js"],"sourcesContent":["export * from \"./chat_models.js\";\nexport * from \"./embeddings.js\";\n"],"names":[],"mappings":";AAAA;AACA","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 2317, "column": 0}, "map": {"version":3,"sources":["file:///Users/dylanchua/Documents/Personal/Code/neurodocument/node_modules/%40langchain/google-genai/index.js"],"sourcesContent":["export * from './dist/index.js'"],"names":[],"mappings":";AAAA","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 2335, "column": 0}, "map": {"version":3,"sources":["file:///Users/dylanchua/Documents/Personal/Code/neurodocument/node_modules/%40langchain/textsplitters/dist/text_splitter.js"],"sourcesContent":["import { Document, BaseDocumentTransformer } from \"@langchain/core/documents\";\nimport { getEncoding } from \"@langchain/core/utils/tiktoken\";\nexport class TextSplitter extends BaseDocumentTransformer {\n    constructor(fields) {\n        super(fields);\n        Object.defineProperty(this, \"lc_namespace\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: [\"langchain\", \"document_transformers\", \"text_splitters\"]\n        });\n        Object.defineProperty(this, \"chunkSize\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: 1000\n        });\n        Object.defineProperty(this, \"chunkOverlap\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: 200\n        });\n        Object.defineProperty(this, \"keepSeparator\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: false\n        });\n        Object.defineProperty(this, \"lengthFunction\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        this.chunkSize = fields?.chunkSize ?? this.chunkSize;\n        this.chunkOverlap = fields?.chunkOverlap ?? this.chunkOverlap;\n        this.keepSeparator = fields?.keepSeparator ?? this.keepSeparator;\n        this.lengthFunction =\n            fields?.lengthFunction ?? ((text) => text.length);\n        if (this.chunkOverlap >= this.chunkSize) {\n            throw new Error(\"Cannot have chunkOverlap >= chunkSize\");\n        }\n    }\n    async transformDocuments(documents, chunkHeaderOptions = {}) {\n        return this.splitDocuments(documents, chunkHeaderOptions);\n    }\n    splitOnSeparator(text, separator) {\n        let splits;\n        if (separator) {\n            if (this.keepSeparator) {\n                const regexEscapedSeparator = separator.replace(/[/\\-\\\\^$*+?.()|[\\]{}]/g, \"\\\\$&\");\n                splits = text.split(new RegExp(`(?=${regexEscapedSeparator})`));\n            }\n            else {\n                splits = text.split(separator);\n            }\n        }\n        else {\n            splits = text.split(\"\");\n        }\n        return splits.filter((s) => s !== \"\");\n    }\n    async createDocuments(texts, \n    // eslint-disable-next-line @typescript-eslint/no-explicit-any\n    metadatas = [], chunkHeaderOptions = {}) {\n        // if no metadata is provided, we create an empty one for each text\n        // eslint-disable-next-line @typescript-eslint/no-explicit-any\n        const _metadatas = metadatas.length > 0\n            ? metadatas\n            : [...Array(texts.length)].map(() => ({}));\n        const { chunkHeader = \"\", chunkOverlapHeader = \"(cont'd) \", appendChunkOverlapHeader = false, } = chunkHeaderOptions;\n        const documents = new Array();\n        for (let i = 0; i < texts.length; i += 1) {\n            const text = texts[i];\n            let lineCounterIndex = 1;\n            let prevChunk = null;\n            let indexPrevChunk = -1;\n            for (const chunk of await this.splitText(text)) {\n                let pageContent = chunkHeader;\n                // we need to count the \\n that are in the text before getting removed by the splitting\n                const indexChunk = text.indexOf(chunk, indexPrevChunk + 1);\n                if (prevChunk === null) {\n                    const newLinesBeforeFirstChunk = this.numberOfNewLines(text, 0, indexChunk);\n                    lineCounterIndex += newLinesBeforeFirstChunk;\n                }\n                else {\n                    const indexEndPrevChunk = indexPrevChunk + (await this.lengthFunction(prevChunk));\n                    if (indexEndPrevChunk < indexChunk) {\n                        const numberOfIntermediateNewLines = this.numberOfNewLines(text, indexEndPrevChunk, indexChunk);\n                        lineCounterIndex += numberOfIntermediateNewLines;\n                    }\n                    else if (indexEndPrevChunk > indexChunk) {\n                        const numberOfIntermediateNewLines = this.numberOfNewLines(text, indexChunk, indexEndPrevChunk);\n                        lineCounterIndex -= numberOfIntermediateNewLines;\n                    }\n                    if (appendChunkOverlapHeader) {\n                        pageContent += chunkOverlapHeader;\n                    }\n                }\n                const newLinesCount = this.numberOfNewLines(chunk);\n                const loc = _metadatas[i].loc && typeof _metadatas[i].loc === \"object\"\n                    ? { ..._metadatas[i].loc }\n                    : {};\n                loc.lines = {\n                    from: lineCounterIndex,\n                    to: lineCounterIndex + newLinesCount,\n                };\n                const metadataWithLinesNumber = {\n                    ..._metadatas[i],\n                    loc,\n                };\n                pageContent += chunk;\n                documents.push(new Document({\n                    pageContent,\n                    metadata: metadataWithLinesNumber,\n                }));\n                lineCounterIndex += newLinesCount;\n                prevChunk = chunk;\n                indexPrevChunk = indexChunk;\n            }\n        }\n        return documents;\n    }\n    numberOfNewLines(text, start, end) {\n        const textSection = text.slice(start, end);\n        return (textSection.match(/\\n/g) || []).length;\n    }\n    async splitDocuments(documents, chunkHeaderOptions = {}) {\n        const selectedDocuments = documents.filter((doc) => doc.pageContent !== undefined);\n        const texts = selectedDocuments.map((doc) => doc.pageContent);\n        const metadatas = selectedDocuments.map((doc) => doc.metadata);\n        return this.createDocuments(texts, metadatas, chunkHeaderOptions);\n    }\n    joinDocs(docs, separator) {\n        const text = docs.join(separator).trim();\n        return text === \"\" ? null : text;\n    }\n    async mergeSplits(splits, separator) {\n        const docs = [];\n        const currentDoc = [];\n        let total = 0;\n        for (const d of splits) {\n            const _len = await this.lengthFunction(d);\n            if (total + _len + currentDoc.length * separator.length >\n                this.chunkSize) {\n                if (total > this.chunkSize) {\n                    console.warn(`Created a chunk of size ${total}, +\nwhich is longer than the specified ${this.chunkSize}`);\n                }\n                if (currentDoc.length > 0) {\n                    const doc = this.joinDocs(currentDoc, separator);\n                    if (doc !== null) {\n                        docs.push(doc);\n                    }\n                    // Keep on popping if:\n                    // - we have a larger chunk than in the chunk overlap\n                    // - or if we still have any chunks and the length is long\n                    while (total > this.chunkOverlap ||\n                        (total + _len + currentDoc.length * separator.length >\n                            this.chunkSize &&\n                            total > 0)) {\n                        total -= await this.lengthFunction(currentDoc[0]);\n                        currentDoc.shift();\n                    }\n                }\n            }\n            currentDoc.push(d);\n            total += _len;\n        }\n        const doc = this.joinDocs(currentDoc, separator);\n        if (doc !== null) {\n            docs.push(doc);\n        }\n        return docs;\n    }\n}\nexport class CharacterTextSplitter extends TextSplitter {\n    static lc_name() {\n        return \"CharacterTextSplitter\";\n    }\n    constructor(fields) {\n        super(fields);\n        Object.defineProperty(this, \"separator\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: \"\\n\\n\"\n        });\n        this.separator = fields?.separator ?? this.separator;\n    }\n    async splitText(text) {\n        // First we naively split the large input into a bunch of smaller ones.\n        const splits = this.splitOnSeparator(text, this.separator);\n        return this.mergeSplits(splits, this.keepSeparator ? \"\" : this.separator);\n    }\n}\nexport const SupportedTextSplitterLanguages = [\n    \"cpp\",\n    \"go\",\n    \"java\",\n    \"js\",\n    \"php\",\n    \"proto\",\n    \"python\",\n    \"rst\",\n    \"ruby\",\n    \"rust\",\n    \"scala\",\n    \"swift\",\n    \"markdown\",\n    \"latex\",\n    \"html\",\n    \"sol\",\n];\nexport class RecursiveCharacterTextSplitter extends TextSplitter {\n    static lc_name() {\n        return \"RecursiveCharacterTextSplitter\";\n    }\n    constructor(fields) {\n        super(fields);\n        Object.defineProperty(this, \"separators\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: [\"\\n\\n\", \"\\n\", \" \", \"\"]\n        });\n        this.separators = fields?.separators ?? this.separators;\n        this.keepSeparator = fields?.keepSeparator ?? true;\n    }\n    async _splitText(text, separators) {\n        const finalChunks = [];\n        // Get appropriate separator to use\n        let separator = separators[separators.length - 1];\n        let newSeparators;\n        for (let i = 0; i < separators.length; i += 1) {\n            const s = separators[i];\n            if (s === \"\") {\n                separator = s;\n                break;\n            }\n            if (text.includes(s)) {\n                separator = s;\n                newSeparators = separators.slice(i + 1);\n                break;\n            }\n        }\n        // Now that we have the separator, split the text\n        const splits = this.splitOnSeparator(text, separator);\n        // Now go merging things, recursively splitting longer texts.\n        let goodSplits = [];\n        const _separator = this.keepSeparator ? \"\" : separator;\n        for (const s of splits) {\n            if ((await this.lengthFunction(s)) < this.chunkSize) {\n                goodSplits.push(s);\n            }\n            else {\n                if (goodSplits.length) {\n                    const mergedText = await this.mergeSplits(goodSplits, _separator);\n                    finalChunks.push(...mergedText);\n                    goodSplits = [];\n                }\n                if (!newSeparators) {\n                    finalChunks.push(s);\n                }\n                else {\n                    const otherInfo = await this._splitText(s, newSeparators);\n                    finalChunks.push(...otherInfo);\n                }\n            }\n        }\n        if (goodSplits.length) {\n            const mergedText = await this.mergeSplits(goodSplits, _separator);\n            finalChunks.push(...mergedText);\n        }\n        return finalChunks;\n    }\n    async splitText(text) {\n        return this._splitText(text, this.separators);\n    }\n    static fromLanguage(language, options) {\n        return new RecursiveCharacterTextSplitter({\n            ...options,\n            separators: RecursiveCharacterTextSplitter.getSeparatorsForLanguage(language),\n        });\n    }\n    static getSeparatorsForLanguage(language) {\n        if (language === \"cpp\") {\n            return [\n                // Split along class definitions\n                \"\\nclass \",\n                // Split along function definitions\n                \"\\nvoid \",\n                \"\\nint \",\n                \"\\nfloat \",\n                \"\\ndouble \",\n                // Split along control flow statements\n                \"\\nif \",\n                \"\\nfor \",\n                \"\\nwhile \",\n                \"\\nswitch \",\n                \"\\ncase \",\n                // Split by the normal type of lines\n                \"\\n\\n\",\n                \"\\n\",\n                \" \",\n                \"\",\n            ];\n        }\n        else if (language === \"go\") {\n            return [\n                // Split along function definitions\n                \"\\nfunc \",\n                \"\\nvar \",\n                \"\\nconst \",\n                \"\\ntype \",\n                // Split along control flow statements\n                \"\\nif \",\n                \"\\nfor \",\n                \"\\nswitch \",\n                \"\\ncase \",\n                // Split by the normal type of lines\n                \"\\n\\n\",\n                \"\\n\",\n                \" \",\n                \"\",\n            ];\n        }\n        else if (language === \"java\") {\n            return [\n                // Split along class definitions\n                \"\\nclass \",\n                // Split along method definitions\n                \"\\npublic \",\n                \"\\nprotected \",\n                \"\\nprivate \",\n                \"\\nstatic \",\n                // Split along control flow statements\n                \"\\nif \",\n                \"\\nfor \",\n                \"\\nwhile \",\n                \"\\nswitch \",\n                \"\\ncase \",\n                // Split by the normal type of lines\n                \"\\n\\n\",\n                \"\\n\",\n                \" \",\n                \"\",\n            ];\n        }\n        else if (language === \"js\") {\n            return [\n                // Split along function definitions\n                \"\\nfunction \",\n                \"\\nconst \",\n                \"\\nlet \",\n                \"\\nvar \",\n                \"\\nclass \",\n                // Split along control flow statements\n                \"\\nif \",\n                \"\\nfor \",\n                \"\\nwhile \",\n                \"\\nswitch \",\n                \"\\ncase \",\n                \"\\ndefault \",\n                // Split by the normal type of lines\n                \"\\n\\n\",\n                \"\\n\",\n                \" \",\n                \"\",\n            ];\n        }\n        else if (language === \"php\") {\n            return [\n                // Split along function definitions\n                \"\\nfunction \",\n                // Split along class definitions\n                \"\\nclass \",\n                // Split along control flow statements\n                \"\\nif \",\n                \"\\nforeach \",\n                \"\\nwhile \",\n                \"\\ndo \",\n                \"\\nswitch \",\n                \"\\ncase \",\n                // Split by the normal type of lines\n                \"\\n\\n\",\n                \"\\n\",\n                \" \",\n                \"\",\n            ];\n        }\n        else if (language === \"proto\") {\n            return [\n                // Split along message definitions\n                \"\\nmessage \",\n                // Split along service definitions\n                \"\\nservice \",\n                // Split along enum definitions\n                \"\\nenum \",\n                // Split along option definitions\n                \"\\noption \",\n                // Split along import statements\n                \"\\nimport \",\n                // Split along syntax declarations\n                \"\\nsyntax \",\n                // Split by the normal type of lines\n                \"\\n\\n\",\n                \"\\n\",\n                \" \",\n                \"\",\n            ];\n        }\n        else if (language === \"python\") {\n            return [\n                // First, try to split along class definitions\n                \"\\nclass \",\n                \"\\ndef \",\n                \"\\n\\tdef \",\n                // Now split by the normal type of lines\n                \"\\n\\n\",\n                \"\\n\",\n                \" \",\n                \"\",\n            ];\n        }\n        else if (language === \"rst\") {\n            return [\n                // Split along section titles\n                \"\\n===\\n\",\n                \"\\n---\\n\",\n                \"\\n***\\n\",\n                // Split along directive markers\n                \"\\n.. \",\n                // Split by the normal type of lines\n                \"\\n\\n\",\n                \"\\n\",\n                \" \",\n                \"\",\n            ];\n        }\n        else if (language === \"ruby\") {\n            return [\n                // Split along method definitions\n                \"\\ndef \",\n                \"\\nclass \",\n                // Split along control flow statements\n                \"\\nif \",\n                \"\\nunless \",\n                \"\\nwhile \",\n                \"\\nfor \",\n                \"\\ndo \",\n                \"\\nbegin \",\n                \"\\nrescue \",\n                // Split by the normal type of lines\n                \"\\n\\n\",\n                \"\\n\",\n                \" \",\n                \"\",\n            ];\n        }\n        else if (language === \"rust\") {\n            return [\n                // Split along function definitions\n                \"\\nfn \",\n                \"\\nconst \",\n                \"\\nlet \",\n                // Split along control flow statements\n                \"\\nif \",\n                \"\\nwhile \",\n                \"\\nfor \",\n                \"\\nloop \",\n                \"\\nmatch \",\n                \"\\nconst \",\n                // Split by the normal type of lines\n                \"\\n\\n\",\n                \"\\n\",\n                \" \",\n                \"\",\n            ];\n        }\n        else if (language === \"scala\") {\n            return [\n                // Split along class definitions\n                \"\\nclass \",\n                \"\\nobject \",\n                // Split along method definitions\n                \"\\ndef \",\n                \"\\nval \",\n                \"\\nvar \",\n                // Split along control flow statements\n                \"\\nif \",\n                \"\\nfor \",\n                \"\\nwhile \",\n                \"\\nmatch \",\n                \"\\ncase \",\n                // Split by the normal type of lines\n                \"\\n\\n\",\n                \"\\n\",\n                \" \",\n                \"\",\n            ];\n        }\n        else if (language === \"swift\") {\n            return [\n                // Split along function definitions\n                \"\\nfunc \",\n                // Split along class definitions\n                \"\\nclass \",\n                \"\\nstruct \",\n                \"\\nenum \",\n                // Split along control flow statements\n                \"\\nif \",\n                \"\\nfor \",\n                \"\\nwhile \",\n                \"\\ndo \",\n                \"\\nswitch \",\n                \"\\ncase \",\n                // Split by the normal type of lines\n                \"\\n\\n\",\n                \"\\n\",\n                \" \",\n                \"\",\n            ];\n        }\n        else if (language === \"markdown\") {\n            return [\n                // First, try to split along Markdown headings (starting with level 2)\n                \"\\n## \",\n                \"\\n### \",\n                \"\\n#### \",\n                \"\\n##### \",\n                \"\\n###### \",\n                // Note the alternative syntax for headings (below) is not handled here\n                // Heading level 2\n                // ---------------\n                // End of code block\n                \"```\\n\\n\",\n                // Horizontal lines\n                \"\\n\\n***\\n\\n\",\n                \"\\n\\n---\\n\\n\",\n                \"\\n\\n___\\n\\n\",\n                // Note that this splitter doesn't handle horizontal lines defined\n                // by *three or more* of ***, ---, or ___, but this is not handled\n                \"\\n\\n\",\n                \"\\n\",\n                \" \",\n                \"\",\n            ];\n        }\n        else if (language === \"latex\") {\n            return [\n                // First, try to split along Latex sections\n                \"\\n\\\\chapter{\",\n                \"\\n\\\\section{\",\n                \"\\n\\\\subsection{\",\n                \"\\n\\\\subsubsection{\",\n                // Now split by environments\n                \"\\n\\\\begin{enumerate}\",\n                \"\\n\\\\begin{itemize}\",\n                \"\\n\\\\begin{description}\",\n                \"\\n\\\\begin{list}\",\n                \"\\n\\\\begin{quote}\",\n                \"\\n\\\\begin{quotation}\",\n                \"\\n\\\\begin{verse}\",\n                \"\\n\\\\begin{verbatim}\",\n                // Now split by math environments\n                \"\\n\\\\begin{align}\",\n                \"$$\",\n                \"$\",\n                // Now split by the normal type of lines\n                \"\\n\\n\",\n                \"\\n\",\n                \" \",\n                \"\",\n            ];\n        }\n        else if (language === \"html\") {\n            return [\n                // First, try to split along HTML tags\n                \"<body>\",\n                \"<div>\",\n                \"<p>\",\n                \"<br>\",\n                \"<li>\",\n                \"<h1>\",\n                \"<h2>\",\n                \"<h3>\",\n                \"<h4>\",\n                \"<h5>\",\n                \"<h6>\",\n                \"<span>\",\n                \"<table>\",\n                \"<tr>\",\n                \"<td>\",\n                \"<th>\",\n                \"<ul>\",\n                \"<ol>\",\n                \"<header>\",\n                \"<footer>\",\n                \"<nav>\",\n                // Head\n                \"<head>\",\n                \"<style>\",\n                \"<script>\",\n                \"<meta>\",\n                \"<title>\",\n                // Normal type of lines\n                \" \",\n                \"\",\n            ];\n        }\n        else if (language === \"sol\") {\n            return [\n                // Split along compiler informations definitions\n                \"\\npragma \",\n                \"\\nusing \",\n                // Split along contract definitions\n                \"\\ncontract \",\n                \"\\ninterface \",\n                \"\\nlibrary \",\n                // Split along method definitions\n                \"\\nconstructor \",\n                \"\\ntype \",\n                \"\\nfunction \",\n                \"\\nevent \",\n                \"\\nmodifier \",\n                \"\\nerror \",\n                \"\\nstruct \",\n                \"\\nenum \",\n                // Split along control flow statements\n                \"\\nif \",\n                \"\\nfor \",\n                \"\\nwhile \",\n                \"\\ndo while \",\n                \"\\nassembly \",\n                // Split by the normal type of lines\n                \"\\n\\n\",\n                \"\\n\",\n                \" \",\n                \"\",\n            ];\n        }\n        else {\n            throw new Error(`Language ${language} is not supported.`);\n        }\n    }\n}\n/**\n * Implementation of splitter which looks at tokens.\n */\nexport class TokenTextSplitter extends TextSplitter {\n    static lc_name() {\n        return \"TokenTextSplitter\";\n    }\n    constructor(fields) {\n        super(fields);\n        Object.defineProperty(this, \"encodingName\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"allowedSpecial\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"disallowedSpecial\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        Object.defineProperty(this, \"tokenizer\", {\n            enumerable: true,\n            configurable: true,\n            writable: true,\n            value: void 0\n        });\n        this.encodingName = fields?.encodingName ?? \"gpt2\";\n        this.allowedSpecial = fields?.allowedSpecial ?? [];\n        this.disallowedSpecial = fields?.disallowedSpecial ?? \"all\";\n    }\n    async splitText(text) {\n        if (!this.tokenizer) {\n            this.tokenizer = await getEncoding(this.encodingName);\n        }\n        const splits = [];\n        const input_ids = this.tokenizer.encode(text, this.allowedSpecial, this.disallowedSpecial);\n        let start_idx = 0;\n        while (start_idx < input_ids.length) {\n            if (start_idx > 0) {\n                start_idx -= this.chunkOverlap;\n            }\n            const end_idx = Math.min(start_idx + this.chunkSize, input_ids.length);\n            const chunk_ids = input_ids.slice(start_idx, end_idx);\n            splits.push(this.tokenizer.decode(chunk_ids));\n            start_idx = end_idx;\n        }\n        return splits;\n    }\n}\nexport class MarkdownTextSplitter extends RecursiveCharacterTextSplitter {\n    constructor(fields) {\n        super({\n            ...fields,\n            separators: RecursiveCharacterTextSplitter.getSeparatorsForLanguage(\"markdown\"),\n        });\n    }\n}\nexport class LatexTextSplitter extends RecursiveCharacterTextSplitter {\n    constructor(fields) {\n        super({\n            ...fields,\n            separators: RecursiveCharacterTextSplitter.getSeparatorsForLanguage(\"latex\"),\n        });\n    }\n}\n"],"names":[],"mappings":";;;;;;;;;AAAA;AAAA;AAAA;AACA;AAAA;;;AACO,MAAM,qBAAqB,0KAAA,CAAA,0BAAuB;IACrD,YAAY,MAAM,CAAE;QAChB,KAAK,CAAC;QACN,OAAO,cAAc,CAAC,IAAI,EAAE,gBAAgB;YACxC,YAAY;YACZ,cAAc;YACd,UAAU;YACV,OAAO;gBAAC;gBAAa;gBAAyB;aAAiB;QACnE;QACA,OAAO,cAAc,CAAC,IAAI,EAAE,aAAa;YACrC,YAAY;YACZ,cAAc;YACd,UAAU;YACV,OAAO;QACX;QACA,OAAO,cAAc,CAAC,IAAI,EAAE,gBAAgB;YACxC,YAAY;YACZ,cAAc;YACd,UAAU;YACV,OAAO;QACX;QACA,OAAO,cAAc,CAAC,IAAI,EAAE,iBAAiB;YACzC,YAAY;YACZ,cAAc;YACd,UAAU;YACV,OAAO;QACX;QACA,OAAO,cAAc,CAAC,IAAI,EAAE,kBAAkB;YAC1C,YAAY;YACZ,cAAc;YACd,UAAU;YACV,OAAO,KAAK;QAChB;QACA,IAAI,CAAC,SAAS,GAAG,QAAQ,aAAa,IAAI,CAAC,SAAS;QACpD,IAAI,CAAC,YAAY,GAAG,QAAQ,gBAAgB,IAAI,CAAC,YAAY;QAC7D,IAAI,CAAC,aAAa,GAAG,QAAQ,iBAAiB,IAAI,CAAC,aAAa;QAChE,IAAI,CAAC,cAAc,GACf,QAAQ,kBAAkB,CAAC,CAAC,OAAS,KAAK,MAAM;QACpD,IAAI,IAAI,CAAC,YAAY,IAAI,IAAI,CAAC,SAAS,EAAE;YACrC,MAAM,IAAI,MAAM;QACpB;IACJ;IACA,MAAM,mBAAmB,SAAS,EAAE,qBAAqB,CAAC,CAAC,EAAE;QACzD,OAAO,IAAI,CAAC,cAAc,CAAC,WAAW;IAC1C;IACA,iBAAiB,IAAI,EAAE,SAAS,EAAE;QAC9B,IAAI;QACJ,IAAI,WAAW;YACX,IAAI,IAAI,CAAC,aAAa,EAAE;gBACpB,MAAM,wBAAwB,UAAU,OAAO,CAAC,0BAA0B;gBAC1E,SAAS,KAAK,KAAK,CAAC,IAAI,OAAO,CAAC,GAAG,EAAE,sBAAsB,CAAC,CAAC;YACjE,OACK;gBACD,SAAS,KAAK,KAAK,CAAC;YACxB;QACJ,OACK;YACD,SAAS,KAAK,KAAK,CAAC;QACxB;QACA,OAAO,OAAO,MAAM,CAAC,CAAC,IAAM,MAAM;IACtC;IACA,MAAM,gBAAgB,KAAK,EAC3B,8DAA8D;IAC9D,YAAY,EAAE,EAAE,qBAAqB,CAAC,CAAC,EAAE;QACrC,mEAAmE;QACnE,8DAA8D;QAC9D,MAAM,aAAa,UAAU,MAAM,GAAG,IAChC,YACA;eAAI,MAAM,MAAM,MAAM;SAAE,CAAC,GAAG,CAAC,IAAM,CAAC,CAAC,CAAC;QAC5C,MAAM,EAAE,cAAc,EAAE,EAAE,qBAAqB,WAAW,EAAE,2BAA2B,KAAK,EAAG,GAAG;QAClG,MAAM,YAAY,IAAI;QACtB,IAAK,IAAI,IAAI,GAAG,IAAI,MAAM,MAAM,EAAE,KAAK,EAAG;YACtC,MAAM,OAAO,KAAK,CAAC,EAAE;YACrB,IAAI,mBAAmB;YACvB,IAAI,YAAY;YAChB,IAAI,iBAAiB,CAAC;YACtB,KAAK,MAAM,SAAS,CAAA,MAAM,IAAI,CAAC,SAAS,CAAC,KAAI,EAAG;gBAC5C,IAAI,cAAc;gBAClB,uFAAuF;gBACvF,MAAM,aAAa,KAAK,OAAO,CAAC,OAAO,iBAAiB;gBACxD,IAAI,cAAc,MAAM;oBACpB,MAAM,2BAA2B,IAAI,CAAC,gBAAgB,CAAC,MAAM,GAAG;oBAChE,oBAAoB;gBACxB,OACK;oBACD,MAAM,oBAAoB,iBAAkB,MAAM,IAAI,CAAC,cAAc,CAAC;oBACtE,IAAI,oBAAoB,YAAY;wBAChC,MAAM,+BAA+B,IAAI,CAAC,gBAAgB,CAAC,MAAM,mBAAmB;wBACpF,oBAAoB;oBACxB,OACK,IAAI,oBAAoB,YAAY;wBACrC,MAAM,+BAA+B,IAAI,CAAC,gBAAgB,CAAC,MAAM,YAAY;wBAC7E,oBAAoB;oBACxB;oBACA,IAAI,0BAA0B;wBAC1B,eAAe;oBACnB;gBACJ;gBACA,MAAM,gBAAgB,IAAI,CAAC,gBAAgB,CAAC;gBAC5C,MAAM,MAAM,UAAU,CAAC,EAAE,CAAC,GAAG,IAAI,OAAO,UAAU,CAAC,EAAE,CAAC,GAAG,KAAK,WACxD;oBAAE,GAAG,UAAU,CAAC,EAAE,CAAC,GAAG;gBAAC,IACvB,CAAC;gBACP,IAAI,KAAK,GAAG;oBACR,MAAM;oBACN,IAAI,mBAAmB;gBAC3B;gBACA,MAAM,0BAA0B;oBAC5B,GAAG,UAAU,CAAC,EAAE;oBAChB;gBACJ;gBACA,eAAe;gBACf,UAAU,IAAI,CAAC,IAAI,sKAAA,CAAA,WAAQ,CAAC;oBACxB;oBACA,UAAU;gBACd;gBACA,oBAAoB;gBACpB,YAAY;gBACZ,iBAAiB;YACrB;QACJ;QACA,OAAO;IACX;IACA,iBAAiB,IAAI,EAAE,KAAK,EAAE,GAAG,EAAE;QAC/B,MAAM,cAAc,KAAK,KAAK,CAAC,OAAO;QACtC,OAAO,CAAC,YAAY,KAAK,CAAC,UAAU,EAAE,EAAE,MAAM;IAClD;IACA,MAAM,eAAe,SAAS,EAAE,qBAAqB,CAAC,CAAC,EAAE;QACrD,MAAM,oBAAoB,UAAU,MAAM,CAAC,CAAC,MAAQ,IAAI,WAAW,KAAK;QACxE,MAAM,QAAQ,kBAAkB,GAAG,CAAC,CAAC,MAAQ,IAAI,WAAW;QAC5D,MAAM,YAAY,kBAAkB,GAAG,CAAC,CAAC,MAAQ,IAAI,QAAQ;QAC7D,OAAO,IAAI,CAAC,eAAe,CAAC,OAAO,WAAW;IAClD;IACA,SAAS,IAAI,EAAE,SAAS,EAAE;QACtB,MAAM,OAAO,KAAK,IAAI,CAAC,WAAW,IAAI;QACtC,OAAO,SAAS,KAAK,OAAO;IAChC;IACA,MAAM,YAAY,MAAM,EAAE,SAAS,EAAE;QACjC,MAAM,OAAO,EAAE;QACf,MAAM,aAAa,EAAE;QACrB,IAAI,QAAQ;QACZ,KAAK,MAAM,KAAK,OAAQ;YACpB,MAAM,OAAO,MAAM,IAAI,CAAC,cAAc,CAAC;YACvC,IAAI,QAAQ,OAAO,WAAW,MAAM,GAAG,UAAU,MAAM,GACnD,IAAI,CAAC,SAAS,EAAE;gBAChB,IAAI,QAAQ,IAAI,CAAC,SAAS,EAAE;oBACxB,QAAQ,IAAI,CAAC,CAAC,wBAAwB,EAAE,MAAM;mCAC/B,EAAE,IAAI,CAAC,SAAS,EAAE;gBACrC;gBACA,IAAI,WAAW,MAAM,GAAG,GAAG;oBACvB,MAAM,MAAM,IAAI,CAAC,QAAQ,CAAC,YAAY;oBACtC,IAAI,QAAQ,MAAM;wBACd,KAAK,IAAI,CAAC;oBACd;oBACA,sBAAsB;oBACtB,qDAAqD;oBACrD,0DAA0D;oBAC1D,MAAO,QAAQ,IAAI,CAAC,YAAY,IAC3B,QAAQ,OAAO,WAAW,MAAM,GAAG,UAAU,MAAM,GAChD,IAAI,CAAC,SAAS,IACd,QAAQ,EAAI;wBAChB,SAAS,MAAM,IAAI,CAAC,cAAc,CAAC,UAAU,CAAC,EAAE;wBAChD,WAAW,KAAK;oBACpB;gBACJ;YACJ;YACA,WAAW,IAAI,CAAC;YAChB,SAAS;QACb;QACA,MAAM,MAAM,IAAI,CAAC,QAAQ,CAAC,YAAY;QACtC,IAAI,QAAQ,MAAM;YACd,KAAK,IAAI,CAAC;QACd;QACA,OAAO;IACX;AACJ;AACO,MAAM,8BAA8B;IACvC,OAAO,UAAU;QACb,OAAO;IACX;IACA,YAAY,MAAM,CAAE;QAChB,KAAK,CAAC;QACN,OAAO,cAAc,CAAC,IAAI,EAAE,aAAa;YACrC,YAAY;YACZ,cAAc;YACd,UAAU;YACV,OAAO;QACX;QACA,IAAI,CAAC,SAAS,GAAG,QAAQ,aAAa,IAAI,CAAC,SAAS;IACxD;IACA,MAAM,UAAU,IAAI,EAAE;QAClB,uEAAuE;QACvE,MAAM,SAAS,IAAI,CAAC,gBAAgB,CAAC,MAAM,IAAI,CAAC,SAAS;QACzD,OAAO,IAAI,CAAC,WAAW,CAAC,QAAQ,IAAI,CAAC,aAAa,GAAG,KAAK,IAAI,CAAC,SAAS;IAC5E;AACJ;AACO,MAAM,iCAAiC;IAC1C;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;CACH;AACM,MAAM,uCAAuC;IAChD,OAAO,UAAU;QACb,OAAO;IACX;IACA,YAAY,MAAM,CAAE;QAChB,KAAK,CAAC;QACN,OAAO,cAAc,CAAC,IAAI,EAAE,cAAc;YACtC,YAAY;YACZ,cAAc;YACd,UAAU;YACV,OAAO;gBAAC;gBAAQ;gBAAM;gBAAK;aAAG;QAClC;QACA,IAAI,CAAC,UAAU,GAAG,QAAQ,cAAc,IAAI,CAAC,UAAU;QACvD,IAAI,CAAC,aAAa,GAAG,QAAQ,iBAAiB;IAClD;IACA,MAAM,WAAW,IAAI,EAAE,UAAU,EAAE;QAC/B,MAAM,cAAc,EAAE;QACtB,mCAAmC;QACnC,IAAI,YAAY,UAAU,CAAC,WAAW,MAAM,GAAG,EAAE;QACjD,IAAI;QACJ,IAAK,IAAI,IAAI,GAAG,IAAI,WAAW,MAAM,EAAE,KAAK,EAAG;YAC3C,MAAM,IAAI,UAAU,CAAC,EAAE;YACvB,IAAI,MAAM,IAAI;gBACV,YAAY;gBACZ;YACJ;YACA,IAAI,KAAK,QAAQ,CAAC,IAAI;gBAClB,YAAY;gBACZ,gBAAgB,WAAW,KAAK,CAAC,IAAI;gBACrC;YACJ;QACJ;QACA,iDAAiD;QACjD,MAAM,SAAS,IAAI,CAAC,gBAAgB,CAAC,MAAM;QAC3C,6DAA6D;QAC7D,IAAI,aAAa,EAAE;QACnB,MAAM,aAAa,IAAI,CAAC,aAAa,GAAG,KAAK;QAC7C,KAAK,MAAM,KAAK,OAAQ;YACpB,IAAI,AAAC,MAAM,IAAI,CAAC,cAAc,CAAC,KAAM,IAAI,CAAC,SAAS,EAAE;gBACjD,WAAW,IAAI,CAAC;YACpB,OACK;gBACD,IAAI,WAAW,MAAM,EAAE;oBACnB,MAAM,aAAa,MAAM,IAAI,CAAC,WAAW,CAAC,YAAY;oBACtD,YAAY,IAAI,IAAI;oBACpB,aAAa,EAAE;gBACnB;gBACA,IAAI,CAAC,eAAe;oBAChB,YAAY,IAAI,CAAC;gBACrB,OACK;oBACD,MAAM,YAAY,MAAM,IAAI,CAAC,UAAU,CAAC,GAAG;oBAC3C,YAAY,IAAI,IAAI;gBACxB;YACJ;QACJ;QACA,IAAI,WAAW,MAAM,EAAE;YACnB,MAAM,aAAa,MAAM,IAAI,CAAC,WAAW,CAAC,YAAY;YACtD,YAAY,IAAI,IAAI;QACxB;QACA,OAAO;IACX;IACA,MAAM,UAAU,IAAI,EAAE;QAClB,OAAO,IAAI,CAAC,UAAU,CAAC,MAAM,IAAI,CAAC,UAAU;IAChD;IACA,OAAO,aAAa,QAAQ,EAAE,OAAO,EAAE;QACnC,OAAO,IAAI,+BAA+B;YACtC,GAAG,OAAO;YACV,YAAY,+BAA+B,wBAAwB,CAAC;QACxE;IACJ;IACA,OAAO,yBAAyB,QAAQ,EAAE;QACtC,IAAI,aAAa,OAAO;YACpB,OAAO;gBACH,gCAAgC;gBAChC;gBACA,mCAAmC;gBACnC;gBACA;gBACA;gBACA;gBACA,sCAAsC;gBACtC;gBACA;gBACA;gBACA;gBACA;gBACA,oCAAoC;gBACpC;gBACA;gBACA;gBACA;aACH;QACL,OACK,IAAI,aAAa,MAAM;YACxB,OAAO;gBACH,mCAAmC;gBACnC;gBACA;gBACA;gBACA;gBACA,sCAAsC;gBACtC;gBACA;gBACA;gBACA;gBACA,oCAAoC;gBACpC;gBACA;gBACA;gBACA;aACH;QACL,OACK,IAAI,aAAa,QAAQ;YAC1B,OAAO;gBACH,gCAAgC;gBAChC;gBACA,iCAAiC;gBACjC;gBACA;gBACA;gBACA;gBACA,sCAAsC;gBACtC;gBACA;gBACA;gBACA;gBACA;gBACA,oCAAoC;gBACpC;gBACA;gBACA;gBACA;aACH;QACL,OACK,IAAI,aAAa,MAAM;YACxB,OAAO;gBACH,mCAAmC;gBACnC;gBACA;gBACA;gBACA;gBACA;gBACA,sCAAsC;gBACtC;gBACA;gBACA;gBACA;gBACA;gBACA;gBACA,oCAAoC;gBACpC;gBACA;gBACA;gBACA;aACH;QACL,OACK,IAAI,aAAa,OAAO;YACzB,OAAO;gBACH,mCAAmC;gBACnC;gBACA,gCAAgC;gBAChC;gBACA,sCAAsC;gBACtC;gBACA;gBACA;gBACA;gBACA;gBACA;gBACA,oCAAoC;gBACpC;gBACA;gBACA;gBACA;aACH;QACL,OACK,IAAI,aAAa,SAAS;YAC3B,OAAO;gBACH,kCAAkC;gBAClC;gBACA,kCAAkC;gBAClC;gBACA,+BAA+B;gBAC/B;gBACA,iCAAiC;gBACjC;gBACA,gCAAgC;gBAChC;gBACA,kCAAkC;gBAClC;gBACA,oCAAoC;gBACpC;gBACA;gBACA;gBACA;aACH;QACL,OACK,IAAI,aAAa,UAAU;YAC5B,OAAO;gBACH,8CAA8C;gBAC9C;gBACA;gBACA;gBACA,wCAAwC;gBACxC;gBACA;gBACA;gBACA;aACH;QACL,OACK,IAAI,aAAa,OAAO;YACzB,OAAO;gBACH,6BAA6B;gBAC7B;gBACA;gBACA;gBACA,gCAAgC;gBAChC;gBACA,oCAAoC;gBACpC;gBACA;gBACA;gBACA;aACH;QACL,OACK,IAAI,aAAa,QAAQ;YAC1B,OAAO;gBACH,iCAAiC;gBACjC;gBACA;gBACA,sCAAsC;gBACtC;gBACA;gBACA;gBACA;gBACA;gBACA;gBACA;gBACA,oCAAoC;gBACpC;gBACA;gBACA;gBACA;aACH;QACL,OACK,IAAI,aAAa,QAAQ;YAC1B,OAAO;gBACH,mCAAmC;gBACnC;gBACA;gBACA;gBACA,sCAAsC;gBACtC;gBACA;gBACA;gBACA;gBACA;gBACA;gBACA,oCAAoC;gBACpC;gBACA;gBACA;gBACA;aACH;QACL,OACK,IAAI,aAAa,SAAS;YAC3B,OAAO;gBACH,gCAAgC;gBAChC;gBACA;gBACA,iCAAiC;gBACjC;gBACA;gBACA;gBACA,sCAAsC;gBACtC;gBACA;gBACA;gBACA;gBACA;gBACA,oCAAoC;gBACpC;gBACA;gBACA;gBACA;aACH;QACL,OACK,IAAI,aAAa,SAAS;YAC3B,OAAO;gBACH,mCAAmC;gBACnC;gBACA,gCAAgC;gBAChC;gBACA;gBACA;gBACA,sCAAsC;gBACtC;gBACA;gBACA;gBACA;gBACA;gBACA;gBACA,oCAAoC;gBACpC;gBACA;gBACA;gBACA;aACH;QACL,OACK,IAAI,aAAa,YAAY;YAC9B,OAAO;gBACH,sEAAsE;gBACtE;gBACA;gBACA;gBACA;gBACA;gBACA,uEAAuE;gBACvE,kBAAkB;gBAClB,kBAAkB;gBAClB,oBAAoB;gBACpB;gBACA,mBAAmB;gBACnB;gBACA;gBACA;gBACA,kEAAkE;gBAClE,kEAAkE;gBAClE;gBACA;gBACA;gBACA;aACH;QACL,OACK,IAAI,aAAa,SAAS;YAC3B,OAAO;gBACH,2CAA2C;gBAC3C;gBACA;gBACA;gBACA;gBACA,4BAA4B;gBAC5B;gBACA;gBACA;gBACA;gBACA;gBACA;gBACA;gBACA;gBACA,iCAAiC;gBACjC;gBACA;gBACA;gBACA,wCAAwC;gBACxC;gBACA;gBACA;gBACA;aACH;QACL,OACK,IAAI,aAAa,QAAQ;YAC1B,OAAO;gBACH,sCAAsC;gBACtC;gBACA;gBACA;gBACA;gBACA;gBACA;gBACA;gBACA;gBACA;gBACA;gBACA;gBACA;gBACA;gBACA;gBACA;gBACA;gBACA;gBACA;gBACA;gBACA;gBACA;gBACA,OAAO;gBACP;gBACA;gBACA;gBACA;gBACA;gBACA,uBAAuB;gBACvB;gBACA;aACH;QACL,OACK,IAAI,aAAa,OAAO;YACzB,OAAO;gBACH,gDAAgD;gBAChD;gBACA;gBACA,mCAAmC;gBACnC;gBACA;gBACA;gBACA,iCAAiC;gBACjC;gBACA;gBACA;gBACA;gBACA;gBACA;gBACA;gBACA;gBACA,sCAAsC;gBACtC;gBACA;gBACA;gBACA;gBACA;gBACA,oCAAoC;gBACpC;gBACA;gBACA;gBACA;aACH;QACL,OACK;YACD,MAAM,IAAI,MAAM,CAAC,SAAS,EAAE,SAAS,kBAAkB,CAAC;QAC5D;IACJ;AACJ;AAIO,MAAM,0BAA0B;IACnC,OAAO,UAAU;QACb,OAAO;IACX;IACA,YAAY,MAAM,CAAE;QAChB,KAAK,CAAC;QACN,OAAO,cAAc,CAAC,IAAI,EAAE,gBAAgB;YACxC,YAAY;YACZ,cAAc;YACd,UAAU;YACV,OAAO,KAAK;QAChB;QACA,OAAO,cAAc,CAAC,IAAI,EAAE,kBAAkB;YAC1C,YAAY;YACZ,cAAc;YACd,UAAU;YACV,OAAO,KAAK;QAChB;QACA,OAAO,cAAc,CAAC,IAAI,EAAE,qBAAqB;YAC7C,YAAY;YACZ,cAAc;YACd,UAAU;YACV,OAAO,KAAK;QAChB;QACA,OAAO,cAAc,CAAC,IAAI,EAAE,aAAa;YACrC,YAAY;YACZ,cAAc;YACd,UAAU;YACV,OAAO,KAAK;QAChB;QACA,IAAI,CAAC,YAAY,GAAG,QAAQ,gBAAgB;QAC5C,IAAI,CAAC,cAAc,GAAG,QAAQ,kBAAkB,EAAE;QAClD,IAAI,CAAC,iBAAiB,GAAG,QAAQ,qBAAqB;IAC1D;IACA,MAAM,UAAU,IAAI,EAAE;QAClB,IAAI,CAAC,IAAI,CAAC,SAAS,EAAE;YACjB,IAAI,CAAC,SAAS,GAAG,MAAM,CAAA,GAAA,kKAAA,CAAA,cAAW,AAAD,EAAE,IAAI,CAAC,YAAY;QACxD;QACA,MAAM,SAAS,EAAE;QACjB,MAAM,YAAY,IAAI,CAAC,SAAS,CAAC,MAAM,CAAC,MAAM,IAAI,CAAC,cAAc,EAAE,IAAI,CAAC,iBAAiB;QACzF,IAAI,YAAY;QAChB,MAAO,YAAY,UAAU,MAAM,CAAE;YACjC,IAAI,YAAY,GAAG;gBACf,aAAa,IAAI,CAAC,YAAY;YAClC;YACA,MAAM,UAAU,KAAK,GAAG,CAAC,YAAY,IAAI,CAAC,SAAS,EAAE,UAAU,MAAM;YACrE,MAAM,YAAY,UAAU,KAAK,CAAC,WAAW;YAC7C,OAAO,IAAI,CAAC,IAAI,CAAC,SAAS,CAAC,MAAM,CAAC;YAClC,YAAY;QAChB;QACA,OAAO;IACX;AACJ;AACO,MAAM,6BAA6B;IACtC,YAAY,MAAM,CAAE;QAChB,KAAK,CAAC;YACF,GAAG,MAAM;YACT,YAAY,+BAA+B,wBAAwB,CAAC;QACxE;IACJ;AACJ;AACO,MAAM,0BAA0B;IACnC,YAAY,MAAM,CAAE;QAChB,KAAK,CAAC;YACF,GAAG,MAAM;YACT,YAAY,+BAA+B,wBAAwB,CAAC;QACxE;IACJ;AACJ","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 3053, "column": 0}, "map": {"version":3,"sources":["file:///Users/dylanchua/Documents/Personal/Code/neurodocument/node_modules/%40langchain/textsplitters/dist/index.js"],"sourcesContent":["export * from \"./text_splitter.js\";\n"],"names":[],"mappings":";AAAA","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 3071, "column": 0}, "map": {"version":3,"sources":["file:///Users/dylanchua/Documents/Personal/Code/neurodocument/node_modules/%40langchain/textsplitters/index.js"],"sourcesContent":["export * from './dist/index.js'"],"names":[],"mappings":";AAAA","ignoreList":[0],"debugId":null}}]
}